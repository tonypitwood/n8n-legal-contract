"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.WorkflowBuilderAgent = void 0;
const messages_1 = require("@langchain/core/messages");
const langgraph_1 = require("@langchain/langgraph");
const n8n_workflow_1 = require("n8n-workflow");
const constants_1 = require("./constants");
const trim_workflow_context_1 = require("./utils/trim-workflow-context");
const conversation_compact_1 = require("./chains/conversation-compact");
const workflow_name_1 = require("./chains/workflow-name");
const errors_1 = require("./errors");
const session_manager_service_1 = require("./session-manager.service");
const builder_tools_1 = require("./tools/builder-tools");
const main_agent_prompt_1 = require("./tools/prompts/main-agent.prompt");
const operations_processor_1 = require("./utils/operations-processor");
const stream_processor_1 = require("./utils/stream-processor");
const token_usage_1 = require("./utils/token-usage");
const tool_executor_1 = require("./utils/tool-executor");
const workflow_state_1 = require("./workflow-state");
class WorkflowBuilderAgent {
    checkpointer;
    parsedNodeTypes;
    llmSimpleTask;
    llmComplexTask;
    logger;
    tracer;
    autoCompactThresholdTokens;
    instanceUrl;
    onGenerationSuccess;
    constructor(config) {
        this.parsedNodeTypes = config.parsedNodeTypes;
        this.llmSimpleTask = config.llmSimpleTask;
        this.llmComplexTask = config.llmComplexTask;
        this.logger = config.logger;
        this.checkpointer = config.checkpointer;
        this.tracer = config.tracer;
        this.autoCompactThresholdTokens =
            config.autoCompactThresholdTokens ?? constants_1.DEFAULT_AUTO_COMPACT_THRESHOLD_TOKENS;
        this.instanceUrl = config.instanceUrl;
        this.onGenerationSuccess = config.onGenerationSuccess;
    }
    getBuilderTools() {
        return (0, builder_tools_1.getBuilderTools)({
            parsedNodeTypes: this.parsedNodeTypes,
            instanceUrl: this.instanceUrl,
            llmComplexTask: this.llmComplexTask,
            logger: this.logger,
        });
    }
    createWorkflow() {
        const builderTools = this.getBuilderTools();
        const tools = builderTools.map((bt) => bt.tool);
        const toolMap = new Map(tools.map((tool) => [tool.name, tool]));
        const callModel = async (state) => {
            if (!this.llmSimpleTask) {
                throw new errors_1.LLMServiceError('LLM not setup');
            }
            if (typeof this.llmSimpleTask.bindTools !== 'function') {
                throw new errors_1.LLMServiceError('LLM does not support tools', {
                    llmModel: this.llmSimpleTask._llmType(),
                });
            }
            const prompt = await main_agent_prompt_1.mainAgentPrompt.invoke({
                ...state,
                workflowJSON: (0, trim_workflow_context_1.trimWorkflowJSON)(state.workflowJSON),
                executionData: state.workflowContext?.executionData ?? {},
                executionSchema: state.workflowContext?.executionSchema ?? [],
                instanceUrl: this.instanceUrl,
            });
            const estimatedTokens = (0, token_usage_1.estimateTokenCountFromMessages)(prompt.messages);
            if (estimatedTokens > constants_1.MAX_INPUT_TOKENS) {
                throw new errors_1.WorkflowStateError('The current conversation and workflow state is too large to process. Try to simplify your workflow by breaking it into smaller parts.');
            }
            const response = await this.llmSimpleTask.bindTools(tools).invoke(prompt);
            return { messages: [response] };
        };
        const shouldAutoCompact = ({ messages }) => {
            const tokenUsage = (0, token_usage_1.extractLastTokenUsage)(messages);
            if (!tokenUsage) {
                this.logger?.debug('No token usage metadata found');
                return false;
            }
            const tokensUsed = tokenUsage.input_tokens + tokenUsage.output_tokens;
            this.logger?.debug('Token usage', {
                inputTokens: tokenUsage.input_tokens,
                outputTokens: tokenUsage.output_tokens,
                totalTokens: tokensUsed,
            });
            return tokensUsed > this.autoCompactThresholdTokens;
        };
        const shouldModifyState = (state) => {
            const { messages, workflowContext } = state;
            const lastHumanMessage = messages.findLast((m) => m instanceof messages_1.HumanMessage);
            if (lastHumanMessage.content === '/compact') {
                return 'compact_messages';
            }
            if (lastHumanMessage.content === '/clear') {
                return 'delete_messages';
            }
            if (workflowContext?.currentWorkflow?.nodes?.length === 0 && messages.length === 1) {
                return 'create_workflow_name';
            }
            if (shouldAutoCompact(state)) {
                return 'auto_compact_messages';
            }
            return 'agent';
        };
        const shouldContinue = ({ messages }) => {
            const lastMessage = messages[messages.length - 1];
            if (lastMessage.tool_calls?.length) {
                return 'tools';
            }
            if (this.onGenerationSuccess) {
                void Promise.resolve(this.onGenerationSuccess()).catch((error) => {
                    this.logger?.warn('Failed to execute onGenerationSuccess callback', { error });
                });
            }
            return langgraph_1.END;
        };
        const customToolExecutor = async (state) => {
            return await (0, tool_executor_1.executeToolsInParallel)({ state, toolMap });
        };
        function deleteMessages(state) {
            const messages = state.messages;
            const stateUpdate = {
                workflowOperations: null,
                workflowContext: {},
                messages: messages.map((m) => new messages_1.RemoveMessage({ id: m.id })) ?? [],
                workflowJSON: {
                    nodes: [],
                    connections: {},
                    name: '',
                },
            };
            return stateUpdate;
        }
        const compactSession = async (state) => {
            if (!this.llmSimpleTask) {
                throw new errors_1.LLMServiceError('LLM not setup');
            }
            const { messages, previousSummary } = state;
            const lastHumanMessage = messages[messages.length - 1];
            const isAutoCompact = lastHumanMessage.content !== '/compact';
            this.logger?.debug('Compacting conversation history', {
                isAutoCompact,
            });
            const compactedMessages = await (0, conversation_compact_1.conversationCompactChain)(this.llmSimpleTask, messages, previousSummary);
            return {
                previousSummary: compactedMessages.summaryPlain,
                messages: [
                    ...messages.map((m) => new messages_1.RemoveMessage({ id: m.id })),
                    new messages_1.HumanMessage('Please compress the conversation history'),
                    new messages_1.AIMessage('Successfully compacted conversation history'),
                    ...(isAutoCompact ? [new messages_1.HumanMessage({ content: lastHumanMessage.content })] : []),
                ],
            };
        };
        const createWorkflowName = async (state) => {
            if (!this.llmSimpleTask) {
                throw new errors_1.LLMServiceError('LLM not setup');
            }
            const { workflowJSON, messages } = state;
            if (messages.length === 1 && messages[0] instanceof messages_1.HumanMessage) {
                const initialMessage = messages[0];
                if (typeof initialMessage.content !== 'string') {
                    this.logger?.debug('Initial message content is not a string, skipping workflow name generation');
                    return {};
                }
                this.logger?.debug('Generating workflow name');
                const { name } = await (0, workflow_name_1.workflowNameChain)(this.llmSimpleTask, initialMessage.content);
                return {
                    workflowJSON: {
                        ...workflowJSON,
                        name,
                    },
                };
            }
            return {};
        };
        const workflow = new langgraph_1.StateGraph(workflow_state_1.WorkflowState)
            .addNode('agent', callModel)
            .addNode('tools', customToolExecutor)
            .addNode('process_operations', operations_processor_1.processOperations)
            .addNode('delete_messages', deleteMessages)
            .addNode('compact_messages', compactSession)
            .addNode('auto_compact_messages', compactSession)
            .addNode('create_workflow_name', createWorkflowName)
            .addConditionalEdges('__start__', shouldModifyState)
            .addEdge('tools', 'process_operations')
            .addEdge('process_operations', 'agent')
            .addEdge('auto_compact_messages', 'agent')
            .addEdge('create_workflow_name', 'agent')
            .addEdge('delete_messages', langgraph_1.END)
            .addEdge('compact_messages', langgraph_1.END)
            .addConditionalEdges('agent', shouldContinue);
        return workflow;
    }
    async getState(workflowId, userId) {
        const workflow = this.createWorkflow();
        const agent = workflow.compile({ checkpointer: this.checkpointer });
        return await agent.getState({
            configurable: { thread_id: `workflow-${workflowId}-user-${userId ?? new Date().getTime()}` },
        });
    }
    getDefaultWorkflowJSON(payload) {
        return (payload.workflowContext?.currentWorkflow ?? {
            nodes: [],
            connections: {},
        });
    }
    async *chat(payload, userId, abortSignal) {
        this.validateMessageLength(payload.message);
        const { agent, threadConfig, streamConfig } = this.setupAgentAndConfigs(payload, userId, abortSignal);
        try {
            const stream = await this.createAgentStream(payload, streamConfig, agent);
            yield* this.processAgentStream(stream, agent, threadConfig);
        }
        catch (error) {
            this.handleStreamError(error);
        }
    }
    validateMessageLength(message) {
        if (message.length > constants_1.MAX_AI_BUILDER_PROMPT_LENGTH) {
            this.logger?.warn('Message exceeds maximum length', {
                messageLength: message.length,
                maxLength: constants_1.MAX_AI_BUILDER_PROMPT_LENGTH,
            });
            throw new errors_1.ValidationError(`Message exceeds maximum length of ${constants_1.MAX_AI_BUILDER_PROMPT_LENGTH} characters`);
        }
    }
    setupAgentAndConfigs(payload, userId, abortSignal) {
        const agent = this.createWorkflow().compile({ checkpointer: this.checkpointer });
        const workflowId = payload.workflowContext?.currentWorkflow?.id;
        const threadId = session_manager_service_1.SessionManagerService.generateThreadId(workflowId, userId);
        const threadConfig = {
            configurable: {
                thread_id: threadId,
            },
        };
        const streamConfig = {
            ...threadConfig,
            streamMode: ['updates', 'custom'],
            recursionLimit: 50,
            signal: abortSignal,
            callbacks: this.tracer ? [this.tracer] : undefined,
        };
        return { agent, threadConfig, streamConfig };
    }
    async createAgentStream(payload, streamConfig, agent) {
        return await agent.stream({
            messages: [new messages_1.HumanMessage({ content: payload.message })],
            workflowJSON: this.getDefaultWorkflowJSON(payload),
            workflowOperations: [],
            workflowContext: payload.workflowContext,
        }, streamConfig);
    }
    handleStreamError(error) {
        const invalidRequestErrorMessage = this.getInvalidRequestError(error);
        if (invalidRequestErrorMessage) {
            throw new errors_1.ValidationError(invalidRequestErrorMessage);
        }
        throw error;
    }
    async *processAgentStream(stream, agent, threadConfig) {
        try {
            const streamProcessor = (0, stream_processor_1.createStreamProcessor)(stream);
            for await (const output of streamProcessor) {
                yield output;
            }
        }
        catch (error) {
            await this.handleAgentStreamError(error, agent, threadConfig);
        }
    }
    async handleAgentStreamError(error, agent, threadConfig) {
        if (error &&
            typeof error === 'object' &&
            'message' in error &&
            typeof error.message === 'string' &&
            ['Abort', 'Aborted'].includes(error.message)) {
            const messages = (await agent.getState(threadConfig)).values.messages;
            const abortedAiMessage = new messages_1.AIMessage({
                content: '[Task aborted]',
                id: crypto.randomUUID(),
            });
            await agent.updateState(threadConfig, { messages: [...messages, abortedAiMessage] });
            return;
        }
        if (error instanceof langgraph_1.GraphRecursionError) {
            throw new n8n_workflow_1.ApplicationError('Workflow generation stopped: The AI reached the maximum number of steps while building your workflow. This usually means the workflow design became too complex or got stuck in a loop while trying to create the nodes and connections.');
        }
        throw error;
    }
    getInvalidRequestError(error) {
        if (error instanceof Error &&
            'error' in error &&
            typeof error.error === 'object' &&
            error.error) {
            const innerError = error.error;
            if ('error' in innerError && typeof innerError.error === 'object' && innerError.error) {
                const errorDetails = innerError.error;
                if ('type' in errorDetails &&
                    errorDetails.type === 'invalid_request_error' &&
                    'message' in errorDetails &&
                    typeof errorDetails.message === 'string') {
                    return errorDetails.message;
                }
            }
        }
        return undefined;
    }
}
exports.WorkflowBuilderAgent = WorkflowBuilderAgent;
//# sourceMappingURL=workflow-builder-agent.js.map