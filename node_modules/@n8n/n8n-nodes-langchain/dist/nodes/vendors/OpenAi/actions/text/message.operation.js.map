{"version":3,"sources":["../../../../../../nodes/vendors/OpenAi/actions/text/message.operation.ts"],"sourcesContent":["import type { Tool } from '@langchain/core/tools';\nimport _omit from 'lodash/omit';\nimport type {\n\tINodeProperties,\n\tIExecuteFunctions,\n\tINodeExecutionData,\n\tIDataObject,\n} from 'n8n-workflow';\nimport { jsonParse, updateDisplayOptions } from 'n8n-workflow';\n\nimport { getConnectedTools } from '@utils/helpers';\n\nimport { MODELS_NOT_SUPPORT_FUNCTION_CALLS } from '../../helpers/constants';\nimport type { ChatCompletion } from '../../helpers/interfaces';\nimport { formatToOpenAIAssistantTool } from '../../helpers/utils';\nimport { apiRequest } from '../../transport';\nimport { modelRLC } from '../descriptions';\n\nconst properties: INodeProperties[] = [\n\tmodelRLC('modelSearch'),\n\t{\n\t\tdisplayName: 'Messages',\n\t\tname: 'messages',\n\t\ttype: 'fixedCollection',\n\t\ttypeOptions: {\n\t\t\tsortable: true,\n\t\t\tmultipleValues: true,\n\t\t},\n\t\tplaceholder: 'Add Message',\n\t\tdefault: { values: [{ content: '' }] },\n\t\toptions: [\n\t\t\t{\n\t\t\t\tdisplayName: 'Values',\n\t\t\t\tname: 'values',\n\t\t\t\tvalues: [\n\t\t\t\t\t{\n\t\t\t\t\t\tdisplayName: 'Prompt',\n\t\t\t\t\t\tname: 'content',\n\t\t\t\t\t\ttype: 'string',\n\t\t\t\t\t\tdescription: 'The content of the message to be send',\n\t\t\t\t\t\tdefault: '',\n\t\t\t\t\t\tplaceholder: 'e.g. Hello, how can you help me?',\n\t\t\t\t\t\ttypeOptions: {\n\t\t\t\t\t\t\trows: 2,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tdisplayName: 'Role',\n\t\t\t\t\t\tname: 'role',\n\t\t\t\t\t\ttype: 'options',\n\t\t\t\t\t\tdescription:\n\t\t\t\t\t\t\t\"Role in shaping the model's response, it tells the model how it should behave and interact with the user\",\n\t\t\t\t\t\toptions: [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tname: 'User',\n\t\t\t\t\t\t\t\tvalue: 'user',\n\t\t\t\t\t\t\t\tdescription: 'Send a message as a user and get a response from the model',\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tname: 'Assistant',\n\t\t\t\t\t\t\t\tvalue: 'assistant',\n\t\t\t\t\t\t\t\tdescription: 'Tell the model to adopt a specific tone or personality',\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tname: 'System',\n\t\t\t\t\t\t\t\tvalue: 'system',\n\t\t\t\t\t\t\t\tdescription:\n\t\t\t\t\t\t\t\t\t\"Usually used to set the model's behavior or context for the next user message\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t],\n\t\t\t\t\t\tdefault: 'user',\n\t\t\t\t\t},\n\t\t\t\t],\n\t\t\t},\n\t\t],\n\t},\n\t{\n\t\tdisplayName: 'Simplify Output',\n\t\tname: 'simplify',\n\t\ttype: 'boolean',\n\t\tdefault: true,\n\t\tdescription: 'Whether to return a simplified version of the response instead of the raw data',\n\t},\n\t{\n\t\tdisplayName: 'Output Content as JSON',\n\t\tname: 'jsonOutput',\n\t\ttype: 'boolean',\n\t\tdescription:\n\t\t\t'Whether to attempt to return the response in JSON format. Compatible with GPT-4 Turbo and all GPT-3.5 Turbo models newer than gpt-3.5-turbo-1106.',\n\t\tdefault: false,\n\t},\n\t{\n\t\tdisplayName: 'Hide Tools',\n\t\tname: 'hideTools',\n\t\ttype: 'hidden',\n\t\tdefault: 'hide',\n\t\tdisplayOptions: {\n\t\t\tshow: {\n\t\t\t\tmodelId: MODELS_NOT_SUPPORT_FUNCTION_CALLS,\n\t\t\t\t'@version': [{ _cnd: { gte: 1.2 } }],\n\t\t\t},\n\t\t},\n\t},\n\t{\n\t\tdisplayName: 'Connect your own custom n8n tools to this node on the canvas',\n\t\tname: 'noticeTools',\n\t\ttype: 'notice',\n\t\tdefault: '',\n\t\tdisplayOptions: {\n\t\t\thide: {\n\t\t\t\thideTools: ['hide'],\n\t\t\t},\n\t\t},\n\t},\n\t{\n\t\tdisplayName: 'Options',\n\t\tname: 'options',\n\t\tplaceholder: 'Add Option',\n\t\ttype: 'collection',\n\t\tdefault: {},\n\t\toptions: [\n\t\t\t{\n\t\t\t\tdisplayName: 'Frequency Penalty',\n\t\t\t\tname: 'frequency_penalty',\n\t\t\t\tdefault: 0,\n\t\t\t\ttypeOptions: { maxValue: 2, minValue: -2, numberPrecision: 1 },\n\t\t\t\tdescription:\n\t\t\t\t\t\"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim\",\n\t\t\t\ttype: 'number',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Maximum Number of Tokens',\n\t\t\t\tname: 'maxTokens',\n\t\t\t\tdefault: 16,\n\t\t\t\tdescription:\n\t\t\t\t\t'The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).',\n\t\t\t\ttype: 'number',\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tmaxValue: 32768,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Number of Completions',\n\t\t\t\tname: 'n',\n\t\t\t\tdefault: 1,\n\t\t\t\tdescription:\n\t\t\t\t\t'How many completions to generate for each prompt. Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.',\n\t\t\t\ttype: 'number',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Presence Penalty',\n\t\t\t\tname: 'presence_penalty',\n\t\t\t\tdefault: 0,\n\t\t\t\ttypeOptions: { maxValue: 2, minValue: -2, numberPrecision: 1 },\n\t\t\t\tdescription:\n\t\t\t\t\t\"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics\",\n\t\t\t\ttype: 'number',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Output Randomness (Temperature)',\n\t\t\t\tname: 'temperature',\n\t\t\t\tdefault: 1,\n\t\t\t\ttypeOptions: { maxValue: 1, minValue: 0, numberPrecision: 1 },\n\t\t\t\tdescription:\n\t\t\t\t\t'Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. We generally recommend altering this or temperature but not both.',\n\t\t\t\ttype: 'number',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Output Randomness (Top P)',\n\t\t\t\tname: 'topP',\n\t\t\t\tdefault: 1,\n\t\t\t\ttypeOptions: { maxValue: 1, minValue: 0, numberPrecision: 1 },\n\t\t\t\tdescription:\n\t\t\t\t\t'An alternative to sampling with temperature, controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.',\n\t\t\t\ttype: 'number',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Reasoning Effort',\n\t\t\t\tname: 'reasoning_effort',\n\t\t\t\tdefault: 'medium',\n\t\t\t\tdescription:\n\t\t\t\t\t'Controls the amount of reasoning tokens to use. A value of \"low\" will favor speed and economical token usage, \"high\" will favor more complete reasoning at the cost of more tokens generated and slower responses.',\n\t\t\t\ttype: 'options',\n\t\t\t\toptions: [\n\t\t\t\t\t{\n\t\t\t\t\t\tname: 'Low',\n\t\t\t\t\t\tvalue: 'low',\n\t\t\t\t\t\tdescription: 'Favors speed and economical token usage',\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tname: 'Medium',\n\t\t\t\t\t\tvalue: 'medium',\n\t\t\t\t\t\tdescription: 'Balance between speed and reasoning accuracy',\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tname: 'High',\n\t\t\t\t\t\tvalue: 'high',\n\t\t\t\t\t\tdescription:\n\t\t\t\t\t\t\t'Favors more complete reasoning at the cost of more tokens generated and slower responses',\n\t\t\t\t\t},\n\t\t\t\t],\n\t\t\t\tdisplayOptions: {\n\t\t\t\t\tshow: {\n\t\t\t\t\t\t// reasoning_effort is only available on o1, o1-versioned, or on o3-mini and beyond, and gpt-5 models. Not on o1-mini or other GPT-models.\n\t\t\t\t\t\t'/modelId': [{ _cnd: { regex: '(^o1([-\\\\d]+)?$)|(^o[3-9].*)|(^gpt-5.*)' } }],\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Max Tool Calls Iterations',\n\t\t\t\tname: 'maxToolsIterations',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 15,\n\t\t\t\tdescription:\n\t\t\t\t\t'The maximum number of tool iteration cycles the LLM will run before stopping. A single iteration can contain multiple tool calls. Set to 0 for no limit.',\n\t\t\t\tdisplayOptions: {\n\t\t\t\t\tshow: {\n\t\t\t\t\t\t'@version': [{ _cnd: { gte: 1.5 } }],\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t],\n\t},\n];\n\nconst displayOptions = {\n\tshow: {\n\t\toperation: ['message'],\n\t\tresource: ['text'],\n\t},\n};\n\nexport const description = updateDisplayOptions(displayOptions, properties);\n\nexport async function execute(this: IExecuteFunctions, i: number): Promise<INodeExecutionData[]> {\n\tconst nodeVersion = this.getNode().typeVersion;\n\tconst model = this.getNodeParameter('modelId', i, '', { extractValue: true });\n\tlet messages = this.getNodeParameter('messages.values', i, []) as IDataObject[];\n\tconst options = this.getNodeParameter('options', i, {});\n\tconst jsonOutput = this.getNodeParameter('jsonOutput', i, false) as boolean;\n\tconst maxToolsIterations =\n\t\tnodeVersion >= 1.5 ? (this.getNodeParameter('options.maxToolsIterations', i, 15) as number) : 0;\n\n\tconst abortSignal = this.getExecutionCancelSignal();\n\n\tif (options.maxTokens !== undefined) {\n\t\toptions.max_completion_tokens = options.maxTokens;\n\t\tdelete options.maxTokens;\n\t}\n\n\tif (options.topP !== undefined) {\n\t\toptions.top_p = options.topP;\n\t\tdelete options.topP;\n\t}\n\n\tlet response_format;\n\tif (jsonOutput) {\n\t\tresponse_format = { type: 'json_object' };\n\t\tmessages = [\n\t\t\t{\n\t\t\t\trole: 'system',\n\t\t\t\tcontent: 'You are a helpful assistant designed to output JSON.',\n\t\t\t},\n\t\t\t...messages,\n\t\t];\n\t}\n\n\tconst hideTools = this.getNodeParameter('hideTools', i, '') as string;\n\n\tlet tools;\n\tlet externalTools: Tool[] = [];\n\n\tif (hideTools !== 'hide') {\n\t\tconst enforceUniqueNames = nodeVersion > 1;\n\t\texternalTools = await getConnectedTools(this, enforceUniqueNames, false);\n\t}\n\n\tif (externalTools.length) {\n\t\ttools = externalTools.length ? externalTools?.map(formatToOpenAIAssistantTool) : undefined;\n\t}\n\n\tconst body: IDataObject = {\n\t\tmodel,\n\t\tmessages,\n\t\ttools,\n\t\tresponse_format,\n\t\t..._omit(options, ['maxToolsIterations']),\n\t};\n\n\tlet response = (await apiRequest.call(this, 'POST', '/chat/completions', {\n\t\tbody,\n\t})) as ChatCompletion;\n\n\tif (!response) return [];\n\n\tlet currentIteration = 1;\n\tlet toolCalls = response?.choices[0]?.message?.tool_calls;\n\n\twhile (toolCalls?.length) {\n\t\t// Break the loop if the max iterations is reached or the execution is canceled\n\t\tif (\n\t\t\tabortSignal?.aborted ||\n\t\t\t(maxToolsIterations > 0 && currentIteration >= maxToolsIterations)\n\t\t) {\n\t\t\tbreak;\n\t\t}\n\t\tmessages.push(response.choices[0].message);\n\n\t\tfor (const toolCall of toolCalls) {\n\t\t\tconst functionName = toolCall.function.name;\n\t\t\tconst functionArgs = toolCall.function.arguments;\n\n\t\t\tlet functionResponse;\n\t\t\tfor (const tool of externalTools ?? []) {\n\t\t\t\tif (tool.name === functionName) {\n\t\t\t\t\tconst parsedArgs: { input: string } = jsonParse(functionArgs);\n\t\t\t\t\tconst functionInput = parsedArgs.input ?? parsedArgs ?? functionArgs;\n\t\t\t\t\tfunctionResponse = await tool.invoke(functionInput);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (typeof functionResponse === 'object') {\n\t\t\t\tfunctionResponse = JSON.stringify(functionResponse);\n\t\t\t}\n\n\t\t\tmessages.push({\n\t\t\t\ttool_call_id: toolCall.id,\n\t\t\t\trole: 'tool',\n\t\t\t\tcontent: functionResponse,\n\t\t\t});\n\t\t}\n\n\t\tresponse = (await apiRequest.call(this, 'POST', '/chat/completions', {\n\t\t\tbody,\n\t\t})) as ChatCompletion;\n\n\t\ttoolCalls = response.choices[0].message.tool_calls;\n\t\tcurrentIteration += 1;\n\t}\n\n\tif (response_format) {\n\t\tresponse.choices = response.choices.map((choice) => {\n\t\t\ttry {\n\t\t\t\tchoice.message.content = JSON.parse(choice.message.content);\n\t\t\t} catch (error) {}\n\t\t\treturn choice;\n\t\t});\n\t}\n\n\tconst simplify = this.getNodeParameter('simplify', i) as boolean;\n\n\tconst returnData: INodeExecutionData[] = [];\n\n\tif (simplify) {\n\t\tfor (const entry of response.choices) {\n\t\t\treturnData.push({\n\t\t\t\tjson: entry,\n\t\t\t\tpairedItem: { item: i },\n\t\t\t});\n\t\t}\n\t} else {\n\t\treturnData.push({ json: response, pairedItem: { item: i } });\n\t}\n\n\treturn returnData;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA,kBAAkB;AAOlB,0BAAgD;AAEhD,qBAAkC;AAElC,uBAAkD;AAElD,mBAA4C;AAC5C,uBAA2B;AAC3B,0BAAyB;AAEzB,MAAM,aAAgC;AAAA,MACrC,8BAAS,aAAa;AAAA,EACtB;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,MAAM;AAAA,IACN,aAAa;AAAA,MACZ,UAAU;AAAA,MACV,gBAAgB;AAAA,IACjB;AAAA,IACA,aAAa;AAAA,IACb,SAAS,EAAE,QAAQ,CAAC,EAAE,SAAS,GAAG,CAAC,EAAE;AAAA,IACrC,SAAS;AAAA,MACR;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,QAAQ;AAAA,UACP;AAAA,YACC,aAAa;AAAA,YACb,MAAM;AAAA,YACN,MAAM;AAAA,YACN,aAAa;AAAA,YACb,SAAS;AAAA,YACT,aAAa;AAAA,YACb,aAAa;AAAA,cACZ,MAAM;AAAA,YACP;AAAA,UACD;AAAA,UACA;AAAA,YACC,aAAa;AAAA,YACb,MAAM;AAAA,YACN,MAAM;AAAA,YACN,aACC;AAAA,YACD,SAAS;AAAA,cACR;AAAA,gBACC,MAAM;AAAA,gBACN,OAAO;AAAA,gBACP,aAAa;AAAA,cACd;AAAA,cACA;AAAA,gBACC,MAAM;AAAA,gBACN,OAAO;AAAA,gBACP,aAAa;AAAA,cACd;AAAA,cACA;AAAA,gBACC,MAAM;AAAA,gBACN,OAAO;AAAA,gBACP,aACC;AAAA,cACF;AAAA,YACD;AAAA,YACA,SAAS;AAAA,UACV;AAAA,QACD;AAAA,MACD;AAAA,IACD;AAAA,EACD;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,MAAM;AAAA,IACN,SAAS;AAAA,IACT,aAAa;AAAA,EACd;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,MAAM;AAAA,IACN,aACC;AAAA,IACD,SAAS;AAAA,EACV;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,MAAM;AAAA,IACN,SAAS;AAAA,IACT,gBAAgB;AAAA,MACf,MAAM;AAAA,QACL,SAAS;AAAA,QACT,YAAY,CAAC,EAAE,MAAM,EAAE,KAAK,IAAI,EAAE,CAAC;AAAA,MACpC;AAAA,IACD;AAAA,EACD;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,MAAM;AAAA,IACN,SAAS;AAAA,IACT,gBAAgB;AAAA,MACf,MAAM;AAAA,QACL,WAAW,CAAC,MAAM;AAAA,MACnB;AAAA,IACD;AAAA,EACD;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,aAAa;AAAA,IACb,MAAM;AAAA,IACN,SAAS,CAAC;AAAA,IACV,SAAS;AAAA,MACR;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa,EAAE,UAAU,GAAG,UAAU,IAAI,iBAAiB,EAAE;AAAA,QAC7D,aACC;AAAA,QACD,MAAM;AAAA,MACP;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,QACD,MAAM;AAAA,QACN,aAAa;AAAA,UACZ,UAAU;AAAA,QACX;AAAA,MACD;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,QACD,MAAM;AAAA,MACP;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa,EAAE,UAAU,GAAG,UAAU,IAAI,iBAAiB,EAAE;AAAA,QAC7D,aACC;AAAA,QACD,MAAM;AAAA,MACP;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa,EAAE,UAAU,GAAG,UAAU,GAAG,iBAAiB,EAAE;AAAA,QAC5D,aACC;AAAA,QACD,MAAM;AAAA,MACP;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa,EAAE,UAAU,GAAG,UAAU,GAAG,iBAAiB,EAAE;AAAA,QAC5D,aACC;AAAA,QACD,MAAM;AAAA,MACP;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,QACD,MAAM;AAAA,QACN,SAAS;AAAA,UACR;AAAA,YACC,MAAM;AAAA,YACN,OAAO;AAAA,YACP,aAAa;AAAA,UACd;AAAA,UACA;AAAA,YACC,MAAM;AAAA,YACN,OAAO;AAAA,YACP,aAAa;AAAA,UACd;AAAA,UACA;AAAA,YACC,MAAM;AAAA,YACN,OAAO;AAAA,YACP,aACC;AAAA,UACF;AAAA,QACD;AAAA,QACA,gBAAgB;AAAA,UACf,MAAM;AAAA;AAAA,YAEL,YAAY,CAAC,EAAE,MAAM,EAAE,OAAO,0CAA0C,EAAE,CAAC;AAAA,UAC5E;AAAA,QACD;AAAA,MACD;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,QACD,gBAAgB;AAAA,UACf,MAAM;AAAA,YACL,YAAY,CAAC,EAAE,MAAM,EAAE,KAAK,IAAI,EAAE,CAAC;AAAA,UACpC;AAAA,QACD;AAAA,MACD;AAAA,IACD;AAAA,EACD;AACD;AAEA,MAAM,iBAAiB;AAAA,EACtB,MAAM;AAAA,IACL,WAAW,CAAC,SAAS;AAAA,IACrB,UAAU,CAAC,MAAM;AAAA,EAClB;AACD;AAEO,MAAM,kBAAc,0CAAqB,gBAAgB,UAAU;AAE1E,eAAsB,QAAiC,GAA0C;AAChG,QAAM,cAAc,KAAK,QAAQ,EAAE;AACnC,QAAM,QAAQ,KAAK,iBAAiB,WAAW,GAAG,IAAI,EAAE,cAAc,KAAK,CAAC;AAC5E,MAAI,WAAW,KAAK,iBAAiB,mBAAmB,GAAG,CAAC,CAAC;AAC7D,QAAM,UAAU,KAAK,iBAAiB,WAAW,GAAG,CAAC,CAAC;AACtD,QAAM,aAAa,KAAK,iBAAiB,cAAc,GAAG,KAAK;AAC/D,QAAM,qBACL,eAAe,MAAO,KAAK,iBAAiB,8BAA8B,GAAG,EAAE,IAAe;AAE/F,QAAM,cAAc,KAAK,yBAAyB;AAElD,MAAI,QAAQ,cAAc,QAAW;AACpC,YAAQ,wBAAwB,QAAQ;AACxC,WAAO,QAAQ;AAAA,EAChB;AAEA,MAAI,QAAQ,SAAS,QAAW;AAC/B,YAAQ,QAAQ,QAAQ;AACxB,WAAO,QAAQ;AAAA,EAChB;AAEA,MAAI;AACJ,MAAI,YAAY;AACf,sBAAkB,EAAE,MAAM,cAAc;AACxC,eAAW;AAAA,MACV;AAAA,QACC,MAAM;AAAA,QACN,SAAS;AAAA,MACV;AAAA,MACA,GAAG;AAAA,IACJ;AAAA,EACD;AAEA,QAAM,YAAY,KAAK,iBAAiB,aAAa,GAAG,EAAE;AAE1D,MAAI;AACJ,MAAI,gBAAwB,CAAC;AAE7B,MAAI,cAAc,QAAQ;AACzB,UAAM,qBAAqB,cAAc;AACzC,oBAAgB,UAAM,kCAAkB,MAAM,oBAAoB,KAAK;AAAA,EACxE;AAEA,MAAI,cAAc,QAAQ;AACzB,YAAQ,cAAc,SAAS,eAAe,IAAI,wCAA2B,IAAI;AAAA,EAClF;AAEA,QAAM,OAAoB;AAAA,IACzB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,OAAG,YAAAA,SAAM,SAAS,CAAC,oBAAoB,CAAC;AAAA,EACzC;AAEA,MAAI,WAAY,MAAM,4BAAW,KAAK,MAAM,QAAQ,qBAAqB;AAAA,IACxE;AAAA,EACD,CAAC;AAED,MAAI,CAAC,SAAU,QAAO,CAAC;AAEvB,MAAI,mBAAmB;AACvB,MAAI,YAAY,UAAU,QAAQ,CAAC,GAAG,SAAS;AAE/C,SAAO,WAAW,QAAQ;AAEzB,QACC,aAAa,WACZ,qBAAqB,KAAK,oBAAoB,oBAC9C;AACD;AAAA,IACD;AACA,aAAS,KAAK,SAAS,QAAQ,CAAC,EAAE,OAAO;AAEzC,eAAW,YAAY,WAAW;AACjC,YAAM,eAAe,SAAS,SAAS;AACvC,YAAM,eAAe,SAAS,SAAS;AAEvC,UAAI;AACJ,iBAAW,QAAQ,iBAAiB,CAAC,GAAG;AACvC,YAAI,KAAK,SAAS,cAAc;AAC/B,gBAAM,iBAAgC,+BAAU,YAAY;AAC5D,gBAAM,gBAAgB,WAAW,SAAS,cAAc;AACxD,6BAAmB,MAAM,KAAK,OAAO,aAAa;AAAA,QACnD;AAAA,MACD;AAEA,UAAI,OAAO,qBAAqB,UAAU;AACzC,2BAAmB,KAAK,UAAU,gBAAgB;AAAA,MACnD;AAEA,eAAS,KAAK;AAAA,QACb,cAAc,SAAS;AAAA,QACvB,MAAM;AAAA,QACN,SAAS;AAAA,MACV,CAAC;AAAA,IACF;AAEA,eAAY,MAAM,4BAAW,KAAK,MAAM,QAAQ,qBAAqB;AAAA,MACpE;AAAA,IACD,CAAC;AAED,gBAAY,SAAS,QAAQ,CAAC,EAAE,QAAQ;AACxC,wBAAoB;AAAA,EACrB;AAEA,MAAI,iBAAiB;AACpB,aAAS,UAAU,SAAS,QAAQ,IAAI,CAAC,WAAW;AACnD,UAAI;AACH,eAAO,QAAQ,UAAU,KAAK,MAAM,OAAO,QAAQ,OAAO;AAAA,MAC3D,SAAS,OAAO;AAAA,MAAC;AACjB,aAAO;AAAA,IACR,CAAC;AAAA,EACF;AAEA,QAAM,WAAW,KAAK,iBAAiB,YAAY,CAAC;AAEpD,QAAM,aAAmC,CAAC;AAE1C,MAAI,UAAU;AACb,eAAW,SAAS,SAAS,SAAS;AACrC,iBAAW,KAAK;AAAA,QACf,MAAM;AAAA,QACN,YAAY,EAAE,MAAM,EAAE;AAAA,MACvB,CAAC;AAAA,IACF;AAAA,EACD,OAAO;AACN,eAAW,KAAK,EAAE,MAAM,UAAU,YAAY,EAAE,MAAM,EAAE,EAAE,CAAC;AAAA,EAC5D;AAEA,SAAO;AACR;","names":["_omit"]}