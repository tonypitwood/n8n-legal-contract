{"version":3,"sources":["../../../../nodes/llms/LMOllama/description.ts"],"sourcesContent":["import type { INodeProperties, INodeTypeDescription } from 'n8n-workflow';\n\nexport const ollamaDescription: Partial<INodeTypeDescription> = {\n\tcredentials: [\n\t\t{\n\t\t\tname: 'ollamaApi',\n\t\t\trequired: true,\n\t\t},\n\t],\n\trequestDefaults: {\n\t\tignoreHttpStatusErrors: true,\n\t\tbaseURL: '={{ $credentials.baseUrl.replace(new RegExp(\"/$\"), \"\") }}',\n\t},\n};\n\nexport const ollamaModel: INodeProperties = {\n\tdisplayName: 'Model',\n\tname: 'model',\n\ttype: 'options',\n\tdefault: 'llama3.2',\n\tdescription:\n\t\t'The model which will generate the completion. To download models, visit <a href=\"https://ollama.ai/library\">Ollama Models Library</a>.',\n\ttypeOptions: {\n\t\tloadOptions: {\n\t\t\trouting: {\n\t\t\t\trequest: {\n\t\t\t\t\tmethod: 'GET',\n\t\t\t\t\turl: '/api/tags',\n\t\t\t\t},\n\t\t\t\toutput: {\n\t\t\t\t\tpostReceive: [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\ttype: 'rootProperty',\n\t\t\t\t\t\t\tproperties: {\n\t\t\t\t\t\t\t\tproperty: 'models',\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\ttype: 'setKeyValue',\n\t\t\t\t\t\t\tproperties: {\n\t\t\t\t\t\t\t\tname: '={{$responseItem.name}}',\n\t\t\t\t\t\t\t\tvalue: '={{$responseItem.name}}',\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\ttype: 'sort',\n\t\t\t\t\t\t\tproperties: {\n\t\t\t\t\t\t\t\tkey: 'name',\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t],\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t},\n\trouting: {\n\t\tsend: {\n\t\t\ttype: 'body',\n\t\t\tproperty: 'model',\n\t\t},\n\t},\n\trequired: true,\n};\n\nexport const ollamaOptions: INodeProperties = {\n\tdisplayName: 'Options',\n\tname: 'options',\n\tplaceholder: 'Add Option',\n\tdescription: 'Additional options to add',\n\ttype: 'collection',\n\tdefault: {},\n\toptions: [\n\t\t{\n\t\t\tdisplayName: 'Sampling Temperature',\n\t\t\tname: 'temperature',\n\t\t\tdefault: 0.7,\n\t\t\ttypeOptions: { maxValue: 1, minValue: 0, numberPrecision: 1 },\n\t\t\tdescription:\n\t\t\t\t'Controls the randomness of the generated text. Lower values make the output more focused and deterministic, while higher values make it more diverse and random.',\n\t\t\ttype: 'number',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Top K',\n\t\t\tname: 'topK',\n\t\t\tdefault: -1,\n\t\t\ttypeOptions: { maxValue: 100, minValue: -1, numberPrecision: 1 },\n\t\t\tdescription:\n\t\t\t\t'Limits the number of highest probability vocabulary tokens to consider at each step. A higher value increases diversity but may reduce coherence. Set to -1 to disable.',\n\t\t\ttype: 'number',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Top P',\n\t\t\tname: 'topP',\n\t\t\tdefault: 1,\n\t\t\ttypeOptions: { maxValue: 1, minValue: 0, numberPrecision: 1 },\n\t\t\tdescription:\n\t\t\t\t'Chooses from the smallest possible set of tokens whose cumulative probability exceeds the probability top_p. Helps generate more human-like text by reducing repetitions.',\n\t\t\ttype: 'number',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Frequency Penalty',\n\t\t\tname: 'frequencyPenalty',\n\t\t\ttype: 'number',\n\t\t\tdefault: 0.0,\n\t\t\ttypeOptions: { minValue: 0 },\n\t\t\tdescription:\n\t\t\t\t'Adjusts the penalty for tokens that have already appeared in the generated text. Higher values discourage repetition.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Keep Alive',\n\t\t\tname: 'keepAlive',\n\t\t\ttype: 'string',\n\t\t\tdefault: '5m',\n\t\t\tdescription:\n\t\t\t\t'Specifies the duration to keep the loaded model in memory after use. Useful for frequently used models. Format: 1h30m (1 hour 30 minutes).',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Low VRAM Mode',\n\t\t\tname: 'lowVram',\n\t\t\ttype: 'boolean',\n\t\t\tdefault: false,\n\t\t\tdescription:\n\t\t\t\t'Whether to Activate low VRAM mode, which reduces memory usage at the cost of slower generation speed. Useful for GPUs with limited memory.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Main GPU ID',\n\t\t\tname: 'mainGpu',\n\t\t\ttype: 'number',\n\t\t\tdefault: 0,\n\t\t\tdescription:\n\t\t\t\t'Specifies the ID of the GPU to use for the main computation. Only change this if you have multiple GPUs.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Context Batch Size',\n\t\t\tname: 'numBatch',\n\t\t\ttype: 'number',\n\t\t\tdefault: 512,\n\t\t\tdescription:\n\t\t\t\t'Sets the batch size for prompt processing. Larger batch sizes may improve generation speed but increase memory usage.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Context Length',\n\t\t\tname: 'numCtx',\n\t\t\ttype: 'number',\n\t\t\tdefault: 2048,\n\t\t\tdescription:\n\t\t\t\t'The maximum number of tokens to use as context for generating the next token. Smaller values reduce memory usage, while larger values provide more context to the model.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Number of GPUs',\n\t\t\tname: 'numGpu',\n\t\t\ttype: 'number',\n\t\t\tdefault: -1,\n\t\t\tdescription:\n\t\t\t\t'Specifies the number of GPUs to use for parallel processing. Set to -1 for auto-detection.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Max Tokens to Generate',\n\t\t\tname: 'numPredict',\n\t\t\ttype: 'number',\n\t\t\tdefault: -1,\n\t\t\tdescription:\n\t\t\t\t'The maximum number of tokens to generate. Set to -1 for no limit. Be cautious when setting this to a large value, as it can lead to very long outputs.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Number of CPU Threads',\n\t\t\tname: 'numThread',\n\t\t\ttype: 'number',\n\t\t\tdefault: 0,\n\t\t\tdescription:\n\t\t\t\t'Specifies the number of CPU threads to use for processing. Set to 0 for auto-detection.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Penalize Newlines',\n\t\t\tname: 'penalizeNewline',\n\t\t\ttype: 'boolean',\n\t\t\tdefault: true,\n\t\t\tdescription:\n\t\t\t\t'Whether the model will be less likely to generate newline characters, encouraging longer continuous sequences of text',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Presence Penalty',\n\t\t\tname: 'presencePenalty',\n\t\t\ttype: 'number',\n\t\t\tdefault: 0.0,\n\t\t\tdescription:\n\t\t\t\t'Adjusts the penalty for tokens based on their presence in the generated text so far. Positive values penalize tokens that have already appeared, encouraging diversity.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Repetition Penalty',\n\t\t\tname: 'repeatPenalty',\n\t\t\ttype: 'number',\n\t\t\tdefault: 1.0,\n\t\t\tdescription:\n\t\t\t\t'Adjusts the penalty factor for repeated tokens. Higher values more strongly discourage repetition. Set to 1.0 to disable repetition penalty.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Use Memory Locking',\n\t\t\tname: 'useMLock',\n\t\t\ttype: 'boolean',\n\t\t\tdefault: false,\n\t\t\tdescription:\n\t\t\t\t'Whether to lock the model in memory to prevent swapping. This can improve performance but requires sufficient available memory.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Use Memory Mapping',\n\t\t\tname: 'useMMap',\n\t\t\ttype: 'boolean',\n\t\t\tdefault: true,\n\t\t\tdescription:\n\t\t\t\t'Whether to use memory mapping for loading the model. This can reduce memory usage but may impact performance. Recommended to keep enabled.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Load Vocabulary Only',\n\t\t\tname: 'vocabOnly',\n\t\t\ttype: 'boolean',\n\t\t\tdefault: false,\n\t\t\tdescription:\n\t\t\t\t'Whether to only load the model vocabulary without the weights. Useful for quickly testing tokenization.',\n\t\t},\n\t\t{\n\t\t\tdisplayName: 'Output Format',\n\t\t\tname: 'format',\n\t\t\ttype: 'options',\n\t\t\toptions: [\n\t\t\t\t{ name: 'Default', value: 'default' },\n\t\t\t\t{ name: 'JSON', value: 'json' },\n\t\t\t],\n\t\t\tdefault: 'default',\n\t\t\tdescription: 'Specifies the format of the API response',\n\t\t},\n\t],\n};\n"],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEO,MAAM,oBAAmD;AAAA,EAC/D,aAAa;AAAA,IACZ;AAAA,MACC,MAAM;AAAA,MACN,UAAU;AAAA,IACX;AAAA,EACD;AAAA,EACA,iBAAiB;AAAA,IAChB,wBAAwB;AAAA,IACxB,SAAS;AAAA,EACV;AACD;AAEO,MAAM,cAA+B;AAAA,EAC3C,aAAa;AAAA,EACb,MAAM;AAAA,EACN,MAAM;AAAA,EACN,SAAS;AAAA,EACT,aACC;AAAA,EACD,aAAa;AAAA,IACZ,aAAa;AAAA,MACZ,SAAS;AAAA,QACR,SAAS;AAAA,UACR,QAAQ;AAAA,UACR,KAAK;AAAA,QACN;AAAA,QACA,QAAQ;AAAA,UACP,aAAa;AAAA,YACZ;AAAA,cACC,MAAM;AAAA,cACN,YAAY;AAAA,gBACX,UAAU;AAAA,cACX;AAAA,YACD;AAAA,YACA;AAAA,cACC,MAAM;AAAA,cACN,YAAY;AAAA,gBACX,MAAM;AAAA,gBACN,OAAO;AAAA,cACR;AAAA,YACD;AAAA,YACA;AAAA,cACC,MAAM;AAAA,cACN,YAAY;AAAA,gBACX,KAAK;AAAA,cACN;AAAA,YACD;AAAA,UACD;AAAA,QACD;AAAA,MACD;AAAA,IACD;AAAA,EACD;AAAA,EACA,SAAS;AAAA,IACR,MAAM;AAAA,MACL,MAAM;AAAA,MACN,UAAU;AAAA,IACX;AAAA,EACD;AAAA,EACA,UAAU;AACX;AAEO,MAAM,gBAAiC;AAAA,EAC7C,aAAa;AAAA,EACb,MAAM;AAAA,EACN,aAAa;AAAA,EACb,aAAa;AAAA,EACb,MAAM;AAAA,EACN,SAAS,CAAC;AAAA,EACV,SAAS;AAAA,IACR;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aAAa,EAAE,UAAU,GAAG,UAAU,GAAG,iBAAiB,EAAE;AAAA,MAC5D,aACC;AAAA,MACD,MAAM;AAAA,IACP;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aAAa,EAAE,UAAU,KAAK,UAAU,IAAI,iBAAiB,EAAE;AAAA,MAC/D,aACC;AAAA,MACD,MAAM;AAAA,IACP;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aAAa,EAAE,UAAU,GAAG,UAAU,GAAG,iBAAiB,EAAE;AAAA,MAC5D,aACC;AAAA,MACD,MAAM;AAAA,IACP;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aAAa,EAAE,UAAU,EAAE;AAAA,MAC3B,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,MACT,aACC;AAAA,IACF;AAAA,IACA;AAAA,MACC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,QACR,EAAE,MAAM,WAAW,OAAO,UAAU;AAAA,QACpC,EAAE,MAAM,QAAQ,OAAO,OAAO;AAAA,MAC/B;AAAA,MACA,SAAS;AAAA,MACT,aAAa;AAAA,IACd;AAAA,EACD;AACD;","names":[]}