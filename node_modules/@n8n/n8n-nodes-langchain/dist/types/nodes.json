[
{"displayName":"Anthropic","name":"anthropic","group":["transform"],"version":1,"subtitle":"={{ $parameter[\"operation\"] + \": \" + $parameter[\"resource\"] }}","description":"Interact with Anthropic AI models","defaults":{"name":"Anthropic"},"usableAsTool":true,"codex":{"alias":["LangChain","document","image","assistant","claude"],"categories":["AI"],"subcategories":{"AI":["Agents","Miscellaneous","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-langchain.anthropic/"}]}},"inputs":"={{\n\t\t(() => {\n\t\t\tconst resource = $parameter.resource;\n\t  \tconst operation = $parameter.operation;\n\t\t\tif (resource === 'text' && operation === 'message') {\n\t\t\t\treturn [{ type: 'main' }, { type: 'ai_tool', displayName: 'Tools' }];\n\t\t\t}\n\n\t\t\treturn ['main'];\n\t\t})()\n\t}}","outputs":["main"],"credentials":[{"name":"anthropicApi","required":true}],"properties":[{"displayName":"Resource","name":"resource","type":"options","noDataExpression":true,"options":[{"name":"Document","value":"document"},{"name":"File","value":"file"},{"name":"Image","value":"image"},{"name":"Prompt","value":"prompt"},{"name":"Text","value":"text"}],"default":"text"},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Analyze Document","value":"analyze","action":"Analyze document","description":"Take in documents and answer questions about them"}],"default":"analyze","displayOptions":{"show":{"resource":["document"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. claude-3-5-sonnet-20241022"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Text Input","name":"text","type":"string","placeholder":"e.g. What's in this document?","default":"What's in this document?","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Document URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"URL(s)","name":"documentUrls","type":"string","placeholder":"e.g. https://example.com/document.pdf","description":"URL(s) of the document(s) to analyze, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["analyze"],"resource":["document"]}}},{"displayName":"Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field(s) which contains the document(s), seperate multiple field names with commas","displayOptions":{"show":{"inputType":["binary"],"operation":["analyze"],"resource":["document"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Length of Description (Max Tokens)","description":"Fewer tokens will result in shorter, less detailed image description","name":"maxTokens","type":"number","default":1024,"typeOptions":{"minValue":1}}],"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Upload File","value":"upload","action":"Upload a file","description":"Upload a file to the Anthropic API for later use"},{"name":"Get File Metadata","value":"get","action":"Get file metadata","description":"Get metadata for a file from the Anthropic API"},{"name":"List Files","value":"list","action":"List files","description":"List files from the Anthropic API"},{"name":"Delete File","value":"deleteFile","action":"Delete a file","description":"Delete a file from the Anthropic API"}],"default":"upload","displayOptions":{"show":{"resource":["file"]}}},{"displayName":"File ID","name":"fileId","type":"string","placeholder":"e.g. file_123","description":"ID of the file to delete","default":"","displayOptions":{"show":{"operation":["deleteFile"],"resource":["file"]}}},{"displayName":"File ID","name":"fileId","type":"string","placeholder":"e.g. file_123","description":"ID of the file to get metadata for","default":"","displayOptions":{"show":{"operation":["get"],"resource":["file"]}}},{"displayName":"Return All","name":"returnAll","type":"boolean","default":false,"description":"Whether to return all results or only up to a given limit","displayOptions":{"show":{"operation":["list"],"resource":["file"]}}},{"displayName":"Limit","name":"limit","type":"number","typeOptions":{"minValue":1,"maxValue":1000},"default":50,"description":"Max number of results to return","displayOptions":{"show":{"returnAll":[false],"operation":["list"],"resource":["file"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"File URL","value":"url"},{"name":"Binary File","value":"binary"}],"displayOptions":{"show":{"operation":["upload"],"resource":["file"]}}},{"displayName":"URL","name":"fileUrl","type":"string","placeholder":"e.g. https://example.com/file.pdf","description":"URL of the file to upload","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["upload"],"resource":["file"]}}},{"displayName":"Input Data Field Name","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field which contains the file","displayOptions":{"show":{"inputType":["binary"],"operation":["upload"],"resource":["file"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"File Name","name":"fileName","type":"string","description":"The file name to use for the uploaded file","default":""}],"displayOptions":{"show":{"operation":["upload"],"resource":["file"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Analyze Image","value":"analyze","action":"Analyze image","description":"Take in images and answer questions about them"}],"default":"analyze","displayOptions":{"show":{"resource":["image"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. claude-3-5-sonnet-20241022"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Text Input","name":"text","type":"string","placeholder":"e.g. What's in this image?","default":"What's in this image?","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Image URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"URL(s)","name":"imageUrls","type":"string","placeholder":"e.g. https://example.com/image.png","description":"URL(s) of the image(s) to analyze, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["analyze"],"resource":["image"]}}},{"displayName":"Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field(s) which contains the image(s), seperate multiple field names with commas","displayOptions":{"show":{"inputType":["binary"],"operation":["analyze"],"resource":["image"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Length of Description (Max Tokens)","description":"Fewer tokens will result in shorter, less detailed image description","name":"maxTokens","type":"number","default":1024,"typeOptions":{"minValue":1}}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Generate Prompt","value":"generate","action":"Generate a prompt","description":"Generate a prompt for a model"},{"name":"Improve Prompt","value":"improve","action":"Improve a prompt","description":"Improve a prompt for a model"},{"name":"Templatize Prompt","value":"templatize","action":"Templatize a prompt","description":"Templatize a prompt for a model"}],"default":"generate","displayOptions":{"show":{"resource":["prompt"]}}},{"displayName":"The <a href=\"https://docs.anthropic.com/en/api/prompt-tools-generate\">prompt tools APIs</a> are in a closed research preview. Your organization must request access to use them.","name":"experimentalNotice","type":"notice","default":"","displayOptions":{"show":{"resource":["prompt"]}}},{"displayName":"Task","name":"task","type":"string","description":"Description of the prompt's purpose","placeholder":"e.g. A chef for a meal prep planning service","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["generate"],"resource":["prompt"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["generate"],"resource":["prompt"]}}},{"displayName":"Messages","name":"messages","type":"fixedCollection","typeOptions":{"sortable":true,"multipleValues":true},"description":"Messages that constitute the prompt to be improved","placeholder":"Add Message","default":{"values":[{"content":"","role":"user"}]},"options":[{"displayName":"Values","name":"values","values":[{"displayName":"Prompt","name":"content","type":"string","description":"The content of the message to be sent","default":"","placeholder":"e.g. Concise instructions for a meal prep service","typeOptions":{"rows":2}},{"displayName":"Role","name":"role","type":"options","description":"Role in shaping the model's response, it tells the model how it should behave and interact with the user","options":[{"name":"User","value":"user","description":"Send a message as a user and get a response from the model"},{"name":"Assistant","value":"assistant","description":"Tell the model to adopt a specific tone or personality"}],"default":"user"}]}],"displayOptions":{"show":{"operation":["improve"],"resource":["prompt"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["improve"],"resource":["prompt"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"System Message","name":"system","type":"string","description":"The existing system prompt to incorporate, if any","default":"","placeholder":"e.g. You are a professional meal prep chef"},{"displayName":"Feedback","name":"feedback","type":"string","description":"Feedback for improving the prompt","default":"","placeholder":"e.g. Make it more detailed and include cooking times"}],"displayOptions":{"show":{"operation":["improve"],"resource":["prompt"]}}},{"displayName":"Messages","name":"messages","type":"fixedCollection","typeOptions":{"sortable":true,"multipleValues":true},"description":"Messages that constitute the prompt to be templatized","placeholder":"Add Message","default":{"values":[{"content":"","role":"user"}]},"options":[{"displayName":"Values","name":"values","values":[{"displayName":"Prompt","name":"content","type":"string","description":"The content of the message to be sent","default":"","placeholder":"e.g. Translate hello to German","typeOptions":{"rows":2}},{"displayName":"Role","name":"role","type":"options","description":"Role in shaping the model's response, it tells the model how it should behave and interact with the user","options":[{"name":"User","value":"user","description":"Send a message as a user and get a response from the model"},{"name":"Assistant","value":"assistant","description":"Tell the model to adopt a specific tone or personality"}],"default":"user"}]}],"displayOptions":{"show":{"operation":["templatize"],"resource":["prompt"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["templatize"],"resource":["prompt"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"System Message","name":"system","type":"string","description":"The existing system prompt to templatize","default":"","placeholder":"e.g. You are a professional English to German translator"}],"displayOptions":{"show":{"operation":["templatize"],"resource":["prompt"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Message a Model","value":"message","action":"Message a model","description":"Create a completion with Anthropic model"}],"default":"message","displayOptions":{"show":{"resource":["text"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. claude-3-5-sonnet-20241022"}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Messages","name":"messages","type":"fixedCollection","typeOptions":{"sortable":true,"multipleValues":true},"placeholder":"Add Message","default":{"values":[{"content":"","role":"user"}]},"options":[{"displayName":"Values","name":"values","values":[{"displayName":"Prompt","name":"content","type":"string","description":"The content of the message to be sent","default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2}},{"displayName":"Role","name":"role","type":"options","description":"Role in shaping the model's response, it tells the model how it should behave and interact with the user","options":[{"name":"User","value":"user","description":"Send a message as a user and get a response from the model"},{"name":"Assistant","value":"assistant","description":"Tell the model to adopt a specific tone or personality"}],"default":"user"}]}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Add Attachments","name":"addAttachments","type":"boolean","default":false,"description":"Whether to add attachments to the message","displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Attachments Input Type","name":"attachmentsInputType","type":"options","default":"url","description":"The type of input to use for the attachments","options":[{"name":"URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"addAttachments":[true],"operation":["message"],"resource":["text"]}}},{"displayName":"Attachment URL(s)","name":"attachmentsUrls","type":"string","default":"","placeholder":"e.g. https://example.com/image.png","description":"URL(s) of the file(s) to attach, multiple URLs can be added separated by comma","displayOptions":{"show":{"addAttachments":[true],"attachmentsInputType":["url"],"operation":["message"],"resource":["text"]}}},{"displayName":"Attachment Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","description":"Name of the binary field(s) which contains the file(s) to attach, multiple field names can be added separated by comma","displayOptions":{"show":{"addAttachments":[true],"attachmentsInputType":["binary"],"operation":["message"],"resource":["text"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Include Merged Response","name":"includeMergedResponse","type":"boolean","default":false,"description":"Whether to include a single output string merging all text parts of the response"},{"displayName":"System Message","name":"system","type":"string","default":"","placeholder":"e.g. You are a helpful assistant"},{"displayName":"Code Execution","name":"codeExecution","type":"boolean","default":false,"description":"Whether to enable code execution. Not supported by all models."},{"displayName":"Web Search","name":"webSearch","type":"boolean","default":false,"description":"Whether to enable web search"},{"displayName":"Web Search Max Uses","name":"maxUses","type":"number","default":5,"description":"The maximum number of web search uses per request","typeOptions":{"minValue":0,"numberPrecision":0}},{"displayName":"Web Search Allowed Domains","name":"allowedDomains","type":"string","default":"","description":"Comma-separated list of domains to search. Only domains in this list will be searched. Conflicts with \"Web Search Blocked Domains\".","placeholder":"e.g. google.com, wikipedia.org"},{"displayName":"Web Search Blocked Domains","name":"blockedDomains","type":"string","default":"","description":"Comma-separated list of domains to block from search. Conflicts with \"Web Search Allowed Domains\".","placeholder":"e.g. google.com, wikipedia.org"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":1024,"description":"The maximum number of tokens to generate in the completion","type":"number","typeOptions":{"minValue":1,"numberPrecision":0}},{"displayName":"Output Randomness (Temperature)","name":"temperature","default":1,"description":"Controls the randomness of the output. Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive","type":"number","typeOptions":{"minValue":0,"maxValue":1,"numberPrecision":1}},{"displayName":"Output Randomness (Top P)","name":"topP","default":0.7,"description":"The maximum cumulative probability of tokens to consider when sampling","type":"number","typeOptions":{"minValue":0,"maxValue":1,"numberPrecision":1}},{"displayName":"Output Randomness (Top K)","name":"topK","default":5,"description":"The maximum number of tokens to consider when sampling","type":"number","typeOptions":{"minValue":0,"numberPrecision":0}},{"displayName":"Max Tool Calls Iterations","name":"maxToolsIterations","type":"number","default":15,"description":"The maximum number of tool iteration cycles the LLM will run before stopping. A single iteration can contain multiple tool calls. Set to 0 for no limit","typeOptions":{"minValue":0,"numberPrecision":0}}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vendors/Anthropic/anthropic.svg"},
{"displayName":"Google Gemini","name":"googleGemini","group":["transform"],"version":1,"subtitle":"={{ $parameter[\"operation\"] + \": \" + $parameter[\"resource\"] }}","description":"Interact with Google Gemini AI models","defaults":{"name":"Google Gemini"},"usableAsTool":true,"codex":{"alias":["LangChain","video","document","audio","transcribe","assistant"],"categories":["AI"],"subcategories":{"AI":["Agents","Miscellaneous","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-langchain.googlegemini/"}]}},"inputs":"={{\n\t\t(() => {\n\t\t\tconst resource = $parameter.resource;\n\t  \tconst operation = $parameter.operation;\n\t\t\tif (resource === 'text' && operation === 'message') {\n\t\t\t\treturn [{ type: 'main' }, { type: 'ai_tool', displayName: 'Tools' }];\n\t\t\t}\n\n\t\t\treturn ['main'];\n\t\t})()\n\t}}","outputs":["main"],"credentials":[{"name":"googlePalmApi","required":true}],"properties":[{"displayName":"Resource","name":"resource","type":"options","noDataExpression":true,"options":[{"name":"Audio","value":"audio"},{"name":"Document","value":"document"},{"name":"File","value":"file"},{"name":"Image","value":"image"},{"name":"Text","value":"text"},{"name":"Video","value":"video"}],"default":"text"},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Analyze Audio","value":"analyze","action":"Analyze audio","description":"Take in audio and answer questions about it"},{"name":"Transcribe a Recording","value":"transcribe","action":"Transcribe a recording","description":"Transcribes audio into the text"}],"default":"transcribe","displayOptions":{"show":{"resource":["audio"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"audioModelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["audio"]}}},{"displayName":"Text Input","name":"text","type":"string","placeholder":"e.g. What's in this audio?","default":"What's in this audio?","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["analyze"],"resource":["audio"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Audio URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["audio"]}}},{"displayName":"URL(s)","name":"audioUrls","type":"string","placeholder":"e.g. https://example.com/audio.mp3","description":"URL(s) of the audio(s) to analyze, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["analyze"],"resource":["audio"]}}},{"displayName":"Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field(s) which contains the audio(s), seperate multiple field names with commas","displayOptions":{"show":{"inputType":["binary"],"operation":["analyze"],"resource":["audio"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["analyze"],"resource":["audio"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Length of Description (Max Tokens)","description":"Fewer tokens will result in shorter, less detailed audio description","name":"maxOutputTokens","type":"number","default":300,"typeOptions":{"minValue":1}}],"displayOptions":{"show":{"operation":["analyze"],"resource":["audio"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"audioModelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Audio URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"URL(s)","name":"audioUrls","type":"string","placeholder":"e.g. https://example.com/audio.mp3","description":"URL(s) of the audio(s) to transcribe, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field(s) which contains the audio(s), seperate multiple field names with commas","displayOptions":{"show":{"inputType":["binary"],"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"options":[{"displayName":"Start Time","name":"startTime","type":"string","default":"","description":"The start time of the audio in MM:SS or HH:MM:SS format","placeholder":"e.g. 00:15"},{"displayName":"End Time","name":"endTime","type":"string","default":"","description":"The end time of the audio in MM:SS or HH:MM:SS format","placeholder":"e.g. 02:15"}],"displayOptions":{"show":{"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Analyze Document","value":"analyze","action":"Analyze document","description":"Take in documents and answer questions about them"}],"default":"analyze","displayOptions":{"show":{"resource":["document"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Text Input","name":"text","type":"string","placeholder":"e.g. What's in this document?","default":"What's in this document?","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Document URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"URL(s)","name":"documentUrls","type":"string","placeholder":"e.g. https://example.com/document.pdf","description":"URL(s) of the document(s) to analyze, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["analyze"],"resource":["document"]}}},{"displayName":"Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field(s) which contains the document(s), seperate multiple field names with commas","displayOptions":{"show":{"inputType":["binary"],"operation":["analyze"],"resource":["document"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Length of Description (Max Tokens)","description":"Fewer tokens will result in shorter, less detailed document description","name":"maxOutputTokens","type":"number","default":300,"typeOptions":{"minValue":1}}],"displayOptions":{"show":{"operation":["analyze"],"resource":["document"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Upload File","value":"upload","action":"Upload a file","description":"Upload a file to the Google Gemini API for later use"}],"default":"upload","displayOptions":{"show":{"resource":["file"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"File URL","value":"url"},{"name":"Binary File","value":"binary"}],"displayOptions":{"show":{"operation":["upload"],"resource":["file"]}}},{"displayName":"URL","name":"fileUrl","type":"string","placeholder":"e.g. https://example.com/file.pdf","description":"URL of the file to upload","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["upload"],"resource":["file"]}}},{"displayName":"Input Data Field Name","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary property which contains the file","displayOptions":{"show":{"inputType":["binary"],"operation":["upload"],"resource":["file"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Analyze Image","value":"analyze","action":"Analyze an image","description":"Take in images and answer questions about them"},{"name":"Generate an Image","value":"generate","action":"Generate an image","description":"Creates an image from a text prompt"},{"name":"Edit Image","value":"edit","action":"Edit an image","description":"Upload one or more images and apply edits based on a prompt"}],"default":"generate","displayOptions":{"show":{"resource":["image"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Text Input","name":"text","type":"string","placeholder":"e.g. What's in this image?","default":"What's in this image?","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Image URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"URL(s)","name":"imageUrls","type":"string","placeholder":"e.g. https://example.com/image.png","description":"URL(s) of the image(s) to analyze, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["analyze"],"resource":["image"]}}},{"displayName":"Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field(s) which contains the image(s), separate multiple field names with commas","displayOptions":{"show":{"inputType":["binary"],"operation":["analyze"],"resource":["image"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Length of Description (Max Tokens)","description":"Fewer tokens will result in shorter, less detailed image description","name":"maxOutputTokens","type":"number","default":300,"typeOptions":{"minValue":1}}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Prompt","name":"prompt","type":"string","placeholder":"e.g. combine the first image with the second image","description":"Instruction describing how to edit the image","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["edit"],"resource":["image"]}}},{"displayName":"Images","name":"images","type":"fixedCollection","placeholder":"Add Image","typeOptions":{"multipleValues":true,"multipleValueButtonText":"Add Image"},"default":{"values":[{"binaryPropertyName":"data"}]},"description":"Add one or more binary fields to include images with your prompt","options":[{"displayName":"Image","name":"values","values":[{"displayName":"Binary Field Name","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","description":"The name of the binary field containing the image data"}]}],"displayOptions":{"show":{"operation":["edit"],"resource":["image"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Put Output in Field","name":"binaryPropertyOutput","type":"string","default":"edited","hint":"The name of the output field to put the binary file data in"}],"displayOptions":{"show":{"operation":["edit"],"resource":["image"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"imageGenerationModelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["generate"],"resource":["image"]}}},{"displayName":"Prompt","name":"prompt","type":"string","placeholder":"e.g. A cute cat eating a dinosaur","description":"A text description of the desired image(s)","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["generate"],"resource":["image"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Number of Images","name":"sampleCount","default":1,"description":"Number of images to generate. Not supported by Gemini models, supported by Imagen models.","type":"number","typeOptions":{"minValue":1}},{"displayName":"Put Output in Field","name":"binaryPropertyOutput","type":"string","default":"data","hint":"The name of the output field to put the binary file data in"}],"displayOptions":{"show":{"operation":["generate"],"resource":["image"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Message a Model","value":"message","action":"Message a model","description":"Create a completion with Google Gemini model"}],"default":"message","displayOptions":{"show":{"resource":["text"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Messages","name":"messages","type":"fixedCollection","typeOptions":{"sortable":true,"multipleValues":true},"placeholder":"Add Message","default":{"values":[{"content":""}]},"options":[{"displayName":"Values","name":"values","values":[{"displayName":"Prompt","name":"content","type":"string","description":"The content of the message to be send","default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2}},{"displayName":"Role","name":"role","type":"options","description":"Role in shaping the model's response, it tells the model how it should behave and interact with the user","options":[{"name":"User","value":"user","description":"Send a message as a user and get a response from the model"},{"name":"Model","value":"model","description":"Tell the model to adopt a specific tone or personality"}],"default":"user"}]}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Output Content as JSON","name":"jsonOutput","type":"boolean","description":"Whether to attempt to return the response in JSON format","default":false,"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"System Message","name":"systemMessage","type":"string","default":"","placeholder":"e.g. You are a helpful assistant"},{"displayName":"Code Execution","name":"codeExecution","type":"boolean","default":false,"description":"Whether to allow the model to execute code it generates to produce a response. Supported only by certain models."},{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number","typeOptions":{"minValue":-2,"maxValue":2,"numberPrecision":1}},{"displayName":"Maximum Number of Tokens","name":"maxOutputTokens","default":16,"description":"The maximum number of tokens to generate in the completion","type":"number","typeOptions":{"minValue":1,"numberPrecision":0}},{"displayName":"Number of Completions","name":"candidateCount","default":1,"description":"How many completions to generate for each prompt","type":"number","typeOptions":{"minValue":1,"maxValue":8,"numberPrecision":0}},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number","typeOptions":{"minValue":-2,"maxValue":2,"numberPrecision":1}},{"displayName":"Output Randomness (Temperature)","name":"temperature","default":1,"description":"Controls the randomness of the output. Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive","type":"number","typeOptions":{"minValue":0,"maxValue":2,"numberPrecision":1}},{"displayName":"Output Randomness (Top P)","name":"topP","default":1,"description":"The maximum cumulative probability of tokens to consider when sampling","type":"number","typeOptions":{"minValue":0,"maxValue":1,"numberPrecision":1}},{"displayName":"Output Randomness (Top K)","name":"topK","default":1,"description":"The maximum number of tokens to consider when sampling","type":"number","typeOptions":{"minValue":1,"numberPrecision":0}},{"displayName":"Thinking Budget","name":"thinkingBudget","type":"number","description":"Controls reasoning tokens for thinking models. Set to 0 to disable automatic thinking. Set to -1 for dynamic thinking. Leave empty for auto mode.","typeOptions":{"minValue":-1,"numberPrecision":0}},{"displayName":"Max Tool Calls Iterations","name":"maxToolsIterations","type":"number","default":15,"description":"The maximum number of tool iteration cycles the LLM will run before stopping. A single iteration can contain multiple tool calls. Set to 0 for no limit","typeOptions":{"minValue":0,"numberPrecision":0}}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Analyze Video","value":"analyze","action":"Analyze video","description":"Take in videos and answer questions about them"},{"name":"Generate a Video","value":"generate","action":"Generate a video","description":"Creates a video from a text prompt"},{"name":"Download Video","value":"download","action":"Download a video","description":"Download a generated video from the Google Gemini API using a URL"}],"default":"generate","displayOptions":{"show":{"resource":["video"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["video"]}}},{"displayName":"Text Input","name":"text","type":"string","placeholder":"e.g. What's in this video?","default":"What's in this video?","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["analyze"],"resource":["video"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Video URL(s)","value":"url"},{"name":"Binary File(s)","value":"binary"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["video"]}}},{"displayName":"URL(s)","name":"videoUrls","type":"string","placeholder":"e.g. https://example.com/video.mp4","description":"URL(s) of the video(s) to analyze, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["analyze"],"resource":["video"]}}},{"displayName":"Input Data Field Name(s)","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary field(s) which contains the video(s), seperate multiple field names with commas","displayOptions":{"show":{"inputType":["binary"],"operation":["analyze"],"resource":["video"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["analyze"],"resource":["video"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Length of Description (Max Tokens)","description":"Fewer tokens will result in shorter, less detailed video description","name":"maxOutputTokens","type":"number","default":300,"typeOptions":{"minValue":1}}],"displayOptions":{"show":{"operation":["analyze"],"resource":["video"]}}},{"displayName":"URL","name":"url","type":"string","placeholder":"e.g. https://generativelanguage.googleapis.com/v1beta/files/abcdefg:download","description":"The URL from Google Gemini API to download the video from","default":"","displayOptions":{"show":{"operation":["download"],"resource":["video"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Put Output in Field","name":"binaryPropertyOutput","type":"string","default":"data","hint":"The name of the output field to put the binary file data in"}],"displayOptions":{"show":{"operation":["download"],"resource":["video"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"videoGenerationModelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. models/gemini-2.5-flash"}],"displayOptions":{"show":{"operation":["generate"],"resource":["video"]}}},{"displayName":"Prompt","name":"prompt","type":"string","placeholder":"e.g. Panning wide shot of a calico kitten sleeping in the sunshine","description":"A text description of the desired video","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["generate"],"resource":["video"]}}},{"displayName":"Return As","name":"returnAs","type":"options","options":[{"name":"Video","value":"video"},{"name":"URL","value":"url"}],"description":"Whether to return the video as a binary file or a URL that can be used to download the video later","default":"video","displayOptions":{"show":{"operation":["generate"],"resource":["video"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Number of Videos","name":"sampleCount","type":"number","default":1,"description":"How many videos to generate","typeOptions":{"minValue":1,"maxValue":4}},{"displayName":"Duration (Seconds)","name":"durationSeconds","type":"number","default":8,"description":"Length of the generated video in seconds. Supported only by certain models.","typeOptions":{"minValue":5,"maxValue":8}},{"displayName":"Aspect Ratio","name":"aspectRatio","type":"options","options":[{"name":"Widescreen (16:9)","value":"16:9","description":"Most common aspect ratio for televisions and monitors"},{"name":"Portrait (9:16)","value":"9:16","description":"Popular for short-form videos like YouTube Shorts"}],"default":"16:9"},{"displayName":"Person Generation","name":"personGeneration","type":"options","options":[{"name":"Don't Allow","value":"dont_allow","description":"Prevent generation of people in the video"},{"name":"Allow Adult","value":"allow_adult","description":"Allow generation of adult people in the video"},{"name":"Allow All","value":"allow_all","description":"Allow generation of all people in the video"}],"default":"dont_allow"},{"displayName":"Put Output in Field","name":"binaryPropertyOutput","type":"string","default":"data","hint":"The name of the output field to put the binary file data in"}],"displayOptions":{"show":{"operation":["generate"],"resource":["video"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vendors/GoogleGemini/gemini.svg"},
{"displayName":"OpenAI","name":"openAi","group":["transform"],"version":[1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8],"subtitle":"={{((resource, operation) => {\n  if (operation === \"deleteAssistant\") {\n    return \"Delete Assistant\";\n  }\n  if (operation === \"deleteFile\") {\n    return \"Delete File\";\n  }\n  if (operation === \"classify\") {\n    return \"Classify Text\";\n  }\n  if (operation === \"message\" && resource === \"text\") {\n    return \"Message Model\";\n  }\n  const capitalize = (str) => {\n    const chars = str.split(\"\");\n    chars[0] = chars[0].toUpperCase();\n    return chars.join(\"\");\n  };\n  if ([\"transcribe\", \"translate\"].includes(operation)) {\n    resource = \"recording\";\n  }\n  if (operation === \"list\") {\n    resource = resource + \"s\";\n  }\n  return `${capitalize(operation)} ${capitalize(resource)}`;\n})($parameter.resource, $parameter.operation)}}","description":"Message an assistant or GPT, analyze images, generate audio, etc.","defaults":{"name":"OpenAI"},"codex":{"alias":["LangChain","ChatGPT","DallE","whisper","audio","transcribe","tts","assistant"],"categories":["AI"],"subcategories":{"AI":["Agents","Miscellaneous","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-langchain.openai/"}]}},"inputs":"={{((resource, operation, hideTools, memory) => {\n  if (resource === \"assistant\" && operation === \"message\") {\n    const inputs = [\n      { type: \"main\" },\n      { type: \"ai_tool\", displayName: \"Tools\" }\n    ];\n    if (memory !== \"threadId\") {\n      inputs.push({ type: \"ai_memory\", displayName: \"Memory\", maxConnections: 1 });\n    }\n    return inputs;\n  }\n  if (resource === \"text\" && operation === \"message\") {\n    if (hideTools === \"hide\") {\n      return [\"main\"];\n    }\n    return [{ type: \"main\" }, { type: \"ai_tool\", displayName: \"Tools\" }];\n  }\n  return [\"main\"];\n})($parameter.resource, $parameter.operation, $parameter.hideTools, $parameter.memory ?? undefined)}}","outputs":["main"],"credentials":[{"name":"openAiApi","required":true}],"properties":[{"displayName":"Resource","name":"resource","type":"options","noDataExpression":true,"options":[{"name":"Assistant","value":"assistant"},{"name":"Text","value":"text"},{"name":"Image","value":"image"},{"name":"Audio","value":"audio"},{"name":"File","value":"file"}],"default":"text"},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Create an Assistant","value":"create","action":"Create an assistant","description":"Create a new assistant"},{"name":"Delete an Assistant","value":"deleteAssistant","action":"Delete an assistant","description":"Delete an assistant from the account"},{"name":"List Assistants","value":"list","action":"List assistants","description":"List assistants in the organization"},{"name":"Message an Assistant","value":"message","action":"Message an assistant","description":"Send messages to an assistant"},{"name":"Update an Assistant","value":"update","action":"Update an assistant","description":"Update an existing assistant"}],"default":"message","displayOptions":{"show":{"resource":["assistant"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. gpt-4"}],"displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Name","name":"name","type":"string","default":"","description":"The name of the assistant. The maximum length is 256 characters.","placeholder":"e.g. My Assistant","required":true,"displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Description","name":"description","type":"string","default":"","description":"The description of the assistant. The maximum length is 512 characters.","placeholder":"e.g. My personal assistant","displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Instructions","name":"instructions","type":"string","description":"The system instructions that the assistant uses. The maximum length is 32768 characters.","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Code Interpreter","name":"codeInterpreter","type":"boolean","default":false,"description":"Whether to enable the code interpreter that allows the assistants to write and run Python code in a sandboxed execution environment, find more <a href=\"https://platform.openai.com/docs/assistants/tools/code-interpreter\" target=\"_blank\">here</a>","displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Knowledge Retrieval","name":"knowledgeRetrieval","type":"boolean","default":false,"description":"Whether to augments the assistant with knowledge from outside its model, such as proprietary product information or documents, find more <a href=\"https://platform.openai.com/docs/assistants/tools/knowledge-retrieval\" target=\"_blank\">here</a>","displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Files","name":"file_ids","type":"multiOptions","description":"The files to be used by the assistant, there can be a maximum of 20 files attached to the assistant. You can use expression to pass file IDs as an array or comma-separated string.","typeOptions":{"loadOptionsMethod":"getFiles"},"default":[],"hint":"Add more files by using the 'Upload a File' operation","displayOptions":{"show":{"codeInterpreter":[true],"operation":["create"],"resource":["assistant"]},"hide":{"knowledgeRetrieval":[true]}}},{"displayName":"Files","name":"file_ids","type":"multiOptions","description":"The files to be used by the assistant, there can be a maximum of 20 files attached to the assistant","typeOptions":{"loadOptionsMethod":"getFiles"},"default":[],"hint":"Add more files by using the 'Upload a File' operation","displayOptions":{"show":{"knowledgeRetrieval":[true],"operation":["create"],"resource":["assistant"]},"hide":{"codeInterpreter":[true]}}},{"displayName":"Files","name":"file_ids","type":"multiOptions","description":"The files to be used by the assistant, there can be a maximum of 20 files attached to the assistant","typeOptions":{"loadOptionsMethod":"getFiles"},"default":[],"hint":"Add more files by using the 'Upload a File' operation","displayOptions":{"show":{"knowledgeRetrieval":[true],"codeInterpreter":[true],"operation":["create"],"resource":["assistant"]}}},{"displayName":"Add custom n8n tools when you <i>message</i> your assistant (rather than when creating it)","name":"noticeTools","type":"notice","default":"","displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Output Randomness (Temperature)","name":"temperature","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Output Randomness (Top P)","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"An alternative to sampling with temperature, controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Fail if Assistant Already Exists","name":"failIfExists","type":"boolean","default":false,"description":"Whether to fail an operation if the assistant with the same name already exists"}],"displayOptions":{"show":{"operation":["create"],"resource":["assistant"]}}},{"displayName":"Assistant","name":"assistantId","type":"resourceLocator","description":"Assistant to respond to the message. You can add, modify or remove assistants in the <a href=\"https://platform.openai.com/playground?mode=assistant\" target=\"_blank\">playground</a>.","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"assistantSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. asst_abc123"}],"displayOptions":{"show":{"operation":["deleteAssistant"],"resource":["assistant"]}}},{"displayName":"Assistant","name":"assistantId","type":"resourceLocator","description":"Assistant to respond to the message. You can add, modify or remove assistants in the <a href=\"https://platform.openai.com/playground?mode=assistant\" target=\"_blank\">playground</a>.","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"assistantSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. asst_abc123"}],"displayOptions":{"show":{"operation":["message"],"resource":["assistant"]}}},{"displayName":"Source for Prompt (User Message)","name":"prompt","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"auto","description":"Looks for an input field called 'chatInput' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"define","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"auto","displayOptions":{"show":{"operation":["message"],"resource":["assistant"]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2},"displayOptions":{"show":{"prompt":["define"],"operation":["message"],"resource":["assistant"]}}},{"displayName":"Memory","name":"memory","type":"options","options":[{"name":"Use memory connector","value":"connector","description":"Connect one of the supported memory nodes"},{"name":"Use thread ID","value":"threadId","description":"Specify the ID of the thread to continue"}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.6}}],"operation":["message"],"resource":["assistant"]}},"default":"connector"},{"displayName":"Thread ID","name":"threadId","type":"string","default":"","placeholder":"","description":"The ID of the thread to continue, a new thread will be created if not specified","hint":"If the thread ID is empty or undefined a new thread will be created and included in the response","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.6}}],"memory":["threadId"],"operation":["message"],"resource":["assistant"]}}},{"displayName":"Connect your own custom n8n tools to this node on the canvas","name":"noticeTools","type":"notice","default":"","displayOptions":{"show":{"operation":["message"],"resource":["assistant"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Base URL","name":"baseURL","default":"https://api.openai.com/v1","description":"Override the default base URL for the API","type":"string","displayOptions":{"hide":{"@version":[{"_cnd":{"gte":1.8}}]}}},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Timeout","name":"timeout","default":10000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Preserve Original Tools","name":"preserveOriginalTools","type":"boolean","default":true,"description":"Whether to preserve the original tools of the assistant after the execution of this node, otherwise the tools will be replaced with the connected tools, if any, default is true","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.3}}]}}}],"displayOptions":{"show":{"operation":["message"],"resource":["assistant"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["list"],"resource":["assistant"]}}},{"displayName":"Assistant","name":"assistantId","type":"resourceLocator","description":"Assistant to respond to the message. You can add, modify or remove assistants in the <a href=\"https://platform.openai.com/playground?mode=assistant\" target=\"_blank\">playground</a>.","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"assistantSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. asst_abc123"}],"displayOptions":{"show":{"operation":["update"],"resource":["assistant"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Code Interpreter","name":"codeInterpreter","type":"boolean","default":false,"description":"Whether to enable the code interpreter that allows the assistants to write and run Python code in a sandboxed execution environment, find more <a href=\"https://platform.openai.com/docs/assistants/tools/code-interpreter\" target=\"_blank\">here</a>"},{"displayName":"Description","name":"description","type":"string","default":"","description":"The description of the assistant. The maximum length is 512 characters.","placeholder":"e.g. My personal assistant"},{"displayName":"Files","name":"file_ids","type":"multiOptions","description":"The files to be used by the assistant, there can be a maximum of 20 files attached to the assistant. You can use expression to pass file IDs as an array or comma-separated string.","typeOptions":{"loadOptionsMethod":"getFiles"},"default":[],"hint":"Add more files by using the 'Upload a File' operation, any existing files not selected here will be removed."},{"displayName":"Instructions","name":"instructions","type":"string","description":"The system instructions that the assistant uses. The maximum length is 32768 characters.","default":"","typeOptions":{"rows":2}},{"displayName":"Knowledge Retrieval","name":"knowledgeRetrieval","type":"boolean","default":false,"description":"Whether to augments the assistant with knowledge from outside its model, such as proprietary product information or documents, find more <a href=\"https://platform.openai.com/docs/assistants/tools/knowledge-retrieval\" target=\"_blank\">here</a>"},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":false,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. gpt-4"}]},{"displayName":"Name","name":"name","type":"string","default":"","description":"The name of the assistant. The maximum length is 256 characters.","placeholder":"e.g. My Assistant"},{"displayName":"Remove All Custom Tools (Functions)","name":"removeCustomTools","type":"boolean","default":false,"description":"Whether to remove all custom tools (functions) from the assistant"},{"displayName":"Output Randomness (Temperature)","name":"temperature","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Output Randomness (Top P)","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"An alternative to sampling with temperature, controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}],"displayOptions":{"show":{"operation":["update"],"resource":["assistant"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Generate Audio","value":"generate","action":"Generate audio","description":"Creates audio from a text prompt"},{"name":"Transcribe a Recording","value":"transcribe","action":"Transcribe a recording","description":"Transcribes audio into the text"},{"name":"Translate a Recording","value":"translate","action":"Translate a recording","description":"Translate audio into the text in the english language"}],"default":"generate","displayOptions":{"show":{"resource":["audio"]}}},{"displayName":"OpenAI API limits the size of the audio file to 25 MB","name":"fileSizeLimitNotice","type":"notice","default":" ","displayOptions":{"show":{"resource":["audio"],"operation":["translate","transcribe"]}}},{"displayName":"Model","name":"model","type":"options","default":"tts-1","options":[{"name":"TTS-1","value":"tts-1"},{"name":"TTS-1-HD","value":"tts-1-hd"}],"displayOptions":{"show":{"operation":["generate"],"resource":["audio"]}}},{"displayName":"Text Input","name":"input","type":"string","placeholder":"e.g. The quick brown fox jumped over the lazy dog","description":"The text to generate audio for. The maximum length is 4096 characters.","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["generate"],"resource":["audio"]}}},{"displayName":"Voice","name":"voice","type":"options","default":"alloy","description":"The voice to use when generating the audio","options":[{"name":"Alloy","value":"alloy"},{"name":"Echo","value":"echo"},{"name":"Fable","value":"fable"},{"name":"Nova","value":"nova"},{"name":"Onyx","value":"onyx"},{"name":"Shimmer","value":"shimmer"}],"displayOptions":{"show":{"operation":["generate"],"resource":["audio"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Response Format","name":"response_format","type":"options","default":"mp3","options":[{"name":"MP3","value":"mp3"},{"name":"OPUS","value":"opus"},{"name":"AAC","value":"aac"},{"name":"FLAC","value":"flac"}]},{"displayName":"Audio Speed","name":"speed","type":"number","default":1,"typeOptions":{"minValue":0.25,"maxValue":4,"numberPrecision":1}},{"displayName":"Put Output in Field","name":"binaryPropertyOutput","type":"string","default":"data","hint":"The name of the output field to put the binary file data in"}],"displayOptions":{"show":{"operation":["generate"],"resource":["audio"]}}},{"displayName":"Input Data Field Name","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary property which contains the audio file in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm","displayOptions":{"show":{"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Language of the Audio File","name":"language","type":"string","description":"The language of the input audio. Supplying the input language in <a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes\" target=\"_blank\">ISO-639-1</a> format will improve accuracy and latency.","default":""},{"displayName":"Output Randomness (Temperature)","name":"temperature","type":"number","default":0,"typeOptions":{"minValue":0,"maxValue":1,"numberPrecision":1}}],"displayOptions":{"show":{"operation":["transcribe"],"resource":["audio"]}}},{"displayName":"Input Data Field Name","name":"binaryPropertyName","type":"string","default":"data","hint":"The name of the input field containing the binary file data to be processed","placeholder":"e.g. data","description":"Name of the binary property which contains the audio file in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm","displayOptions":{"show":{"operation":["translate"],"resource":["audio"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Output Randomness (Temperature)","name":"temperature","type":"number","default":0,"typeOptions":{"minValue":0,"maxValue":1,"numberPrecision":1}}],"displayOptions":{"show":{"operation":["translate"],"resource":["audio"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Delete a File","value":"deleteFile","action":"Delete a file","description":"Delete a file from the server"},{"name":"List Files","value":"list","action":"List files","description":"Returns a list of files that belong to the user's organization"},{"name":"Upload a File","value":"upload","action":"Upload a file","description":"Upload a file that can be used across various endpoints"}],"default":"upload","displayOptions":{"show":{"resource":["file"]}}},{"displayName":"Input Data Field Name","name":"binaryPropertyName","type":"string","default":"data","hint":"The name of the input field containing the binary file data to be processed","placeholder":"e.g. data","description":"Name of the binary property which contains the file. The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants.","displayOptions":{"show":{"operation":["upload"],"resource":["file"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Purpose","name":"purpose","type":"options","default":"assistants","description":"The intended purpose of the uploaded file, the 'Fine-tuning' only supports .jsonl files","options":[{"name":"Assistants","value":"assistants"},{"name":"Fine-Tune","value":"fine-tune"}]}],"displayOptions":{"show":{"operation":["upload"],"resource":["file"]}}},{"displayName":"File","name":"fileId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"fileSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","validation":[{"type":"regex","properties":{"regex":"file-[a-zA-Z0-9]","errorMessage":"Not a valid File ID"}}],"placeholder":"e.g. file-1234567890"}],"displayOptions":{"show":{"operation":["deleteFile"],"resource":["file"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Purpose","name":"purpose","type":"options","default":"any","description":"Only return files with the given purpose","options":[{"name":"Any [Default]","value":"any"},{"name":"Assistants","value":"assistants"},{"name":"Fine-Tune","value":"fine-tune"}]}],"displayOptions":{"show":{"operation":["list"],"resource":["file"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Analyze Image","value":"analyze","action":"Analyze image","description":"Take in images and answer questions about them"},{"name":"Generate an Image","value":"generate","action":"Generate an image","description":"Creates an image from a text prompt"}],"default":"generate","displayOptions":{"show":{"resource":["image"]}}},{"displayName":"Model","name":"model","type":"options","default":"dall-e-3","description":"The model to use for image generation","options":[{"name":"DALLE 2","value":"dall-e-2"},{"name":"DALLE 3","value":"dall-e-3"},{"name":"GPT Image 1","value":"gpt-image-1"}],"displayOptions":{"show":{"operation":["generate"],"resource":["image"]}}},{"displayName":"Prompt","name":"prompt","type":"string","placeholder":"e.g. A cute cat eating a dinosaur","description":"A text description of the desired image(s). The maximum length is 1000 characters for dall-e-2 and 4000 characters for dall-e-3.","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["generate"],"resource":["image"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Number of Images","name":"n","default":1,"description":"Number of images to generate","type":"number","typeOptions":{"minValue":1,"maxValue":10},"displayOptions":{"show":{"/model":["dall-e-2"]}}},{"displayName":"Quality","name":"dalleQuality","type":"options","description":"The quality of the image that will be generated, HD creates images with finer details and greater consistency across the image","options":[{"name":"HD","value":"hd"},{"name":"Standard","value":"standard"}],"displayOptions":{"show":{"/model":["dall-e-3"]}},"default":"standard"},{"displayName":"Quality","name":"quality","type":"options","description":"The quality of the image that will be generated, High creates images with finer details and greater consistency across the image","options":[{"name":"High","value":"high"},{"name":"Medium","value":"medium"},{"name":"Low","value":"low"}],"displayOptions":{"show":{"/model":["gpt-image-1"]}},"default":"medium"},{"displayName":"Resolution","name":"size","type":"options","options":[{"name":"256x256","value":"256x256"},{"name":"512x512","value":"512x512"},{"name":"1024x1024","value":"1024x1024"}],"displayOptions":{"show":{"/model":["dall-e-2"]}},"default":"1024x1024"},{"displayName":"Resolution","name":"size","type":"options","options":[{"name":"1024x1024","value":"1024x1024"},{"name":"1792x1024","value":"1792x1024"},{"name":"1024x1792","value":"1024x1792"}],"displayOptions":{"show":{"/model":["dall-e-3"]}},"default":"1024x1024"},{"displayName":"Resolution","name":"size","type":"options","options":[{"name":"1024x1024","value":"1024x1024"},{"name":"1024x1536","value":"1024x1536"},{"name":"1536x1024","value":"1536x1024"}],"displayOptions":{"show":{"/model":["gpt-image-1"]}},"default":"1024x1024"},{"displayName":"Style","name":"style","type":"options","options":[{"name":"Natural","value":"natural","description":"Produce more natural looking images"},{"name":"Vivid","value":"vivid","description":"Lean towards generating hyper-real and dramatic images"}],"displayOptions":{"show":{"/model":["dall-e-3"]}},"default":"vivid"},{"displayName":"Respond with Image URL(s)","name":"returnImageUrls","type":"boolean","default":false,"description":"Whether to return image URL(s) instead of binary file(s)","displayOptions":{"hide":{"/model":["gpt-image-1"]}}},{"displayName":"Put Output in Field","name":"binaryPropertyOutput","type":"string","default":"data","hint":"The name of the output field to put the binary file data in","displayOptions":{"show":{"returnImageUrls":[false]}}}],"displayOptions":{"show":{"operation":["generate"],"resource":["image"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"imageModelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. gpt-4"}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.4}}],"operation":["analyze"],"resource":["image"]}}},{"displayName":"Text Input","name":"text","type":"string","placeholder":"e.g. What's in this image?","default":"What's in this image?","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Input Type","name":"inputType","type":"options","default":"url","options":[{"name":"Image URL(s)","value":"url"},{"name":"Binary File(s)","value":"base64"}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"URL(s)","name":"imageUrls","type":"string","placeholder":"e.g. https://example.com/image.jpeg","description":"URL(s) of the image(s) to analyze, multiple URLs can be added separated by comma","default":"","displayOptions":{"show":{"inputType":["url"],"operation":["analyze"],"resource":["image"]}}},{"displayName":"Input Data Field Name","name":"binaryPropertyName","type":"string","default":"data","placeholder":"e.g. data","hint":"The name of the input field containing the binary file data to be processed","description":"Name of the binary property which contains the image(s)","displayOptions":{"show":{"inputType":["base64"],"operation":["analyze"],"resource":["image"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to simplify the response or not","displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Detail","name":"detail","type":"options","default":"auto","options":[{"name":"Auto","value":"auto","description":"Model will look at the image input size and decide if it should use the low or high setting"},{"name":"Low","value":"low","description":"Return faster responses and consume fewer tokens"},{"name":"High","value":"high","description":"Return more detailed responses, consumes more tokens"}]},{"displayName":"Length of Description (Max Tokens)","description":"Fewer tokens will result in shorter, less detailed image description","name":"maxTokens","type":"number","default":300,"typeOptions":{"minValue":1}}],"displayOptions":{"show":{"operation":["analyze"],"resource":["image"]}}},{"displayName":"Operation","name":"operation","type":"options","noDataExpression":true,"options":[{"name":"Message a Model","value":"message","action":"Message a model","description":"Create a completion with GPT 3, 4, etc."},{"name":"Classify Text for Violations","value":"classify","action":"Classify text for violations","description":"Check whether content complies with usage policies"}],"default":"message","displayOptions":{"show":{"resource":["text"]}}},{"displayName":"Text Input","name":"input","type":"string","placeholder":"e.g. Sample text goes here","description":"The input text to classify if it is violates the moderation policy","default":"","typeOptions":{"rows":2},"displayOptions":{"show":{"operation":["classify"],"resource":["text"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":false,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["classify"],"resource":["text"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Use Stable Model","name":"useStableModel","type":"boolean","default":false,"description":"Whether to use the stable version of the model instead of the latest version, accuracy may be slightly lower"}],"displayOptions":{"show":{"operation":["classify"],"resource":["text"]}}},{"displayName":"Model","name":"modelId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"modelSearch","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"e.g. gpt-4"}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Messages","name":"messages","type":"fixedCollection","typeOptions":{"sortable":true,"multipleValues":true},"placeholder":"Add Message","default":{"values":[{"content":""}]},"options":[{"displayName":"Values","name":"values","values":[{"displayName":"Prompt","name":"content","type":"string","description":"The content of the message to be send","default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2}},{"displayName":"Role","name":"role","type":"options","description":"Role in shaping the model's response, it tells the model how it should behave and interact with the user","options":[{"name":"User","value":"user","description":"Send a message as a user and get a response from the model"},{"name":"Assistant","value":"assistant","description":"Tell the model to adopt a specific tone or personality"},{"name":"System","value":"system","description":"Usually used to set the model's behavior or context for the next user message"}],"default":"user"}]}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Simplify Output","name":"simplify","type":"boolean","default":true,"description":"Whether to return a simplified version of the response instead of the raw data","displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Output Content as JSON","name":"jsonOutput","type":"boolean","description":"Whether to attempt to return the response in JSON format. Compatible with GPT-4 Turbo and all GPT-3.5 Turbo models newer than gpt-3.5-turbo-1106.","default":false,"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Hide Tools","name":"hideTools","type":"hidden","default":"hide","displayOptions":{"show":{"modelId":["gpt-3.5-turbo-16k-0613","dall-e-3","text-embedding-3-large","dall-e-2","whisper-1","tts-1-hd-1106","tts-1-hd","gpt-4-0314","text-embedding-3-small","gpt-4-32k-0314","gpt-3.5-turbo-0301","gpt-4-vision-preview","gpt-3.5-turbo-16k","gpt-3.5-turbo-instruct-0914","tts-1","davinci-002","gpt-3.5-turbo-instruct","babbage-002","tts-1-1106","text-embedding-ada-002"],"@version":[{"_cnd":{"gte":1.2}}],"operation":["message"],"resource":["text"]}}},{"displayName":"Connect your own custom n8n tools to this node on the canvas","name":"noticeTools","type":"notice","default":"","displayOptions":{"hide":{"hideTools":["hide"]},"show":{"operation":["message"],"resource":["text"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Frequency Penalty","name":"frequency_penalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":16,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Number of Completions","name":"n","default":1,"description":"How many completions to generate for each prompt. Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.","type":"number"},{"displayName":"Presence Penalty","name":"presence_penalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Output Randomness (Temperature)","name":"temperature","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Output Randomness (Top P)","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"An alternative to sampling with temperature, controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Reasoning Effort","name":"reasoning_effort","default":"medium","description":"Controls the amount of reasoning tokens to use. A value of \"low\" will favor speed and economical token usage, \"high\" will favor more complete reasoning at the cost of more tokens generated and slower responses.","type":"options","options":[{"name":"Low","value":"low","description":"Favors speed and economical token usage"},{"name":"Medium","value":"medium","description":"Balance between speed and reasoning accuracy"},{"name":"High","value":"high","description":"Favors more complete reasoning at the cost of more tokens generated and slower responses"}],"displayOptions":{"show":{"/modelId":[{"_cnd":{"regex":"(^o1([-\\d]+)?$)|(^o[3-9].*)|(^gpt-5.*)"}}]}}},{"displayName":"Max Tool Calls Iterations","name":"maxToolsIterations","type":"number","default":15,"description":"The maximum number of tool iteration cycles the LLM will run before stopping. A single iteration can contain multiple tool calls. Set to 0 for no limit.","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.5}}]}}}],"displayOptions":{"show":{"operation":["message"],"resource":["text"]}}}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vendors/OpenAi/openAi.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vendors/OpenAi/openAi.dark.svg"}},
{"displayName":"AI Agent","name":"agent","icon":"fa:robot","iconColor":"black","group":["transform"],"description":"Generates an action plan and executes it. Can use external tools.","codex":{"alias":["LangChain","Chat","Conversational","Plan and Execute","ReAct","Tools"],"categories":["AI"],"subcategories":{"AI":["Agents","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"}]}},"defaultVersion":2.2,"version":[2,2.1,2.2],"defaults":{"name":"AI Agent","color":"#404040"},"inputs":"={{\n\t\t\t\t((hasOutputParser, needsFallback) => {\n\t\t\t\t\tfunction getInputs(hasMainInput, hasOutputParser, needsFallback) {\n  const getInputData = (inputs) => {\n    return inputs.map(({ type, filter, displayName, required }) => {\n      const input = {\n        type,\n        displayName,\n        required,\n        maxConnections: [\"ai_languageModel\", \"ai_memory\", \"ai_outputParser\"].includes(type) ? 1 : void 0\n      };\n      if (filter) {\n        input.filter = filter;\n      }\n      return input;\n    });\n  };\n  let specialInputs = [\n    {\n      type: \"ai_languageModel\",\n      displayName: \"Chat Model\",\n      required: true,\n      filter: {\n        excludedNodes: [\n          \"@n8n/n8n-nodes-langchain.lmCohere\",\n          \"@n8n/n8n-nodes-langchain.lmOllama\",\n          \"n8n/n8n-nodes-langchain.lmOpenAi\",\n          \"@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference\"\n        ]\n      }\n    },\n    {\n      type: \"ai_languageModel\",\n      displayName: \"Fallback Model\",\n      required: true,\n      filter: {\n        excludedNodes: [\n          \"@n8n/n8n-nodes-langchain.lmCohere\",\n          \"@n8n/n8n-nodes-langchain.lmOllama\",\n          \"n8n/n8n-nodes-langchain.lmOpenAi\",\n          \"@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference\"\n        ]\n      }\n    },\n    {\n      displayName: \"Memory\",\n      type: \"ai_memory\"\n    },\n    {\n      displayName: \"Tool\",\n      type: \"ai_tool\"\n    },\n    {\n      displayName: \"Output Parser\",\n      type: \"ai_outputParser\"\n    }\n  ];\n  if (hasOutputParser === false) {\n    specialInputs = specialInputs.filter((input) => input.type !== \"ai_outputParser\");\n  }\n  if (needsFallback === false) {\n    specialInputs = specialInputs.filter((input) => input.displayName !== \"Fallback Model\");\n  }\n  const mainInputs = hasMainInput ? [\"main\"] : [];\n  return [...mainInputs, ...getInputData(specialInputs)];\n};\n\t\t\t\t\treturn getInputs(true, hasOutputParser, needsFallback);\n\t\t\t\t})($parameter.hasOutputParser === undefined || $parameter.hasOutputParser === true, $parameter.needsFallback !== undefined && $parameter.needsFallback === true)\n\t\t\t}}","outputs":["main"],"properties":[{"displayName":"Tip: Get a feel for agents with our quick <a href=\"https://docs.n8n.io/advanced-ai/intro-tutorial/\" target=\"_blank\">tutorial</a> or see an <a href=\"/workflows/templates/1954\" target=\"_blank\">example</a> of how this node works","name":"aiAgentStarterCallout","type":"callout","default":""},{"displayName":"Get started faster with our","name":"preBuiltAgentsCallout","type":"callout","typeOptions":{"calloutAction":{"label":"pre-built agents","icon":"bot","type":"openPreBuiltAgentsCollection"}},"default":""},{"displayName":"Source for Prompt (User Message)","name":"promptType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"auto","description":"Looks for an input field called 'chatInput' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"define","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"auto"},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"={{ $json.chatInput }}","typeOptions":{"rows":2},"disabledOptions":{"show":{"promptType":["auto"]}},"displayOptions":{"show":{"promptType":["auto"]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2},"displayOptions":{"show":{"promptType":["define"]}}},{"displayName":"Require Specific Output Format","name":"hasOutputParser","type":"boolean","default":false,"noDataExpression":true},{"displayName":"Connect an <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_outputParser'>output parser</a> on the canvas to specify the output format you require","name":"notice","type":"notice","default":"","displayOptions":{"show":{"hasOutputParser":[true]}}},{"displayName":"Enable Fallback Model","name":"needsFallback","type":"boolean","default":false,"noDataExpression":true,"displayOptions":{"show":{"@version":[{"_cnd":{"gte":2.1}}]}}},{"displayName":"Connect an additional language model on the canvas to use it as a fallback if the main model fails","name":"fallbackNotice","type":"notice","default":"","displayOptions":{"show":{"needsFallback":[true]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"System Message","name":"systemMessage","type":"string","default":"You are a helpful assistant","description":"The message that will be sent to the agent before the conversation starts","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"},{"displayName":"Automatically Passthrough Binary Images","name":"passthroughBinaryImages","type":"boolean","default":true,"description":"Whether or not binary images should be automatically passed through to the agent as image type messages"},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":1,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}]},{"displayName":"Enable Streaming","name":"enableStreaming","type":"boolean","default":true,"description":"Whether this agent will stream the response in real-time as it generates text"}],"displayOptions":{"hide":{"@version":[{"_cnd":{"lt":2.2}}]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"System Message","name":"systemMessage","type":"string","default":"You are a helpful assistant","description":"The message that will be sent to the agent before the conversation starts","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"},{"displayName":"Automatically Passthrough Binary Images","name":"passthroughBinaryImages","type":"boolean","default":true,"description":"Whether or not binary images should be automatically passed through to the agent as image type messages"},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":1,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}]}],"displayOptions":{"show":{"@version":[{"_cnd":{"lt":2.2}}]}}}],"hints":[{"message":"You are using streaming responses. Make sure to set the response mode to \"Streaming Response\" on the connected trigger node.","type":"warning","location":"outputPane","whenToDisplay":"afterExecution","displayCondition":"={{ $parameter[\"enableStreaming\"] === true }}"}]},
{"version":[1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9],"displayName":"AI Agent","name":"agent","icon":"fa:robot","iconColor":"black","group":["transform"],"description":"Generates an action plan and executes it. Can use external tools.","codex":{"alias":["LangChain","Chat","Conversational","Plan and Execute","ReAct","Tools"],"categories":["AI"],"subcategories":{"AI":["Agents","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"}]}},"defaultVersion":2.2,"defaults":{"name":"AI Agent","color":"#404040"},"inputs":"={{\n\t\t\t\t((agent, hasOutputParser) => {\n\t\t\t\t\tfunction getInputs(agent, hasOutputParser) {\n  const getInputData = (inputs) => {\n    const displayNames = {\n      ai_languageModel: \"Model\",\n      ai_memory: \"Memory\",\n      ai_tool: \"Tool\",\n      ai_outputParser: \"Output Parser\"\n    };\n    return inputs.map(({ type, filter }) => {\n      const isModelType = type === \"ai_languageModel\";\n      let displayName = type in displayNames ? displayNames[type] : void 0;\n      if (isModelType && [\"openAiFunctionsAgent\", \"toolsAgent\", \"conversationalAgent\"].includes(agent)) {\n        displayName = \"Chat Model\";\n      }\n      const input = {\n        type,\n        displayName,\n        required: isModelType,\n        maxConnections: [\"ai_languageModel\", \"ai_memory\", \"ai_outputParser\"].includes(type) ? 1 : void 0\n      };\n      if (filter) {\n        input.filter = filter;\n      }\n      return input;\n    });\n  };\n  let specialInputs = [];\n  if (agent === \"conversationalAgent\") {\n    specialInputs = [\n      {\n        type: \"ai_languageModel\",\n        filter: {\n          nodes: [\n            \"@n8n/n8n-nodes-langchain.lmChatAnthropic\",\n            \"@n8n/n8n-nodes-langchain.lmChatAwsBedrock\",\n            \"@n8n/n8n-nodes-langchain.lmChatGroq\",\n            \"@n8n/n8n-nodes-langchain.lmChatOllama\",\n            \"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\n            \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n            \"@n8n/n8n-nodes-langchain.lmChatGoogleVertex\",\n            \"@n8n/n8n-nodes-langchain.lmChatMistralCloud\",\n            \"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi\",\n            \"@n8n/n8n-nodes-langchain.lmChatDeepSeek\",\n            \"@n8n/n8n-nodes-langchain.lmChatOpenRouter\",\n            \"@n8n/n8n-nodes-langchain.lmChatVercelAiGateway\",\n            \"@n8n/n8n-nodes-langchain.lmChatXAiGrok\",\n            \"@n8n/n8n-nodes-langchain.modelSelector\"\n          ]\n        }\n      },\n      {\n        type: \"ai_memory\"\n      },\n      {\n        type: \"ai_tool\"\n      },\n      {\n        type: \"ai_outputParser\"\n      }\n    ];\n  } else if (agent === \"toolsAgent\") {\n    specialInputs = [\n      {\n        type: \"ai_languageModel\",\n        filter: {\n          nodes: [\n            \"@n8n/n8n-nodes-langchain.lmChatAnthropic\",\n            \"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi\",\n            \"@n8n/n8n-nodes-langchain.lmChatAwsBedrock\",\n            \"@n8n/n8n-nodes-langchain.lmChatMistralCloud\",\n            \"@n8n/n8n-nodes-langchain.lmChatOllama\",\n            \"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\n            \"@n8n/n8n-nodes-langchain.lmChatGroq\",\n            \"@n8n/n8n-nodes-langchain.lmChatGoogleVertex\",\n            \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n            \"@n8n/n8n-nodes-langchain.lmChatDeepSeek\",\n            \"@n8n/n8n-nodes-langchain.lmChatOpenRouter\",\n            \"@n8n/n8n-nodes-langchain.lmChatVercelAiGateway\",\n            \"@n8n/n8n-nodes-langchain.lmChatXAiGrok\"\n          ]\n        }\n      },\n      {\n        type: \"ai_memory\"\n      },\n      {\n        type: \"ai_tool\",\n        required: true\n      },\n      {\n        type: \"ai_outputParser\"\n      }\n    ];\n  } else if (agent === \"openAiFunctionsAgent\") {\n    specialInputs = [\n      {\n        type: \"ai_languageModel\",\n        filter: {\n          nodes: [\n            \"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\n            \"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi\"\n          ]\n        }\n      },\n      {\n        type: \"ai_memory\"\n      },\n      {\n        type: \"ai_tool\",\n        required: true\n      },\n      {\n        type: \"ai_outputParser\"\n      }\n    ];\n  } else if (agent === \"reActAgent\") {\n    specialInputs = [\n      {\n        type: \"ai_languageModel\"\n      },\n      {\n        type: \"ai_tool\"\n      },\n      {\n        type: \"ai_outputParser\"\n      }\n    ];\n  } else if (agent === \"sqlAgent\") {\n    specialInputs = [\n      {\n        type: \"ai_languageModel\"\n      },\n      {\n        type: \"ai_memory\"\n      }\n    ];\n  } else if (agent === \"planAndExecuteAgent\") {\n    specialInputs = [\n      {\n        type: \"ai_languageModel\"\n      },\n      {\n        type: \"ai_tool\"\n      },\n      {\n        type: \"ai_outputParser\"\n      }\n    ];\n  }\n  if (hasOutputParser === false) {\n    specialInputs = specialInputs.filter((input) => input.type !== \"ai_outputParser\");\n  }\n  return [\"main\", ...getInputData(specialInputs)];\n};\n\t\t\t\t\treturn getInputs(agent, hasOutputParser)\n\t\t\t\t})($parameter.agent, $parameter.hasOutputParser === undefined || $parameter.hasOutputParser === true)\n\t\t\t}}","outputs":["main"],"credentials":[{"name":"mySql","required":true,"testedBy":"mysqlConnectionTest","displayOptions":{"show":{"agent":["sqlAgent"],"/dataSource":["mysql"]}}},{"name":"postgres","required":true,"displayOptions":{"show":{"agent":["sqlAgent"],"/dataSource":["postgres"]}}}],"properties":[{"displayName":"Tip: Get a feel for agents with our quick <a href=\"https://docs.n8n.io/advanced-ai/intro-tutorial/\" target=\"_blank\">tutorial</a> or see an <a href=\"/templates/1954\" target=\"_blank\">example</a> of how this node works","name":"aiAgentStarterCallout","type":"callout","default":"","displayOptions":{"show":{"agent":["conversationalAgent","toolsAgent"]}}},{"displayName":"Get started faster with our","name":"preBuiltAgentsCallout","type":"callout","typeOptions":{"calloutAction":{"label":"pre-built agents","icon":"bot","type":"openPreBuiltAgentsCollection"}},"default":""},{"displayName":"This node is using Agent that has been deprecated. Please switch to using 'Tools Agent' instead.","name":"deprecated","type":"notice","default":"","displayOptions":{"show":{"agent":["conversationalAgent","openAiFunctionsAgent","planAndExecuteAgent","reActAgent","sqlAgent"]}}},{"displayName":"Agent","name":"agent","type":"options","noDataExpression":true,"options":[{"name":"Conversational Agent","value":"conversationalAgent","description":"Describes tools in the system prompt and parses JSON responses for tool calls. More flexible but potentially less reliable than the Tools Agent. Suitable for simpler interactions or with models not supporting structured schemas."},{"name":"OpenAI Functions Agent","value":"openAiFunctionsAgent","description":"Leverages OpenAI's function calling capabilities to precisely select and execute tools. Excellent for tasks requiring structured outputs when working with OpenAI models."},{"name":"Plan and Execute Agent","value":"planAndExecuteAgent","description":"Creates a high-level plan for complex tasks and then executes each step. Suitable for multi-stage problems or when a strategic approach is needed."},{"name":"ReAct Agent","value":"reActAgent","description":"Combines reasoning and action in an iterative process. Effective for tasks that require careful analysis and step-by-step problem-solving."},{"name":"SQL Agent","value":"sqlAgent","description":"Specializes in interacting with SQL databases. Ideal for data analysis tasks, generating queries, or extracting insights from structured data."}],"default":"conversationalAgent","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.5}}]}}},{"displayName":"Agent","name":"agent","type":"options","noDataExpression":true,"options":[{"name":"Tools Agent","value":"toolsAgent","description":"Utilizes structured tool schemas for precise and reliable tool selection and execution. Recommended for complex tasks requiring accurate and consistent tool usage, but only usable with models that support tool calling."},{"name":"Conversational Agent","value":"conversationalAgent","description":"Describes tools in the system prompt and parses JSON responses for tool calls. More flexible but potentially less reliable than the Tools Agent. Suitable for simpler interactions or with models not supporting structured schemas."},{"name":"OpenAI Functions Agent","value":"openAiFunctionsAgent","description":"Leverages OpenAI's function calling capabilities to precisely select and execute tools. Excellent for tasks requiring structured outputs when working with OpenAI models."},{"name":"Plan and Execute Agent","value":"planAndExecuteAgent","description":"Creates a high-level plan for complex tasks and then executes each step. Suitable for multi-stage problems or when a strategic approach is needed."},{"name":"ReAct Agent","value":"reActAgent","description":"Combines reasoning and action in an iterative process. Effective for tasks that require careful analysis and step-by-step problem-solving."},{"name":"SQL Agent","value":"sqlAgent","description":"Specializes in interacting with SQL databases. Ideal for data analysis tasks, generating queries, or extracting insights from structured data."}],"default":"toolsAgent","displayOptions":{"show":{"@version":[{"_cnd":{"between":{"from":1.6,"to":1.7}}}]}}},{"displayName":"Agent","name":"agent","type":"hidden","noDataExpression":true,"options":[{"name":"Tools Agent","value":"toolsAgent","description":"Utilizes structured tool schemas for precise and reliable tool selection and execution. Recommended for complex tasks requiring accurate and consistent tool usage, but only usable with models that support tool calling."},{"name":"Conversational Agent","value":"conversationalAgent","description":"Describes tools in the system prompt and parses JSON responses for tool calls. More flexible but potentially less reliable than the Tools Agent. Suitable for simpler interactions or with models not supporting structured schemas."},{"name":"OpenAI Functions Agent","value":"openAiFunctionsAgent","description":"Leverages OpenAI's function calling capabilities to precisely select and execute tools. Excellent for tasks requiring structured outputs when working with OpenAI models."},{"name":"Plan and Execute Agent","value":"planAndExecuteAgent","description":"Creates a high-level plan for complex tasks and then executes each step. Suitable for multi-stage problems or when a strategic approach is needed."},{"name":"ReAct Agent","value":"reActAgent","description":"Combines reasoning and action in an iterative process. Effective for tasks that require careful analysis and step-by-step problem-solving."},{"name":"SQL Agent","value":"sqlAgent","description":"Specializes in interacting with SQL databases. Ideal for data analysis tasks, generating queries, or extracting insights from structured data."}],"default":"toolsAgent","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.8}}]}}},{"displayName":"Source for Prompt (User Message)","name":"promptType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"auto","description":"Looks for an input field called 'chatInput' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"define","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"auto","displayOptions":{"hide":{"@version":[{"_cnd":{"lte":1.2}}],"agent":["sqlAgent"]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"={{ $json.chatInput }}","typeOptions":{"rows":2},"disabledOptions":{"show":{"promptType":["auto"]}},"displayOptions":{"show":{"promptType":["auto"],"@version":[{"_cnd":{"gte":1.7}}]},"hide":{"agent":["sqlAgent"]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2},"displayOptions":{"show":{"promptType":["define"]},"hide":{"agent":["sqlAgent"]}}},{"displayName":"For more reliable structured output parsing, consider using the Tools agent","name":"notice","type":"notice","default":"","displayOptions":{"show":{"hasOutputParser":[true],"agent":["conversationalAgent","reActAgent","planAndExecuteAgent","openAiFunctionsAgent"]}}},{"displayName":"Require Specific Output Format","name":"hasOutputParser","type":"boolean","default":false,"noDataExpression":true,"displayOptions":{"hide":{"@version":[{"_cnd":{"lte":1.2}}],"agent":["sqlAgent"]}}},{"displayName":"Connect an <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_outputParser'>output parser</a> on the canvas to specify the output format you require","name":"notice","type":"notice","default":"","displayOptions":{"show":{"hasOutputParser":[true],"agent":["toolsAgent"]}}},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"agent":["toolsAgent"]}},"default":{},"placeholder":"Add Option","options":[{"displayName":"System Message","name":"systemMessage","type":"string","default":"You are a helpful assistant","description":"The message that will be sent to the agent before the conversation starts","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"},{"displayName":"Automatically Passthrough Binary Images","name":"passthroughBinaryImages","type":"boolean","default":true,"description":"Whether or not binary images should be automatically passed through to the agent as image type messages"}]},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["conversationalAgent"],"@version":[1]}},"default":"={{ $json.input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["conversationalAgent"],"@version":[1.1]}},"default":"={{ $json.chat_input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["conversationalAgent"],"@version":[1.2]}},"default":"={{ $json.chatInput }}"},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"agent":["conversationalAgent"]}},"default":{},"placeholder":"Add Option","options":[{"displayName":"Human Message","name":"humanMessage","type":"string","default":"TOOLS\n------\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n\n{tools}\n\n{format_instructions}\n\nUSER'S INPUT\n--------------------\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n\n{{input}}","description":"The message that will provide the agent with a list of tools to use","typeOptions":{"rows":6}},{"displayName":"System Message","name":"systemMessage","type":"string","default":"Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.","description":"The message that will be sent to the agent before the conversation starts","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"}]},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["openAiFunctionsAgent"],"@version":[1]}},"default":"={{ $json.input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["openAiFunctionsAgent"],"@version":[1.1]}},"default":"={{ $json.chat_input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["openAiFunctionsAgent"],"@version":[1.2]}},"default":"={{ $json.chatInput }}"},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"agent":["openAiFunctionsAgent"]}},"default":{},"placeholder":"Add Option","options":[{"displayName":"System Message","name":"systemMessage","type":"string","default":"You are a helpful AI assistant.","description":"The message that will be sent to the agent before the conversation starts","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"}]},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["reActAgent"],"@version":[1]}},"default":"={{ $json.input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["reActAgent"],"@version":[1.1]}},"default":"={{ $json.chat_input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["reActAgent"],"@version":[1.2]}},"default":"={{ $json.chatInput }}"},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"agent":["reActAgent"]}},"default":{},"placeholder":"Add Option","options":[{"displayName":"Human Message Template","name":"humanMessageTemplate","type":"string","default":"{input}\n\n{agent_scratchpad}","description":"String to use directly as the human message template","typeOptions":{"rows":6}},{"displayName":"Prefix Message","name":"prefix","type":"string","default":"Answer the following questions as best you can. You have access to the following tools:","description":"String to put before the list of tools","typeOptions":{"rows":6}},{"displayName":"Suffix Message for Chat Model","name":"suffixChat","type":"string","default":"Begin! Reminder to always use the exact characters `Final Answer` when responding.","description":"String to put after the list of tools that will be used if chat model is used","typeOptions":{"rows":6}},{"displayName":"Suffix Message for Regular Model","name":"suffix","type":"string","default":"Begin!\n\n\tQuestion: {input}\n\tThought:{agent_scratchpad}","description":"String to put after the list of tools that will be used if regular model is used","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"}]},{"displayName":"Data Source","name":"dataSource","type":"options","displayOptions":{"show":{"agent":["sqlAgent"],"@version":[{"_cnd":{"lt":1.4}}]}},"default":"sqlite","description":"SQL database to connect to","options":[{"name":"MySQL","value":"mysql","description":"Connect to a MySQL database"},{"name":"Postgres","value":"postgres","description":"Connect to a Postgres database"},{"name":"SQLite","value":"sqlite","description":"Use SQLite by connecting a database file as binary input"}]},{"displayName":"Data Source","name":"dataSource","type":"options","displayOptions":{"show":{"agent":["sqlAgent"],"@version":[{"_cnd":{"gte":1.4}}]}},"default":"postgres","description":"SQL database to connect to","options":[{"name":"MySQL","value":"mysql","description":"Connect to a MySQL database"},{"name":"Postgres","value":"postgres","description":"Connect to a Postgres database"},{"name":"SQLite","value":"sqlite","description":"Use SQLite by connecting a database file as binary input"}]},{"displayName":"Credentials","name":"credentials","type":"credentials","default":""},{"displayName":"Pass the SQLite database into this node as binary data, e.g. by inserting a 'Read/Write Files from Disk' node beforehand","name":"sqLiteFileNotice","type":"notice","default":"","displayOptions":{"show":{"agent":["sqlAgent"],"dataSource":["sqlite"]}}},{"displayName":"Input Binary Field","name":"binaryPropertyName","type":"string","default":"data","required":true,"placeholder":"e.g data","hint":"The name of the input binary field containing the file to be extracted","displayOptions":{"show":{"agent":["sqlAgent"],"dataSource":["sqlite"]}}},{"displayName":"Prompt","name":"input","type":"string","displayOptions":{"show":{"agent":["sqlAgent"],"@version":[{"_cnd":{"lte":1.2}}]}},"default":"","required":true,"typeOptions":{"rows":5}},{"displayName":"Source for Prompt (User Message)","name":"promptType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"auto","description":"Looks for an input field called 'chatInput' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"define","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"auto","displayOptions":{"hide":{"@version":[{"_cnd":{"lte":1.2}}]},"show":{"agent":["sqlAgent"]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"={{ $json.chatInput }}","typeOptions":{"rows":2},"disabledOptions":{"show":{"promptType":["auto"]}},"displayOptions":{"show":{"promptType":["auto"],"@version":[{"_cnd":{"gte":1.7}}],"agent":["sqlAgent"]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2},"displayOptions":{"show":{"promptType":["define"],"agent":["sqlAgent"]}}},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"agent":["sqlAgent"]}},"default":{},"placeholder":"Add Option","options":[{"displayName":"Ignored Tables","name":"ignoredTables","type":"string","default":"","description":"Comma-separated list of tables to ignore from the database. If empty, no tables are ignored."},{"displayName":"Include Sample Rows","name":"includedSampleRows","type":"number","description":"Number of sample rows to include in the prompt to the agent. It helps the agent to understand the schema of the database but it also increases the amount of tokens used.","default":3},{"displayName":"Included Tables","name":"includedTables","type":"string","default":"","description":"Comma-separated list of tables to include in the database. If empty, all tables are included."},{"displayName":"Prefix Prompt","name":"prefixPrompt","type":"string","default":"You are an agent designed to interact with an SQL database.\nGiven an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results using the LIMIT clause.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for a the few relevant columns given the question.\nYou have access to tools for interacting with the database.\nOnly use the below tools. Only use the information returned by the below tools to construct your final answer.\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n\nIf the question does not seem related to the database, just return \"I don't know\" as the answer.","description":"Prefix prompt to use for the agent","typeOptions":{"rows":10}},{"displayName":"Suffix Prompt","name":"suffixPrompt","type":"string","default":"Begin!\nChat History:\n{chatHistory}\n\nQuestion: {input}\nThought: I should look at the tables in the database to see what I can query.\n{agent_scratchpad}","description":"Suffix prompt to use for the agent","typeOptions":{"rows":4}},{"displayName":"Limit","name":"topK","type":"number","default":10,"description":"The maximum number of results to return"}]},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["planAndExecuteAgent"],"@version":[1]}},"default":"={{ $json.input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["planAndExecuteAgent"],"@version":[1.1]}},"default":"={{ $json.chat_input }}"},{"displayName":"Text","name":"text","type":"string","required":true,"displayOptions":{"show":{"agent":["planAndExecuteAgent"],"@version":[1.2]}},"default":"={{ $json.chatInput }}"},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"agent":["planAndExecuteAgent"]}},"default":{},"placeholder":"Add Option","options":[{"displayName":"Human Message Template","name":"humanMessageTemplate","type":"string","default":"Previous steps: {previous_steps}\n\nCurrent objective: {current_step}\n\n{agent_scratchpad}\n\nYou may extract and combine relevant data from your previous steps when responding to me.","description":"The message that will be sent to the agent during each step execution","typeOptions":{"rows":6}}]}]},
{"displayName":"AI Agent Tool","name":"agentTool","icon":"fa:robot","iconColor":"black","group":["transform"],"description":"Generates an action plan and executes it. Can use external tools.","codex":{"alias":["LangChain","Chat","Conversational","Plan and Execute","ReAct","Tools"],"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]}},"defaultVersion":2.2,"version":[2.2],"defaults":{"name":"AI Agent Tool","color":"#404040"},"inputs":"={{\n\t\t\t\t((hasOutputParser, needsFallback) => {\n\t\t\t\t\tfunction getInputs(hasMainInput, hasOutputParser, needsFallback) {\n  const getInputData = (inputs) => {\n    return inputs.map(({ type, filter, displayName, required }) => {\n      const input = {\n        type,\n        displayName,\n        required,\n        maxConnections: [\"ai_languageModel\", \"ai_memory\", \"ai_outputParser\"].includes(type) ? 1 : void 0\n      };\n      if (filter) {\n        input.filter = filter;\n      }\n      return input;\n    });\n  };\n  let specialInputs = [\n    {\n      type: \"ai_languageModel\",\n      displayName: \"Chat Model\",\n      required: true,\n      filter: {\n        excludedNodes: [\n          \"@n8n/n8n-nodes-langchain.lmCohere\",\n          \"@n8n/n8n-nodes-langchain.lmOllama\",\n          \"n8n/n8n-nodes-langchain.lmOpenAi\",\n          \"@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference\"\n        ]\n      }\n    },\n    {\n      type: \"ai_languageModel\",\n      displayName: \"Fallback Model\",\n      required: true,\n      filter: {\n        excludedNodes: [\n          \"@n8n/n8n-nodes-langchain.lmCohere\",\n          \"@n8n/n8n-nodes-langchain.lmOllama\",\n          \"n8n/n8n-nodes-langchain.lmOpenAi\",\n          \"@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference\"\n        ]\n      }\n    },\n    {\n      displayName: \"Memory\",\n      type: \"ai_memory\"\n    },\n    {\n      displayName: \"Tool\",\n      type: \"ai_tool\"\n    },\n    {\n      displayName: \"Output Parser\",\n      type: \"ai_outputParser\"\n    }\n  ];\n  if (hasOutputParser === false) {\n    specialInputs = specialInputs.filter((input) => input.type !== \"ai_outputParser\");\n  }\n  if (needsFallback === false) {\n    specialInputs = specialInputs.filter((input) => input.displayName !== \"Fallback Model\");\n  }\n  const mainInputs = hasMainInput ? [\"main\"] : [];\n  return [...mainInputs, ...getInputData(specialInputs)];\n};\n\t\t\t\t\treturn getInputs(false, hasOutputParser, needsFallback)\n\t\t\t\t})($parameter.hasOutputParser === undefined || $parameter.hasOutputParser === true, $parameter.needsFallback !== undefined && $parameter.needsFallback === true)\n\t\t\t}}","outputs":["ai_tool"],"properties":[{"displayName":"Description","name":"toolDescription","type":"string","default":"AI Agent that can call other tools","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often"},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2}},{"displayName":"Require Specific Output Format","name":"hasOutputParser","type":"boolean","default":false,"noDataExpression":true},{"displayName":"Connect an <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_outputParser'>output parser</a> on the canvas to specify the output format you require","name":"notice","type":"notice","default":"","displayOptions":{"show":{"hasOutputParser":[true]}}},{"displayName":"Enable Fallback Model","name":"needsFallback","type":"boolean","default":false,"noDataExpression":true,"displayOptions":{"show":{"@version":[{"_cnd":{"gte":2.1}}]}}},{"displayName":"Connect an additional language model on the canvas to use it as a fallback if the main model fails","name":"fallbackNotice","type":"notice","default":"","displayOptions":{"show":{"needsFallback":[true]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"System Message","name":"systemMessage","type":"string","default":"You are a helpful assistant","description":"The message that will be sent to the agent before the conversation starts","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"},{"displayName":"Automatically Passthrough Binary Images","name":"passthroughBinaryImages","type":"boolean","default":true,"description":"Whether or not binary images should be automatically passed through to the agent as image type messages"},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":1,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}]}],"displayOptions":{"hide":{"@version":[{"_cnd":{"lt":2.2}}]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"System Message","name":"systemMessage","type":"string","default":"You are a helpful assistant","description":"The message that will be sent to the agent before the conversation starts","typeOptions":{"rows":6}},{"displayName":"Max Iterations","name":"maxIterations","type":"number","default":10,"description":"The maximum number of iterations the agent will run before stopping"},{"displayName":"Return Intermediate Steps","name":"returnIntermediateSteps","type":"boolean","default":false,"description":"Whether or not the output should include intermediate steps the agent took"},{"displayName":"Automatically Passthrough Binary Images","name":"passthroughBinaryImages","type":"boolean","default":true,"description":"Whether or not binary images should be automatically passed through to the agent as image type messages"},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":1,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}]}],"displayOptions":{"show":{"@version":[{"_cnd":{"lt":2.2}}]}}}]},
{"displayName":"OpenAI Assistant","name":"openAiAssistant","hidden":true,"icon":"fa:robot","group":["transform"],"version":[1,1.1],"description":"Utilizes Assistant API from Open AI.","subtitle":"Open AI Assistant","defaults":{"name":"OpenAI Assistant","color":"#404040"},"codex":{"alias":["LangChain"],"categories":["AI"],"subcategories":{"AI":["Agents","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.openaiassistant/"}]}},"inputs":[{"type":"main"},{"type":"ai_tool","displayName":"Tools"}],"outputs":["main"],"credentials":[{"name":"openAiApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $parameter.options?.baseURL?.split(\"/\").slice(0,-1).join(\"/\") || \"https://api.openai.com\" }}"},"properties":[{"displayName":"Operation","name":"mode","type":"options","noDataExpression":true,"default":"existing","options":[{"name":"Use New Assistant","value":"new"},{"name":"Use Existing Assistant","value":"existing"}]},{"displayName":"Name","name":"name","type":"string","default":"","required":true,"displayOptions":{"show":{"/mode":["new"]}}},{"displayName":"Instructions","name":"instructions","type":"string","description":"How the Assistant and model should behave or respond","default":"","typeOptions":{"rows":5},"displayOptions":{"show":{"/mode":["new"]}}},{"displayName":"Model","name":"model","type":"options","description":"The model which will be used to power the assistant. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>. The Retrieval tool requires gpt-3.5-turbo-1106 and gpt-4-1106-preview models.","required":true,"displayOptions":{"show":{"/mode":["new"]}},"typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"={{ $parameter.options?.baseURL?.split(\"/\").slice(-1).pop() || \"v1\"  }}/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"filter","properties":{"pass":"={{ $responseItem.id.startsWith('gpt-') && !$responseItem.id.includes('instruct') }}"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"gpt-3.5-turbo-1106"},{"displayName":"Assistant","name":"assistantId","type":"options","noDataExpression":true,"displayOptions":{"show":{"/mode":["existing"]}},"description":"The assistant to use. <a href=\"https://beta.openai.com/docs/assistants/overview\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","headers":{"OpenAI-Beta":"assistants=v1"},"url":"={{ $parameter.options?.baseURL?.split(\"/\").slice(-1).pop() || \"v1\"  }}/assistants"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.name}}","value":"={{$responseItem.id}}","description":"={{$responseItem.model}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"assistant"}},"required":true,"default":""},{"displayName":"Text","name":"text","type":"string","required":true,"default":"={{ $json.chat_input }}","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Text","name":"text","type":"string","required":true,"default":"={{ $json.chatInput }}","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"OpenAI Tools","name":"nativeTools","type":"multiOptions","default":[],"options":[{"name":"Code Interpreter","value":"code_interpreter"},{"name":"Knowledge Retrieval","value":"retrieval"}]},{"displayName":"Connect your own custom tools to this node on the canvas","name":"noticeTools","type":"notice","default":""},{"displayName":"Upload files for retrieval using the <a href=\"https://platform.openai.com/playground\" target=\"_blank\">OpenAI website<a/>","name":"noticeTools","type":"notice","typeOptions":{"noticeTheme":"info"},"displayOptions":{"show":{"/nativeTools":["retrieval"]}},"default":""},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Base URL","name":"baseURL","default":"https://api.openai.com/v1","description":"Override the default base URL for the API","type":"string"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Timeout","name":"timeout","default":10000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"}]}]},
{"displayName":"Summarization Chain","name":"chainSummarization","icon":"fa:link","iconColor":"black","group":["transform"],"description":"Transforms text into a concise summary","codex":{"alias":["LangChain"],"categories":["AI"],"subcategories":{"AI":["Chains","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainsummarization/"}]}},"defaultVersion":2.1,"version":[2,2.1],"defaults":{"name":"Summarization Chain","color":"#909298"},"inputs":"={{ ((parameter) => { function getInputs(parameters) {\n  const chunkingMode = parameters?.chunkingMode;\n  const operationMode = parameters?.operationMode;\n  const inputs = [\n    { displayName: \"\", type: \"main\" },\n    {\n      displayName: \"Model\",\n      maxConnections: 1,\n      type: \"ai_languageModel\",\n      required: true\n    }\n  ];\n  if (operationMode === \"documentLoader\") {\n    inputs.push({\n      displayName: \"Document\",\n      type: \"ai_document\",\n      required: true,\n      maxConnections: 1\n    });\n    return inputs;\n  }\n  if (chunkingMode === \"advanced\") {\n    inputs.push({\n      displayName: \"Text Splitter\",\n      type: \"ai_textSplitter\",\n      required: false,\n      maxConnections: 1\n    });\n    return inputs;\n  }\n  return inputs;\n}; return getInputs(parameter) })($parameter) }}","outputs":["main"],"credentials":[],"properties":[{"displayName":"Save time with an <a href=\"/templates/1951\" target=\"_blank\">example</a> of how this node works","name":"notice","type":"notice","default":""},{"displayName":"Data to Summarize","name":"operationMode","noDataExpression":true,"type":"options","description":"How to pass data into the summarization chain","default":"nodeInputJson","options":[{"name":"Use Node Input (JSON)","value":"nodeInputJson","description":"Summarize the JSON data coming into this node from the previous one"},{"name":"Use Node Input (Binary)","value":"nodeInputBinary","description":"Summarize the binary data coming into this node from the previous one"},{"name":"Use Document Loader","value":"documentLoader","description":"Use a loader sub-node with more configuration options"}]},{"displayName":"Chunking Strategy","name":"chunkingMode","noDataExpression":true,"type":"options","description":"Chunk splitting strategy","default":"simple","options":[{"name":"Simple (Define Below)","value":"simple"},{"name":"Advanced","value":"advanced","description":"Use a splitter sub-node with more configuration options"}],"displayOptions":{"show":{"/operationMode":["nodeInputJson","nodeInputBinary"]}}},{"displayName":"Characters Per Chunk","name":"chunkSize","description":"Controls the max size (in terms of number of characters) of the final document chunk","type":"number","default":1000,"displayOptions":{"show":{"/chunkingMode":["simple"]}}},{"displayName":"Chunk Overlap (Characters)","name":"chunkOverlap","type":"number","description":"Specifies how much characters overlap there should be between chunks","default":200,"displayOptions":{"show":{"/chunkingMode":["simple"]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"Input Data Field Name","name":"binaryDataKey","type":"string","default":"data","description":"The name of the field in the agent or chains input that contains the binary file to be processed","displayOptions":{"show":{"/operationMode":["nodeInputBinary"]}}},{"displayName":"Summarization Method and Prompts","name":"summarizationMethodAndPrompts","type":"fixedCollection","default":{"values":{"summarizationMethod":"map_reduce","prompt":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","combineMapPrompt":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:"}},"placeholder":"Add Option","typeOptions":{},"options":[{"name":"values","displayName":"Values","values":[{"displayName":"Summarization Method","name":"summarizationMethod","type":"options","description":"The type of summarization to run","default":"map_reduce","options":[{"name":"Map Reduce (Recommended)","value":"map_reduce","description":"Summarize each document (or chunk) individually, then summarize those summaries"},{"name":"Refine","value":"refine","description":"Summarize the first document (or chunk). Then update that summary based on the next document (or chunk), and repeat."},{"name":"Stuff","value":"stuff","description":"Pass all documents (or chunks) at once. Ideal for small datasets."}]},{"displayName":"Individual Summary Prompt","name":"combineMapPrompt","type":"string","hint":"The prompt to summarize an individual document (or chunk)","displayOptions":{"hide":{"/options.summarizationMethodAndPrompts.values.summarizationMethod":["stuff","refine"]}},"default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","typeOptions":{"rows":9}},{"displayName":"Final Prompt to Combine","name":"prompt","type":"string","default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","hint":"The prompt to combine individual summaries","displayOptions":{"hide":{"/options.summarizationMethodAndPrompts.values.summarizationMethod":["stuff","refine"]}},"typeOptions":{"rows":9}},{"displayName":"Prompt","name":"prompt","type":"string","default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","displayOptions":{"hide":{"/options.summarizationMethodAndPrompts.values.summarizationMethod":["refine","map_reduce"]}},"typeOptions":{"rows":9}},{"displayName":"Subsequent (Refine) Prompt","name":"refinePrompt","type":"string","displayOptions":{"hide":{"/options.summarizationMethodAndPrompts.values.summarizationMethod":["stuff","map_reduce"]}},"default":"Your job is to produce a final summary\nWe have provided an existing summary up to a certain point: \"{existing_answer}\"\nWe have the opportunity to refine the existing summary\n(only if needed) with some more context below.\n------------\n\"{text}\"\n------------\n\nGiven the new context, refine the original summary\nIf the context isn't useful, return the original summary.\n\nREFINED SUMMARY:","hint":"The prompt to refine the summary based on the next document (or chunk)","typeOptions":{"rows":9}},{"displayName":"Initial Prompt","name":"refineQuestionPrompt","type":"string","displayOptions":{"hide":{"/options.summarizationMethodAndPrompts.values.summarizationMethod":["stuff","map_reduce"]}},"default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","hint":"The prompt for the first document (or chunk)","typeOptions":{"rows":9}}]}]},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":5,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":2.1}}]}}}]}]},
{"displayName":"Summarization Chain","name":"chainSummarization","icon":"fa:link","iconColor":"black","group":["transform"],"description":"Transforms text into a concise summary","codex":{"alias":["LangChain"],"categories":["AI"],"subcategories":{"AI":["Chains","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainsummarization/"}]}},"defaultVersion":2.1,"version":1,"defaults":{"name":"Summarization Chain","color":"#909298"},"inputs":["main",{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true},{"displayName":"Document","maxConnections":1,"type":"ai_document","required":true}],"outputs":["main"],"credentials":[],"properties":[{"displayName":"Save time with an <a href=\"/templates/1951\" target=\"_blank\">example</a> of how this node works","name":"notice","type":"notice","default":""},{"displayName":"Type","name":"type","type":"options","description":"The type of summarization to run","default":"map_reduce","options":[{"name":"Map Reduce (Recommended)","value":"map_reduce","description":"Summarize each document (or chunk) individually, then summarize those summaries"},{"name":"Refine","value":"refine","description":"Summarize the first document (or chunk). Then update that summary based on the next document (or chunk), and repeat."},{"name":"Stuff","value":"stuff","description":"Pass all documents (or chunks) at once. Ideal for small datasets."}]},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"Final Prompt to Combine","name":"combineMapPrompt","type":"string","hint":"The prompt to combine individual summaries","displayOptions":{"show":{"/type":["map_reduce"]}},"default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","typeOptions":{"rows":6}},{"displayName":"Individual Summary Prompt","name":"prompt","type":"string","default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","hint":"The prompt to summarize an individual document (or chunk)","displayOptions":{"show":{"/type":["map_reduce"]}},"typeOptions":{"rows":6}},{"displayName":"Prompt","name":"prompt","type":"string","default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","displayOptions":{"show":{"/type":["stuff"]}},"typeOptions":{"rows":6}},{"displayName":"Subsequent (Refine) Prompt","name":"refinePrompt","type":"string","displayOptions":{"show":{"/type":["refine"]}},"default":"Your job is to produce a final summary\nWe have provided an existing summary up to a certain point: \"{existing_answer}\"\nWe have the opportunity to refine the existing summary\n(only if needed) with some more context below.\n------------\n\"{text}\"\n------------\n\nGiven the new context, refine the original summary\nIf the context isn't useful, return the original summary.\n\nREFINED SUMMARY:","hint":"The prompt to refine the summary based on the next document (or chunk)","typeOptions":{"rows":6}},{"displayName":"Initial Prompt","name":"refineQuestionPrompt","type":"string","displayOptions":{"show":{"/type":["refine"]}},"default":"Write a concise summary of the following:\n\n\n\"{text}\"\n\n\nCONCISE SUMMARY:","hint":"The prompt for the first document (or chunk)","typeOptions":{"rows":6}}]}]},
{"displayName":"Basic LLM Chain","name":"chainLlm","icon":"fa:link","iconColor":"black","group":["transform"],"version":[1,1.1,1.2,1.3,1.4,1.5,1.6,1.7],"description":"A simple chain to prompt a large language model","defaults":{"name":"Basic LLM Chain","color":"#909298"},"codex":{"alias":["LangChain"],"categories":["AI"],"subcategories":{"AI":["Chains","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/"}]}},"inputs":"={{ ((parameter) => { function getInputs(parameters) {\n  const inputs = [\n    { displayName: \"\", type: \"main\" },\n    {\n      displayName: \"Model\",\n      maxConnections: 1,\n      type: \"ai_languageModel\",\n      required: true\n    }\n  ];\n  const needsFallback = parameters?.needsFallback;\n  if (needsFallback === true) {\n    inputs.push({\n      displayName: \"Fallback Model\",\n      maxConnections: 1,\n      type: \"ai_languageModel\",\n      required: true\n    });\n  }\n  const hasOutputParser = parameters?.hasOutputParser;\n  if (hasOutputParser === void 0 || hasOutputParser === true) {\n    inputs.push({\n      displayName: \"Output Parser\",\n      type: \"ai_outputParser\",\n      maxConnections: 1,\n      required: false\n    });\n  }\n  return inputs;\n}; return getInputs(parameter) })($parameter) }}","outputs":["main"],"credentials":[],"properties":[{"displayName":"Save time with an <a href=\"/templates/1978\" target=\"_blank\">example</a> of how this node works","name":"notice","type":"notice","default":""},{"displayName":"Prompt","name":"prompt","type":"string","required":true,"default":"={{ $json.input }}","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Prompt","name":"prompt","type":"string","required":true,"default":"={{ $json.chat_input }}","displayOptions":{"show":{"@version":[1.1,1.2]}}},{"displayName":"Prompt","name":"prompt","type":"string","required":true,"default":"={{ $json.chatInput }}","displayOptions":{"show":{"@version":[1.3]}}},{"displayName":"Source for Prompt (User Message)","name":"promptType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"auto","description":"Looks for an input field called 'chatInput' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"define","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"auto","displayOptions":{"hide":{"@version":[1,1.1,1.2,1.3]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"={{ $json.chatInput }}","typeOptions":{"rows":2},"disabledOptions":{"show":{"promptType":["auto"]}},"displayOptions":{"show":{"promptType":["auto"],"@version":[{"_cnd":{"gte":1.5}}]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2},"displayOptions":{"show":{"promptType":["define"]}}},{"displayName":"Require Specific Output Format","name":"hasOutputParser","type":"boolean","default":false,"noDataExpression":true,"displayOptions":{"hide":{"@version":[1,1.1,1.3]}}},{"displayName":"Enable Fallback Model","name":"needsFallback","type":"boolean","default":false,"noDataExpression":true,"displayOptions":{"hide":{"@version":[1,1.1,1.3]}}},{"displayName":"Chat Messages (if Using a Chat Model)","name":"messages","type":"fixedCollection","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add prompt","options":[{"name":"messageValues","displayName":"Prompt","values":[{"displayName":"Type Name or ID","name":"type","type":"options","options":[{"name":"AI","value":"AIMessagePromptTemplate"},{"name":"System","value":"SystemMessagePromptTemplate"},{"name":"User","value":"HumanMessagePromptTemplate"}],"default":"SystemMessagePromptTemplate"},{"displayName":"Message Type","name":"messageType","type":"options","displayOptions":{"show":{"type":["HumanMessagePromptTemplate"]}},"options":[{"name":"Text","value":"text","description":"Simple text message"},{"name":"Image (Binary)","value":"imageBinary","description":"Process the binary input from the previous node"},{"name":"Image (URL)","value":"imageUrl","description":"Process the image from the specified URL"}],"default":"text"},{"displayName":"Image Data Field Name","name":"binaryImageDataKey","type":"string","default":"data","required":true,"description":"The name of the field in the chain's input that contains the binary image file to be processed","displayOptions":{"show":{"messageType":["imageBinary"]}}},{"displayName":"Image URL","name":"imageUrl","type":"string","default":"","required":true,"description":"URL to the image to be processed","displayOptions":{"show":{"messageType":["imageUrl"]}}},{"displayName":"Image Details","description":"Control how the model processes the image and generates its textual understanding","name":"imageDetail","type":"options","displayOptions":{"show":{"type":["HumanMessagePromptTemplate"],"messageType":["imageBinary","imageUrl"]}},"options":[{"name":"Auto","value":"auto","description":"Model will use the auto setting which will look at the image input size and decide if it should use the low or high setting"},{"name":"Low","value":"low","description":"The model will receive a low-res 512px x 512px version of the image, and represent the image with a budget of 65 tokens. This allows the API to return faster responses and consume fewer input tokens for use cases that do not require high detail."},{"name":"High","value":"high","description":"Allows the model to see the low res image and then creates detailed crops of input images as 512px squares based on the input image size. Each of the detailed crops uses twice the token budget (65 tokens) for a total of 129 tokens."}],"default":"auto"},{"displayName":"Message","name":"message","type":"string","required":true,"displayOptions":{"hide":{"messageType":["imageBinary","imageUrl"]}},"default":""}]}]},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":5,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.7}}]}}},{"displayName":"Connect an <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_outputParser'>output parser</a> on the canvas to specify the output format you require","name":"notice","type":"notice","default":"","displayOptions":{"show":{"hasOutputParser":[true]}}},{"displayName":"Connect an additional language model on the canvas to use it as a fallback if the main model fails","name":"fallbackNotice","type":"notice","default":"","displayOptions":{"show":{"needsFallback":[true]}}}]},
{"displayName":"Question and Answer Chain","name":"chainRetrievalQa","icon":"fa:link","iconColor":"black","group":["transform"],"version":[1,1.1,1.2,1.3,1.4,1.5,1.6],"description":"Answer questions about retrieved documents","defaults":{"name":"Question and Answer Chain","color":"#909298"},"codex":{"alias":["LangChain"],"categories":["AI"],"subcategories":{"AI":["Chains","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainretrievalqa/"}]}},"inputs":["main",{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true},{"displayName":"Retriever","maxConnections":1,"type":"ai_retriever","required":true}],"outputs":["main"],"credentials":[],"properties":[{"displayName":"Save time with an <a href=\"/templates/1960\" target=\"_blank\">example</a> of how this node works","name":"notice","type":"notice","default":""},{"displayName":"Query","name":"query","type":"string","required":true,"default":"={{ $json.input }}","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Query","name":"query","type":"string","required":true,"default":"={{ $json.chat_input }}","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Query","name":"query","type":"string","required":true,"default":"={{ $json.chatInput }}","displayOptions":{"show":{"@version":[1.2]}}},{"displayName":"Source for Prompt (User Message)","name":"promptType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"auto","description":"Looks for an input field called 'chatInput' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"define","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"auto","displayOptions":{"hide":{"@version":[{"_cnd":{"lte":1.2}}]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"={{ $json.chatInput }}","typeOptions":{"rows":2},"disabledOptions":{"show":{"promptType":["auto"]}},"displayOptions":{"show":{"promptType":["auto"],"@version":[{"_cnd":{"gte":1.4}}]}}},{"displayName":"Prompt (User Message)","name":"text","type":"string","required":true,"default":"","placeholder":"e.g. Hello, how can you help me?","typeOptions":{"rows":2},"displayOptions":{"show":{"promptType":["define"]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"System Prompt Template","name":"systemPromptTemplate","type":"string","default":"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\nContext: {context}","typeOptions":{"rows":6},"description":"Template string used for the system prompt. This should include the variable `{context}` for the provided context. For text completion models, you should also include the variable `{question}` for the users query.","displayOptions":{"show":{"@version":[{"_cnd":{"lt":1.5}}]}}},{"displayName":"System Prompt Template","name":"systemPromptTemplate","type":"string","default":"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\nContext: {context}","typeOptions":{"rows":6},"description":"Template string used for the system prompt. This should include the variable `{context}` for the provided context. For text completion models, you should also include the variable `{input}` for the users query.","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.5}}]}}},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":5,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.6}}]}}}]}]},
{"displayName":"Sentiment Analysis","name":"sentimentAnalysis","icon":"fa:balance-scale-left","iconColor":"black","group":["transform"],"version":[1,1.1],"description":"Analyze the sentiment of your text","codex":{"categories":["AI"],"subcategories":{"AI":["Chains","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.sentimentanalysis/"}]}},"defaults":{"name":"Sentiment Analysis"},"inputs":[{"displayName":"","type":"main"},{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true}],"outputs":"={{((parameters, defaultCategories) => {\n  const options = parameters?.options ?? {};\n  const categories = options?.categories ?? defaultCategories;\n  const categoriesArray = categories.split(\",\").map((cat) => cat.trim());\n  const ret = categoriesArray.map((cat) => ({ type: \"main\", displayName: cat }));\n  return ret;\n})($parameter, \"Positive, Neutral, Negative\")}}","properties":[{"displayName":"Text to Analyze","name":"inputText","type":"string","required":true,"default":"","description":"Use an expression to reference data in previous nodes or enter static text","typeOptions":{"rows":2}},{"displayName":"Sentiment scores are LLM-generated estimates, not statistically rigorous measurements. They may be inconsistent across runs and should be used as rough indicators only.","name":"detailedResultsNotice","type":"notice","default":"","displayOptions":{"show":{"/options.includeDetailedResults":[true]}}},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"Sentiment Categories","name":"categories","type":"string","default":"Positive, Neutral, Negative","description":"A comma-separated list of categories to analyze","noDataExpression":true,"typeOptions":{"rows":2}},{"displayName":"System Prompt Template","name":"systemPromptTemplate","type":"string","default":"You are highly intelligent and accurate sentiment analyzer. Analyze the sentiment of the provided text. Categorize it into one of the following: {categories}. Use the provided formatting instructions. Only output the JSON.","description":"String to use directly as the system prompt template","typeOptions":{"rows":6}},{"displayName":"Include Detailed Results","name":"includeDetailedResults","type":"boolean","default":false,"description":"Whether to include sentiment strength and confidence scores in the output"},{"displayName":"Enable Auto-Fixing","name":"enableAutoFixing","type":"boolean","default":true,"description":"Whether to enable auto-fixing (may trigger an additional LLM call if output is broken)"},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":5,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.1}}]}}}]}]},
{"displayName":"Information Extractor","name":"informationExtractor","icon":"fa:project-diagram","iconColor":"black","group":["transform"],"version":[1,1.1,1.2],"defaultVersion":1.2,"description":"Extract information from text in a structured format","codex":{"alias":["NER","parse","parsing","JSON","data extraction","structured"],"categories":["AI"],"subcategories":{"AI":["Chains","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/"}]}},"defaults":{"name":"Information Extractor"},"inputs":[{"displayName":"","type":"main"},{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true}],"outputs":["main"],"properties":[{"displayName":"Text","name":"text","type":"string","default":"","description":"The text to extract information from","typeOptions":{"rows":2}},{"displayName":"Schema Type","name":"schemaType","type":"options","noDataExpression":true,"options":[{"name":"From Attribute Descriptions","value":"fromAttributes","description":"Extract specific attributes from the text based on types and descriptions"},{"name":"Generate From JSON Example","value":"fromJson","description":"Generate a schema from an example JSON object"},{"name":"Define using JSON Schema","value":"manual","description":"Define the JSON schema manually"}],"default":"fromAttributes","description":"How to specify the schema for the desired output"},{"displayName":"JSON Example","name":"jsonSchemaExample","type":"json","default":"{\n\t\"state\": \"California\",\n\t\"cities\": [\"Los Angeles\", \"San Francisco\", \"San Diego\"]\n}","noDataExpression":true,"typeOptions":{"rows":10},"displayOptions":{"show":{"schemaType":["fromJson"]}},"description":"Example JSON object to use to generate the schema"},{"displayName":"All properties will be required. To make them optional, use the 'JSON Schema' schema type instead","name":"notice","type":"notice","default":"","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}],"schemaType":["fromJson"]}}},{"displayName":"Input Schema","name":"inputSchema","type":"json","default":"{\n\t\"type\": \"object\",\n\t\"properties\": {\n\t\t\"state\": {\n\t\t\t\"type\": \"string\"\n\t\t},\n\t\t\"cities\": {\n\t\t\t\"type\": \"array\",\n\t\t\t\"items\": {\n\t\t\t\t\"type\": \"string\"\n\t\t\t}\n\t\t}\n\t}\n}","noDataExpression":false,"typeOptions":{"rows":10},"displayOptions":{"show":{"schemaType":["manual"]}},"description":"Schema to use for the function","hint":"Use <a target=\"_blank\" href=\"https://json-schema.org/\">JSON Schema</a> format (<a target=\"_blank\" href=\"https://json-schema.org/learn/miscellaneous-examples.html\">examples</a>). $refs syntax is currently not supported."},{"displayName":"Attributes","name":"attributes","placeholder":"Add Attribute","type":"fixedCollection","default":{},"displayOptions":{"show":{"schemaType":["fromAttributes"]}},"typeOptions":{"multipleValues":true},"options":[{"name":"attributes","displayName":"Attribute List","values":[{"displayName":"Name","name":"name","type":"string","default":"","description":"Attribute to extract","placeholder":"e.g. company_name","required":true},{"displayName":"Type","name":"type","type":"options","description":"Data type of the attribute","required":true,"options":[{"name":"Boolean","value":"boolean"},{"name":"Date","value":"date"},{"name":"Number","value":"number"},{"name":"String","value":"string"}],"default":"string"},{"displayName":"Description","name":"description","type":"string","default":"","description":"Describe your attribute","placeholder":"Add description for the attribute","required":true},{"displayName":"Required","name":"required","type":"boolean","default":false,"description":"Whether attribute is required","required":true}]}]},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"System Prompt Template","name":"systemPromptTemplate","type":"string","default":"You are an expert extraction algorithm.\nOnly extract relevant information from the text.\nIf you do not know the value of an attribute asked to extract, you may omit the attribute's value.","description":"String to use directly as the system prompt template","typeOptions":{"rows":6}},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":5,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.1}}]}}}]}]},
{"displayName":"Text Classifier","name":"textClassifier","icon":"fa:tags","iconColor":"black","group":["transform"],"version":[1,1.1],"description":"Classify your text into distinct categories","codex":{"categories":["AI"],"subcategories":{"AI":["Chains","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.text-classifier/"}]}},"defaults":{"name":"Text Classifier"},"inputs":[{"displayName":"","type":"main"},{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true}],"outputs":"={{((parameters) => {\n  const categories = parameters.categories?.categories ?? [];\n  const fallback = parameters.options?.fallback;\n  const ret = categories.map((cat) => {\n    return { type: \"main\", displayName: cat.category };\n  });\n  if (fallback === \"other\") ret.push({ type: \"main\", displayName: \"Other\" });\n  return ret;\n})($parameter)}}","properties":[{"displayName":"Text to Classify","name":"inputText","type":"string","required":true,"default":"","description":"Use an expression to reference data in previous nodes or enter static text","typeOptions":{"rows":2}},{"displayName":"Categories","name":"categories","placeholder":"Add Category","type":"fixedCollection","default":{},"typeOptions":{"multipleValues":true},"options":[{"name":"categories","displayName":"Categories","values":[{"displayName":"Category","name":"category","type":"string","default":"","description":"Category to add","required":true},{"displayName":"Description","name":"description","type":"string","default":"","description":"Describe your category if it's not obvious"}]}]},{"displayName":"Options","name":"options","type":"collection","default":{},"placeholder":"Add Option","options":[{"displayName":"Allow Multiple Classes To Be True","name":"multiClass","type":"boolean","default":false},{"displayName":"When No Clear Match","name":"fallback","type":"options","default":"discard","description":"What to do with items that dont match the categories exactly","options":[{"name":"Discard Item","value":"discard","description":"Ignore the item and drop it from the output"},{"name":"Output on Extra, 'Other' Branch","value":"other","description":"Create a separate output branch called 'Other'"}]},{"displayName":"System Prompt Template","name":"systemPromptTemplate","type":"string","default":"Please classify the text provided by the user into one of the following categories: {categories}, and use the provided formatting instructions below. Don't explain, and only output the json.","description":"String to use directly as the system prompt template","typeOptions":{"rows":6}},{"displayName":"Enable Auto-Fixing","name":"enableAutoFixing","type":"boolean","default":true,"description":"Whether to enable auto-fixing (may trigger an additional LLM call if output is broken)"},{"displayName":"Batch Processing","name":"batching","type":"collection","placeholder":"Add Batch Processing Option","description":"Batch processing options for rate limiting","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":5,"type":"number","description":"How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."},{"displayName":"Delay Between Batches","name":"delayBetweenBatches","default":0,"type":"number","description":"Delay in milliseconds between batches. This is useful for rate limiting."}],"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.1}}]}}}]}]},
{"displayName":"LangChain Code","name":"code","icon":"fa:code","iconColor":"black","group":["transform"],"version":1,"description":"LangChain Code Node","defaults":{"name":"LangChain Code"},"codex":{"categories":["AI"],"subcategories":{"AI":["Miscellaneous"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/"}]}},"inputs":"={{ ((values) => { const connectorTypes = {\"ai_chain\":\"Chain\",\"ai_document\":\"Document\",\"ai_embedding\":\"Embedding\",\"ai_languageModel\":\"Language Model\",\"ai_memory\":\"Memory\",\"ai_outputParser\":\"Output Parser\",\"ai_textSplitter\":\"Text Splitter\",\"ai_tool\":\"Tool\",\"ai_vectorStore\":\"Vector Store\",\"main\":\"Main\"}; return values.map(value => { return { type: value.type, required: value.required, maxConnections: value.maxConnections === -1 ? undefined : value.maxConnections, displayName: connectorTypes[value.type] !== 'Main' ? connectorTypes[value.type] : undefined } } ) })($parameter.inputs.input) }}","outputs":"={{ ((values) => { const connectorTypes = {\"ai_chain\":\"Chain\",\"ai_document\":\"Document\",\"ai_embedding\":\"Embedding\",\"ai_languageModel\":\"Language Model\",\"ai_memory\":\"Memory\",\"ai_outputParser\":\"Output Parser\",\"ai_textSplitter\":\"Text Splitter\",\"ai_tool\":\"Tool\",\"ai_vectorStore\":\"Vector Store\",\"main\":\"Main\"}; return values.map(value => { return { type: value.type, displayName: connectorTypes[value.type] !== 'Main' ? connectorTypes[value.type] : undefined } } ) })($parameter.outputs.output) }}","properties":[{"displayName":"Code","name":"code","placeholder":"Add Code","type":"fixedCollection","noDataExpression":true,"default":{},"options":[{"name":"execute","displayName":"Execute","values":[{"displayName":"JavaScript - Execute","name":"code","type":"string","typeOptions":{"editor":"jsEditor"},"default":"const { PromptTemplate } = require('@langchain/core/prompts');\n\nconst query = 'Tell me a joke';\nconst prompt = PromptTemplate.fromTemplate(query);\n\n// If you are allowing more than one language model input connection (-1 or\n// anything greater than 1), getInputConnectionData returns an array, so you\n// will have to change the code below it to deal with that. For example, use\n// llm[0] in the chain definition\n\nconst llm = await this.getInputConnectionData('ai_languageModel', 0);\nlet chain = prompt.pipe(llm);\nconst output = await chain.invoke();\nreturn [ {json: { output } } ];","hint":"This code will only run and return data if a \"Main\" input & output got created.","noDataExpression":true}]},{"name":"supplyData","displayName":"Supply Data","values":[{"displayName":"JavaScript - Supply Data","name":"code","type":"string","typeOptions":{"editor":"jsEditor"},"default":"const { WikipediaQueryRun } = require( '@langchain/community/tools/wikipedia_query_run');\nreturn new WikipediaQueryRun();","hint":"This code will only run and return data if an output got created which is not \"Main\".","noDataExpression":true}]}]},{"displayName":"You can import LangChain and use all available functionality. Debug by using <code>console.log()</code> statements and viewing their output in the browser console.","name":"notice","type":"notice","default":""},{"displayName":"Inputs","name":"inputs","placeholder":"Add Input","type":"fixedCollection","noDataExpression":true,"typeOptions":{"multipleValues":true,"sortable":true},"description":"The input to add","default":{},"options":[{"name":"input","displayName":"Input","values":[{"displayName":"Type","name":"type","type":"options","options":[{"name":"Chain","value":"ai_chain"},{"name":"Document","value":"ai_document"},{"name":"Embedding","value":"ai_embedding"},{"name":"Language Model","value":"ai_languageModel"},{"name":"Memory","value":"ai_memory"},{"name":"Output Parser","value":"ai_outputParser"},{"name":"Text Splitter","value":"ai_textSplitter"},{"name":"Tool","value":"ai_tool"},{"name":"Vector Store","value":"ai_vectorStore"},{"name":"Main","value":"main"}],"noDataExpression":true,"default":"","required":true,"description":"The type of the input"},{"displayName":"Max Connections","name":"maxConnections","type":"number","noDataExpression":true,"default":-1,"required":true,"description":"How many nodes of this type are allowed to be connected. Set it to -1 for unlimited."},{"displayName":"Required","name":"required","type":"boolean","noDataExpression":true,"default":false,"required":true,"description":"Whether the input needs a connection"}]}]},{"displayName":"Outputs","name":"outputs","placeholder":"Add Output","type":"fixedCollection","noDataExpression":true,"typeOptions":{"multipleValues":true,"sortable":true},"description":"The output to add","default":{},"options":[{"name":"output","displayName":"Output","values":[{"displayName":"Type","name":"type","type":"options","options":[{"name":"Chain","value":"ai_chain"},{"name":"Document","value":"ai_document"},{"name":"Embedding","value":"ai_embedding"},{"name":"Language Model","value":"ai_languageModel"},{"name":"Memory","value":"ai_memory"},{"name":"Output Parser","value":"ai_outputParser"},{"name":"Text Splitter","value":"ai_textSplitter"},{"name":"Tool","value":"ai_tool"},{"name":"Vector Store","value":"ai_vectorStore"},{"name":"Main","value":"main"}],"noDataExpression":true,"default":"","required":true,"description":"The type of the input"}]}]}]},
{"displayName":"Default Data Loader","name":"documentDefaultDataLoader","group":["transform"],"version":[1,1.1],"defaultVersion":1.1,"description":"Load data from previous step in the workflow","defaults":{"name":"Default Data Loader"},"codex":{"categories":["AI"],"subcategories":{"AI":["Document Loaders"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader/"}]}},"inputs":"={{ ((parameter) => { function getInputs(parameters) {\n  const inputs = [];\n  const textSplittingMode = parameters?.textSplittingMode;\n  if (!textSplittingMode || textSplittingMode === \"custom\") {\n    inputs.push({\n      displayName: \"Text Splitter\",\n      maxConnections: 1,\n      type: \"ai_textSplitter\",\n      required: true\n    });\n  }\n  return inputs;\n}; return getInputs(parameter) })($parameter) }}","outputs":["ai_document"],"outputNames":["Document"],"properties":[{"displayName":"This will load data from a previous step in the workflow. <a href=\"/templates/1962\" target=\"_blank\">Example</a>","name":"notice","type":"notice","default":""},{"displayName":"Type of Data","name":"dataType","type":"options","default":"json","required":true,"noDataExpression":true,"options":[{"name":"JSON","value":"json","description":"Process JSON data from previous step in the workflow"},{"name":"Binary","value":"binary","description":"Process binary data from previous step in the workflow"}]},{"displayName":"Mode","name":"jsonMode","type":"options","default":"allInputData","required":true,"displayOptions":{"show":{"dataType":["json"]}},"options":[{"name":"Load All Input Data","value":"allInputData","description":"Use all JSON data that flows into the parent agent or chain"},{"name":"Load Specific Data","value":"expressionData","description":"Load a subset of data, and/or data from any previous step in the workflow"}]},{"displayName":"Mode","name":"binaryMode","type":"options","default":"allInputData","required":true,"displayOptions":{"show":{"dataType":["binary"]}},"options":[{"name":"Load All Input Data","value":"allInputData","description":"Use all Binary data that flows into the parent agent or chain"},{"name":"Load Specific Data","value":"specificField","description":"Load data from a specific field in the parent agent or chain"}]},{"displayName":"Data Format","name":"loader","type":"options","default":"auto","required":true,"displayOptions":{"show":{"dataType":["binary"]}},"options":[{"name":"Automatically Detect by Mime Type","value":"auto","description":"Uses the mime type to detect the format"},{"name":"CSV","value":"csvLoader","description":"Load CSV files"},{"name":"Docx","value":"docxLoader","description":"Load Docx documents"},{"name":"EPub","value":"epubLoader","description":"Load EPub files"},{"name":"JSON","value":"jsonLoader","description":"Load JSON files"},{"name":"PDF","value":"pdfLoader","description":"Load PDF documents"},{"name":"Text","value":"textLoader","description":"Load plain text files"}]},{"displayName":"Data","name":"jsonData","type":"string","typeOptions":{"rows":6},"default":"","required":true,"description":"Drag and drop fields from the input pane, or use an expression","displayOptions":{"show":{"dataType":["json"],"jsonMode":["expressionData"]}}},{"displayName":"Input Data Field Name","name":"binaryDataKey","type":"string","default":"data","required":true,"description":"The name of the field in the agent or chains input that contains the binary file to be processed","displayOptions":{"show":{"dataType":["binary"]},"hide":{"binaryMode":["allInputData"]}}},{"displayName":"Text Splitting","name":"textSplittingMode","type":"options","default":"simple","required":true,"noDataExpression":true,"displayOptions":{"show":{"@version":[1.1]}},"options":[{"name":"Simple","value":"simple","description":"Splits every 1000 characters with a 200 character overlap"},{"name":"Custom","value":"custom","description":"Connect a custom text-splitting sub-node"}]},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"JSON Pointers","name":"pointers","type":"string","default":"","description":"Pointers to extract from JSON, e.g. \"/text\" or \"/text, /meta/title\"","displayOptions":{"show":{"/loader":["jsonLoader","auto"]}}},{"displayName":"CSV Separator","name":"separator","type":"string","description":"Separator to use for CSV","default":",","displayOptions":{"show":{"/loader":["csvLoader","auto"]}}},{"displayName":"CSV Column","name":"column","type":"string","default":"","description":"Column to extract from CSV","displayOptions":{"show":{"/loader":["csvLoader","auto"]}}},{"displayName":"Split Pages in PDF","description":"Whether to split PDF pages into separate documents","name":"splitPages","type":"boolean","default":true,"displayOptions":{"show":{"/loader":["pdfLoader","auto"]}}},{"displayName":"Metadata","name":"metadata","type":"fixedCollection","description":"Metadata to add to each document. Could be used for filtering during retrieval","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add property","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/document_loaders/DocumentDefaultDataLoader/binary.svg"},
{"hidden":true,"displayName":"Binary Input Loader","name":"documentBinaryInputLoader","group":["transform"],"version":1,"description":"Use binary data from a previous step in the workflow","defaults":{"name":"Binary Input Loader"},"codex":{"categories":["AI"],"subcategories":{"AI":["Document Loaders"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader/"}]}},"inputs":[{"displayName":"Text Splitter","maxConnections":1,"type":"ai_textSplitter","required":true}],"outputs":["ai_document"],"outputNames":["Document"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Loader Type","name":"loader","type":"options","default":"jsonLoader","required":true,"options":[{"name":"CSV Loader","value":"csvLoader","description":"Load CSV files"},{"name":"Docx Loader","value":"docxLoader","description":"Load Docx documents"},{"name":"EPub Loader","value":"epubLoader","description":"Load EPub files"},{"name":"JSON Loader","value":"jsonLoader","description":"Load JSON files"},{"name":"PDF Loader","value":"pdfLoader","description":"Load PDF documents"},{"name":"Text Loader","value":"textLoader","description":"Load plain text files"}]},{"displayName":"Binary Data Key","name":"binaryDataKey","type":"string","default":"data","required":true,"description":"Name of the binary property from which to read the file buffer"},{"displayName":"Split Pages","name":"splitPages","type":"boolean","default":true,"displayOptions":{"show":{"loader":["pdfLoader"]}}},{"displayName":"Column","name":"column","type":"string","default":"","description":"Column to extract from CSV","displayOptions":{"show":{"loader":["csvLoader"]}}},{"displayName":"Separator","name":"separator","type":"string","description":"Separator to use for CSV","default":",","displayOptions":{"show":{"loader":["csvLoader"]}}},{"displayName":"Pointers","name":"pointers","type":"string","default":"","description":"Pointers to extract from JSON, e.g. \"/text\" or \"/text, /meta/title\"","displayOptions":{"show":{"loader":["jsonLoader"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Metadata","name":"metadata","type":"fixedCollection","description":"Metadata to add to each document. Could be used for filtering during retrieval","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add property","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/document_loaders/DocumentBinaryInputLoader/binary.svg"},
{"displayName":"GitHub Document Loader","name":"documentGithubLoader","group":["transform"],"version":[1,1.1],"defaultVersion":1.1,"description":"Use GitHub data as input to this chain","defaults":{"name":"GitHub Document Loader"},"codex":{"categories":["AI"],"subcategories":{"AI":["Document Loaders"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentgithubloader/"}]}},"credentials":[{"name":"githubApi","required":true}],"inputs":"={{ ((parameter) => { function getInputs(parameters) {\n  const inputs = [];\n  const textSplittingMode = parameters?.textSplittingMode;\n  if (!textSplittingMode || textSplittingMode === \"custom\") {\n    inputs.push({\n      displayName: \"Text Splitter\",\n      maxConnections: 1,\n      type: \"ai_textSplitter\",\n      required: true\n    });\n  }\n  return inputs;\n}; return getInputs(parameter) })($parameter) }}","inputNames":["Text Splitter"],"outputs":["ai_document"],"outputNames":["Document"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Repository Link","name":"repository","type":"string","default":""},{"displayName":"Branch","name":"branch","type":"string","default":"main"},{"displayName":"Text Splitting","name":"textSplittingMode","type":"options","default":"simple","required":true,"noDataExpression":true,"displayOptions":{"show":{"@version":[1.1]}},"options":[{"name":"Simple","value":"simple","description":"Splits every 1000 characters with a 200 character overlap"},{"name":"Custom","value":"custom","description":"Connect a custom text-splitting sub-node"}]},{"displayName":"Options","name":"additionalOptions","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Recursive","name":"recursive","type":"boolean","default":false},{"displayName":"Ignore Paths","name":"ignorePaths","type":"string","description":"Comma-separated list of paths to ignore, e.g. \"docs, src/tests","default":""}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/document_loaders/DocumentGithubLoader/github.svg"},
{"hidden":true,"displayName":"JSON Input Loader","name":"documentJsonInputLoader","group":["transform"],"version":1,"description":"Use JSON data from a previous step in the workflow","defaults":{"name":"JSON Input Loader"},"codex":{"categories":["AI"],"subcategories":{"AI":["Document Loaders"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader/"}]}},"inputs":[{"displayName":"Text Splitter","maxConnections":1,"type":"ai_textSplitter"}],"inputNames":["Text Splitter"],"outputs":["ai_document"],"outputNames":["Document"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Pointers","name":"pointers","type":"string","default":"","description":"Pointers to extract from JSON, e.g. \"/text\" or \"/text, /meta/title\""},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Metadata","name":"metadata","type":"fixedCollection","description":"Metadata to add to each document. Could be used for filtering during retrieval","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add property","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/document_loaders/DocumentJSONInputLoader/json.svg"},
{"displayName":"Embeddings Cohere","name":"embeddingsCohere","group":["transform"],"version":1,"description":"Use Cohere Embeddings","defaults":{"name":"Embeddings Cohere"},"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.host }}"},"credentials":[{"name":"cohereApi","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingscohere/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Each model is using different dimensional density for embeddings. Please make sure to use the same dimensionality for your vector store. The default model is using 768-dimensional embeddings.","name":"notice","type":"notice","default":""},{"displayName":"Model","name":"modelName","type":"options","description":"The model which will generate the embeddings. <a href=\"https://docs.cohere.com/docs/models\">Learn more</a>.","default":"embed-english-v2.0","options":[{"name":"Embed-English-Light-v2.0 (1024 Dimensions)","value":"embed-english-light-v2.0"},{"name":"Embed-English-Light-v3.0 (384 Dimensions)","value":"embed-english-light-v3.0"},{"name":"Embed-English-v2.0 (4096 Dimensions)","value":"embed-english-v2.0"},{"name":"Embed-English-v3.0 (1024 Dimensions)","value":"embed-english-v3.0"},{"name":"Embed-Multilingual-Light-v3.0 (384 Dimensions)","value":"embed-multilingual-light-v3.0"},{"name":"Embed-Multilingual-v2.0 (768 Dimensions)","value":"embed-multilingual-v2.0"},{"name":"Embed-Multilingual-v3.0 (1024 Dimensions)","value":"embed-multilingual-v3.0"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsCohere/cohere.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsCohere/cohere.dark.svg"}},
{"displayName":"Embeddings AWS Bedrock","name":"embeddingsAwsBedrock","credentials":[{"name":"aws","required":true}],"group":["transform"],"version":1,"description":"Use Embeddings AWS Bedrock","defaults":{"name":"Embeddings AWS Bedrock"},"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsawsbedrock/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"=https://bedrock.{{$credentials?.region ?? \"eu-central-1\"}}.amazonaws.com"},"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion. <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/foundation-models.html\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/foundation-models?byInferenceType=ON_DEMAND&byOutputModality=EMBEDDING"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"modelSummaries"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.modelName}}","description":"={{$responseItem.modelArn}}","value":"={{$responseItem.modelId}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":""}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsAwsBedrock/bedrock.svg"},
{"displayName":"Embeddings Azure OpenAI","name":"embeddingsAzureOpenAi","credentials":[{"name":"azureOpenAiApi","required":true}],"group":["transform"],"version":1,"description":"Use Embeddings Azure OpenAI","defaults":{"name":"Embeddings Azure OpenAI"},"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsazureopenai/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model (Deployment) Name","name":"model","type":"string","description":"The name of the model(deployment) to use","default":""},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":512,"typeOptions":{"maxValue":2048},"description":"Maximum number of documents to send in each request","type":"number"},{"displayName":"Strip New Lines","name":"stripNewLines","default":true,"description":"Whether to strip new lines from the input text","type":"boolean"},{"displayName":"Timeout","name":"timeout","default":-1,"description":"Maximum amount of time a request is allowed to take in seconds. Set to -1 for no timeout.","type":"number"},{"displayName":"Dimensions","name":"dimensions","description":"The number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models.","type":"options","options":[{"name":"256","value":256},{"name":"512","value":512},{"name":"1024","value":1024},{"name":"1536","value":1536},{"name":"3072","value":3072}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsAzureOpenAi/azure.svg"},
{"displayName":"Embeddings Google Gemini","name":"embeddingsGoogleGemini","group":["transform"],"version":1,"description":"Use Google Gemini Embeddings","defaults":{"name":"Embeddings Google Gemini"},"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.host }}"},"credentials":[{"name":"googlePalmApi","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsgooglegemini/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Each model is using different dimensional density for embeddings. Please make sure to use the same dimensionality for your vector store. The default model is using 768-dimensional embeddings.","name":"notice","type":"notice","default":""},{"displayName":"Model","name":"modelName","type":"options","description":"The model which will generate the embeddings. <a href=\"https://developers.generativeai.google/api/rest/generativelanguage/models/list\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/v1beta/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"models"}},{"type":"filter","properties":{"pass":"={{ $responseItem.name.includes('embedding') }}"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.name}}","value":"={{$responseItem.name}}","description":"={{$responseItem.description}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"models/text-embedding-004"}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsGoogleGemini/google.svg"},
{"displayName":"Embeddings Google Vertex","name":"embeddingsGoogleVertex","group":["transform"],"version":1,"description":"Use Google Vertex Embeddings","defaults":{"name":"Embeddings Google Vertex"},"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.host }}"},"credentials":[{"name":"googleApi","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsgooglevertex/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Each model is using different dimensional density for embeddings. Please make sure to use the same dimensionality for your vector store. The default model is using 768-dimensional embeddings. You can find available models <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api\">here</a>.","name":"notice","type":"notice","default":""},{"displayName":"Project ID","name":"projectId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"description":"Select or enter your Google Cloud project ID","modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"gcpProjectsList"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Model Name","name":"modelName","type":"string","description":"The model which will generate the embeddings. <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api\">Learn more</a>.","default":"text-embedding-005"}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsGoogleVertex/google.svg"},
{"displayName":"Embeddings Hugging Face Inference","name":"embeddingsHuggingFaceInference","group":["transform"],"version":1,"description":"Use HuggingFace Inference Embeddings","defaults":{"name":"Embeddings HuggingFace Inference"},"credentials":[{"name":"huggingFaceApi","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingshuggingfaceinference/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Each model is using different dimensional density for embeddings. Please make sure to use the same dimensionality for your vector store. The default model is using 768-dimensional embeddings.","name":"notice","type":"notice","default":""},{"displayName":"Model Name","name":"modelName","type":"string","default":"sentence-transformers/distilbert-base-nli-mean-tokens","description":"The model name to use from HuggingFace library"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Custom Inference Endpoint","name":"endpointUrl","default":"","description":"Custom endpoint URL","type":"string"},{"displayName":"Provider","name":"provider","type":"options","options":[{"value":"black-forest-labs","name":"black-forest-labs"},{"value":"cerebras","name":"cerebras"},{"value":"cohere","name":"cohere"},{"value":"fal-ai","name":"fal-ai"},{"value":"featherless-ai","name":"featherless-ai"},{"value":"fireworks-ai","name":"fireworks-ai"},{"value":"groq","name":"groq"},{"value":"hf-inference","name":"hf-inference"},{"value":"hyperbolic","name":"hyperbolic"},{"value":"nebius","name":"nebius"},{"value":"novita","name":"novita"},{"value":"nscale","name":"nscale"},{"value":"openai","name":"openai"},{"value":"ovhcloud","name":"ovhcloud"},{"value":"replicate","name":"replicate"},{"value":"sambanova","name":"sambanova"},{"value":"together","name":"together"},{"value":"auto","name":"auto"}],"default":"auto"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsHuggingFaceInference/huggingface.svg"},
{"displayName":"Embeddings Mistral Cloud","name":"embeddingsMistralCloud","credentials":[{"name":"mistralCloudApi","required":true}],"group":["transform"],"version":1,"description":"Use Embeddings Mistral Cloud","defaults":{"name":"Embeddings Mistral Cloud"},"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsmistralcloud/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"https://api.mistral.ai/v1"},"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","description":"The model which will compute the embeddings. <a href=\"https://docs.mistral.ai/platform/endpoints/\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"filter","properties":{"pass":"={{ $responseItem.id.includes('embed') }}"}},{"type":"setKeyValue","properties":{"name":"={{ $responseItem.id }}","value":"={{ $responseItem.id }}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"mistral-embed"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Batch Size","name":"batchSize","default":512,"typeOptions":{"maxValue":2048},"description":"Maximum number of documents to send in each request","type":"number"},{"displayName":"Strip New Lines","name":"stripNewLines","default":true,"description":"Whether to strip new lines from the input text","type":"boolean"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsMistralCloud/mistral.svg"},
{"displayName":"Embeddings OpenAI","name":"embeddingsOpenAi","credentials":[{"name":"openAiApi","required":true}],"group":["transform"],"version":[1,1.1,1.2],"description":"Use Embeddings OpenAI","defaults":{"name":"Embeddings OpenAI"},"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $parameter.options?.baseURL?.split(\"/\").slice(0,-1).join(\"/\") || $credentials.url?.split(\"/\").slice(0,-1).join(\"/\") || \"https://api.openai.com\" }}"},"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the embeddings. <a href=\"https://platform.openai.com/docs/models/overview\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"={{ $parameter.options?.baseURL?.split(\"/\").slice(-1).pop() || $credentials?.url?.split(\"/\").slice(-1).pop() || \"v1\" }}/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"filter","properties":{"pass":"={{\n\t\t\t\t\t\t\t\t\t($parameter.options?.baseURL && !$parameter.options?.baseURL?.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t($credentials?.url && !$credentials.url.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t$responseItem.id.includes('embed')\n\t\t\t\t\t\t\t\t}}"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"text-embedding-ada-002","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the embeddings. <a href=\"https://platform.openai.com/docs/models/overview\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"={{ $parameter.options?.baseURL?.split(\"/\").slice(-1).pop() || $credentials?.url?.split(\"/\").slice(-1).pop() || \"v1\" }}/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"filter","properties":{"pass":"={{\n\t\t\t\t\t\t\t\t\t($parameter.options?.baseURL && !$parameter.options?.baseURL?.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t($credentials?.url && !$credentials.url.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t$responseItem.id.includes('embed')\n\t\t\t\t\t\t\t\t}}"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"text-embedding-3-small","displayOptions":{"hide":{"@version":[1]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Dimensions","name":"dimensions","description":"The number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models.","type":"options","options":[{"name":"256","value":256},{"name":"512","value":512},{"name":"1024","value":1024},{"name":"1536","value":1536},{"name":"3072","value":3072}]},{"displayName":"Base URL","name":"baseURL","default":"https://api.openai.com/v1","description":"Override the default base URL for the API","type":"string","displayOptions":{"hide":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Batch Size","name":"batchSize","default":512,"typeOptions":{"maxValue":2048},"description":"Maximum number of documents to send in each request","type":"number"},{"displayName":"Strip New Lines","name":"stripNewLines","default":true,"description":"Whether to strip new lines from the input text","type":"boolean"},{"displayName":"Timeout","name":"timeout","default":-1,"description":"Maximum amount of time a request is allowed to take in seconds. Set to -1 for no timeout.","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsOpenAI/openAiLight.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsOpenAI/openAiLight.dark.svg"}},
{"displayName":"Embeddings Ollama","name":"embeddingsOllama","group":["transform"],"version":1,"description":"Use Ollama Embeddings","defaults":{"name":"Embeddings Ollama"},"credentials":[{"name":"ollamaApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.baseUrl.replace(new RegExp(\"/$\"), \"\") }}"},"codex":{"categories":["AI"],"subcategories":{"AI":["Embeddings"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsollama/"}]}},"inputs":[],"outputs":["ai_embedding"],"outputNames":["Embeddings"],"properties":[{"displayName":"This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","default":"llama3.2","description":"The model which will generate the completion. To download models, visit <a href=\"https://ollama.ai/library\">Ollama Models Library</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/api/tags"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"models"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.name}}","value":"={{$responseItem.name}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"required":true}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/embeddings/EmbeddingsOllama/ollama.svg"},
{"displayName":"Anthropic Chat Model","name":"lmChatAnthropic","group":["transform"],"version":[1,1.1,1.2,1.3],"defaultVersion":1.3,"description":"Language Model Anthropic","defaults":{"name":"Anthropic Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatanthropic/"}]},"alias":["claude","sonnet","opus"]},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"anthropicApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","options":[{"name":"Claude 3.5 Sonnet(20241022)","value":"claude-3-5-sonnet-20241022"},{"name":"Claude 3 Opus(20240229)","value":"claude-3-opus-20240229"},{"name":"Claude 3.5 Sonnet(20240620)","value":"claude-3-5-sonnet-20240620"},{"name":"Claude 3 Sonnet(20240229)","value":"claude-3-sonnet-20240229"},{"name":"Claude 3.5 Haiku(20241022)","value":"claude-3-5-haiku-20241022"},{"name":"Claude 3 Haiku(20240307)","value":"claude-3-haiku-20240307"},{"name":"LEGACY: Claude 2","value":"claude-2"},{"name":"LEGACY: Claude 2.1","value":"claude-2.1"},{"name":"LEGACY: Claude Instant 1.2","value":"claude-instant-1.2"},{"name":"LEGACY: Claude Instant 1","value":"claude-instant-1"}],"description":"The model which will generate the completion. <a href=\"https://docs.anthropic.com/claude/docs/models-overview\">Learn more</a>.","default":"claude-2","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Model","name":"model","type":"options","options":[{"name":"Claude 3.5 Sonnet(20241022)","value":"claude-3-5-sonnet-20241022"},{"name":"Claude 3 Opus(20240229)","value":"claude-3-opus-20240229"},{"name":"Claude 3.5 Sonnet(20240620)","value":"claude-3-5-sonnet-20240620"},{"name":"Claude 3 Sonnet(20240229)","value":"claude-3-sonnet-20240229"},{"name":"Claude 3.5 Haiku(20241022)","value":"claude-3-5-haiku-20241022"},{"name":"Claude 3 Haiku(20240307)","value":"claude-3-haiku-20240307"},{"name":"LEGACY: Claude 2","value":"claude-2"},{"name":"LEGACY: Claude 2.1","value":"claude-2.1"},{"name":"LEGACY: Claude Instant 1.2","value":"claude-instant-1.2"},{"name":"LEGACY: Claude Instant 1","value":"claude-instant-1"}],"description":"The model which will generate the completion. <a href=\"https://docs.anthropic.com/claude/docs/models-overview\">Learn more</a>.","default":"claude-3-sonnet-20240229","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Model","name":"model","type":"options","options":[{"name":"Claude 3.5 Sonnet(20241022)","value":"claude-3-5-sonnet-20241022"},{"name":"Claude 3 Opus(20240229)","value":"claude-3-opus-20240229"},{"name":"Claude 3.5 Sonnet(20240620)","value":"claude-3-5-sonnet-20240620"},{"name":"Claude 3 Sonnet(20240229)","value":"claude-3-sonnet-20240229"},{"name":"Claude 3.5 Haiku(20241022)","value":"claude-3-5-haiku-20241022"},{"name":"Claude 3 Haiku(20240307)","value":"claude-3-haiku-20240307"}],"description":"The model which will generate the completion. <a href=\"https://docs.anthropic.com/claude/docs/models-overview\">Learn more</a>.","default":"claude-3-5-sonnet-20240620","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}]}}},{"displayName":"Model","name":"model","type":"resourceLocator","default":{"mode":"list","value":"claude-sonnet-4-20250514","cachedResultName":"Claude 4 Sonnet"},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","placeholder":"Select a model...","typeOptions":{"searchListMethod":"searchModels","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"Claude Sonnet"}],"description":"The model. Choose from the list, or specify an ID. <a href=\"https://docs.anthropic.com/claude/docs/models-overview\">Learn more</a>.","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.3}}]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Maximum Number of Tokens","name":"maxTokensToSample","default":4096,"description":"The maximum number of tokens to generate in the completion","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number","displayOptions":{"hide":{"thinking":[true]}}},{"displayName":"Top K","name":"topK","default":-1,"typeOptions":{"maxValue":1,"minValue":-1,"numberPrecision":1},"description":"Used to remove \"long tail\" low probability responses. Defaults to -1, which disables it.","type":"number","displayOptions":{"hide":{"thinking":[true]}}},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number","displayOptions":{"hide":{"thinking":[true]}}},{"displayName":"Enable Thinking","name":"thinking","type":"boolean","default":false,"description":"Whether to enable thinking mode for the model"},{"displayName":"Thinking Budget (Tokens)","name":"thinkingBudget","type":"number","default":1024,"description":"The maximum number of tokens to use for thinking","displayOptions":{"show":{"thinking":[true]}}}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMChatAnthropic/anthropic.svg"},
{"displayName":"Azure OpenAI Chat Model","name":"lmChatAzureOpenAi","group":["transform"],"version":1,"description":"For advanced usage with an AI chain","defaults":{"name":"Azure OpenAI Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatazureopenai/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"azureOpenAiApi","required":true,"displayOptions":{"show":{"authentication":["azureOpenAiApi"]}}},{"name":"azureEntraCognitiveServicesOAuth2Api","required":true,"displayOptions":{"show":{"authentication":["azureEntraCognitiveServicesOAuth2Api"]}}}],"properties":[{"displayName":"Authentication","name":"authentication","type":"options","default":"azureOpenAiApi","options":[{"name":"API Key","value":"azureOpenAiApi"},{"name":"Azure Entra ID (OAuth2)","value":"azureEntraCognitiveServicesOAuth2Api"}]},{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"If using JSON response format, you must include word \"json\" in the prompt in your chain or agent. Also, make sure to select latest models released post November 2023.","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.responseFormat":["json_object"]}}},{"displayName":"Model (Deployment) Name","name":"model","type":"string","description":"The name of the model(deployment) to use (e.g., gpt-4, gpt-35-turbo)","required":true,"default":""},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768). Use -1 for default.","type":"number","typeOptions":{"maxValue":128000}},{"displayName":"Response Format","name":"responseFormat","default":"text","type":"options","options":[{"name":"Text","value":"text","description":"Regular text response"},{"name":"JSON","value":"json_object","description":"Enables JSON mode, which should guarantee the message the model generates is valid JSON"}]},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":2,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Timeout (Ms)","name":"timeout","default":60000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt on failure","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatAzureOpenAi/azure.svg"},
{"displayName":"AWS Bedrock Chat Model","name":"lmChatAwsBedrock","group":["transform"],"version":[1,1.1],"description":"Language Model AWS Bedrock","defaults":{"name":"AWS Bedrock Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatawsbedrock/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"aws","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"=https://bedrock.{{$credentials?.region ?? \"eu-central-1\"}}.amazonaws.com"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model Source","name":"modelSource","type":"options","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.1}}]}},"options":[{"name":"On-Demand Models","value":"onDemand","description":"Standard foundation models with on-demand pricing"},{"name":"Inference Profiles","value":"inferenceProfile","description":"Cross-region inference profiles (required for models like Claude Sonnet 4 and others)"}],"default":"onDemand","description":"Choose between on-demand foundation models or inference profiles"},{"displayName":"Model","name":"model","type":"options","allowArbitraryValues":true,"description":"The model which will generate the completion. <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/foundation-models.html\">Learn more</a>.","displayOptions":{"hide":{"modelSource":["inferenceProfile"]}},"typeOptions":{"loadOptionsDependsOn":["modelSource"],"loadOptions":{"routing":{"request":{"method":"GET","url":"/foundation-models?&byOutputModality=TEXT&byInferenceType=ON_DEMAND"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"modelSummaries"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.modelName}}","description":"={{$responseItem.modelArn}}","value":"={{$responseItem.modelId}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":""},{"displayName":"Model","name":"model","type":"options","allowArbitraryValues":true,"description":"The inference profile which will generate the completion. <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-use.html\">Learn more</a>.","displayOptions":{"show":{"modelSource":["inferenceProfile"]}},"typeOptions":{"loadOptionsDependsOn":["modelSource"],"loadOptions":{"routing":{"request":{"method":"GET","url":"/inference-profiles?maxResults=1000"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"inferenceProfileSummaries"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.inferenceProfileName}}","description":"={{$responseItem.description || $responseItem.inferenceProfileArn}}","value":"={{$responseItem.inferenceProfileId}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":""},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Maximum Number of Tokens","name":"maxTokensToSample","default":2000,"description":"The maximum number of tokens to generate in the completion","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatAwsBedrock/bedrock.svg"},
{"displayName":"Cohere Chat Model","name":"lmChatCohere","group":["transform"],"version":[1],"description":"For advanced usage with an AI chain","defaults":{"name":"Cohere Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatcohere/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"cohereApi","required":true}],"requestDefaults":{"baseURL":"={{$credentials?.url}}","headers":{"accept":"application/json","authorization":"=Bearer {{$credentials?.apiKey}}"}},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion. <a href=\"https://docs.cohere.com/docs/models\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/v1/models?page_size=100&endpoint=chat"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"models"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.name}}","value":"={{$responseItem.name}}","description":"={{$responseItem.description}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"default":"command-a-03-2025"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":2,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatCohere/cohere.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatCohere/cohere.dark.svg"}},
{"displayName":"DeepSeek Chat Model","name":"lmChatDeepSeek","group":["transform"],"version":[1],"description":"For advanced usage with an AI chain","defaults":{"name":"DeepSeek Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatdeepseek/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"deepSeekApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials?.url }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"If using JSON response format, you must include word \"json\" in the prompt in your chain or agent. Also, make sure to select latest models released post November 2023.","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.responseFormat":["json_object"]}}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion. <a href=\"https://api-docs.deepseek.com/quick_start/pricing\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"deepseek-chat"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Response Format","name":"responseFormat","default":"text","type":"options","options":[{"name":"Text","value":"text","description":"Regular text response"},{"name":"JSON","value":"json_object","description":"Enables JSON mode, which should guarantee the message the model generates is valid JSON"}]},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":2,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Timeout","name":"timeout","default":360000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatDeepSeek/deepseek.svg"},
{"displayName":"Google Gemini Chat Model","name":"lmChatGoogleGemini","group":["transform"],"version":1,"description":"Chat Model Google Gemini","defaults":{"name":"Google Gemini Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"googlePalmApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.host }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"modelName","type":"options","description":"The model which will generate the completion. <a href=\"https://developers.generativeai.google/api/rest/generativelanguage/models/list\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/v1beta/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"models"}},{"type":"filter","properties":{"pass":"={{ !$responseItem.name.includes('embedding') }}"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.name}}","value":"={{$responseItem.name}}","description":"={{$responseItem.description}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"models/gemini-2.5-flash"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Maximum Number of Tokens","name":"maxOutputTokens","default":2048,"description":"The maximum number of tokens to generate in the completion","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.4,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Top K","name":"topK","default":32,"typeOptions":{"maxValue":40,"minValue":-1,"numberPrecision":1},"description":"Used to remove \"long tail\" low probability responses. Defaults to -1, which disables it.","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Safety Settings","name":"safetySettings","type":"fixedCollection","typeOptions":{"multipleValues":true},"default":{"values":{"category":"HARM_CATEGORY_HARASSMENT","threshold":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}},"placeholder":"Add Option","options":[{"name":"values","displayName":"Values","values":[{"displayName":"Safety Category","name":"category","type":"options","description":"The category of harmful content to block","default":"HARM_CATEGORY_UNSPECIFIED","options":[{"value":"HARM_CATEGORY_HARASSMENT","name":"HARM_CATEGORY_HARASSMENT","description":"Harassment content"},{"value":"HARM_CATEGORY_HATE_SPEECH","name":"HARM_CATEGORY_HATE_SPEECH","description":"Hate speech and content"},{"value":"HARM_CATEGORY_SEXUALLY_EXPLICIT","name":"HARM_CATEGORY_SEXUALLY_EXPLICIT","description":"Sexually explicit content"},{"value":"HARM_CATEGORY_DANGEROUS_CONTENT","name":"HARM_CATEGORY_DANGEROUS_CONTENT","description":"Dangerous content"}]},{"displayName":"Safety Threshold","name":"threshold","type":"options","description":"The threshold of harmful content to block","default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","name":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","description":"Threshold is unspecified"},{"value":"BLOCK_LOW_AND_ABOVE","name":"BLOCK_LOW_AND_ABOVE","description":"Content with NEGLIGIBLE will be allowed"},{"value":"BLOCK_MEDIUM_AND_ABOVE","name":"BLOCK_MEDIUM_AND_ABOVE","description":"Content with NEGLIGIBLE and LOW will be allowed"},{"value":"BLOCK_ONLY_HIGH","name":"BLOCK_ONLY_HIGH","description":"Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed"},{"value":"BLOCK_NONE","name":"BLOCK_NONE","description":"All content will be allowed"}]}]}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatGoogleGemini/google.svg"},
{"displayName":"Google Vertex Chat Model","name":"lmChatGoogleVertex","group":["transform"],"version":1,"description":"Chat Model Google Vertex","defaults":{"name":"Google Vertex Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglevertex/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"googleApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Project ID","name":"projectId","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"description":"Select or enter your Google Cloud project ID","modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"gcpProjectsList"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Model Name","name":"modelName","type":"string","description":"The model which will generate the completion. <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\">Learn more</a>.","default":"gemini-2.5-flash"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Maximum Number of Tokens","name":"maxOutputTokens","default":2048,"description":"The maximum number of tokens to generate in the completion","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.4,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Top K","name":"topK","default":32,"typeOptions":{"maxValue":40,"minValue":-1,"numberPrecision":1},"description":"Used to remove \"long tail\" low probability responses. Defaults to -1, which disables it.","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Safety Settings","name":"safetySettings","type":"fixedCollection","typeOptions":{"multipleValues":true},"default":{"values":{"category":"HARM_CATEGORY_HARASSMENT","threshold":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}},"placeholder":"Add Option","options":[{"name":"values","displayName":"Values","values":[{"displayName":"Safety Category","name":"category","type":"options","description":"The category of harmful content to block","default":"HARM_CATEGORY_UNSPECIFIED","options":[{"value":"HARM_CATEGORY_HARASSMENT","name":"HARM_CATEGORY_HARASSMENT","description":"Harassment content"},{"value":"HARM_CATEGORY_HATE_SPEECH","name":"HARM_CATEGORY_HATE_SPEECH","description":"Hate speech and content"},{"value":"HARM_CATEGORY_SEXUALLY_EXPLICIT","name":"HARM_CATEGORY_SEXUALLY_EXPLICIT","description":"Sexually explicit content"},{"value":"HARM_CATEGORY_DANGEROUS_CONTENT","name":"HARM_CATEGORY_DANGEROUS_CONTENT","description":"Dangerous content"}]},{"displayName":"Safety Threshold","name":"threshold","type":"options","description":"The threshold of harmful content to block","default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","name":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","description":"Threshold is unspecified"},{"value":"BLOCK_LOW_AND_ABOVE","name":"BLOCK_LOW_AND_ABOVE","description":"Content with NEGLIGIBLE will be allowed"},{"value":"BLOCK_MEDIUM_AND_ABOVE","name":"BLOCK_MEDIUM_AND_ABOVE","description":"Content with NEGLIGIBLE and LOW will be allowed"},{"value":"BLOCK_ONLY_HIGH","name":"BLOCK_ONLY_HIGH","description":"Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed"},{"value":"BLOCK_NONE","name":"BLOCK_NONE","description":"All content will be allowed"}]}]}]},{"displayName":"Thinking Budget","name":"thinkingBudget","description":"Controls reasoning tokens for thinking models. Set to 0 to disable automatic thinking. Set to -1 for dynamic thinking. Leave empty for auto mode.","type":"number","typeOptions":{"minValue":-1,"numberPrecision":0}}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatGoogleVertex/google.svg"},
{"displayName":"Groq Chat Model","name":"lmChatGroq","group":["transform"],"version":1,"description":"Language Model Groq","defaults":{"name":"Groq Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgroq/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"groqApi","required":true}],"requestDefaults":{"baseURL":"https://api.groq.com/openai/v1"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"filter","properties":{"pass":"={{ $responseItem.active === true && $responseItem.object === \"model\" }}"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"description":"The model which will generate the completion. <a href=\"https://console.groq.com/docs/models\">Learn more</a>.","default":"llama3-8b-8192"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Maximum Number of Tokens","name":"maxTokensToSample","default":4096,"description":"The maximum number of tokens to generate in the completion","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatGroq/groq.svg"},
{"displayName":"Mistral Cloud Chat Model","name":"lmChatMistralCloud","group":["transform"],"version":1,"description":"For advanced usage with an AI chain","defaults":{"name":"Mistral Cloud Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatmistralcloud/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"mistralCloudApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"https://api.mistral.ai/v1"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion. <a href=\"https://docs.mistral.ai/platform/endpoints/\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"filter","properties":{"pass":"={{ !$responseItem.id.includes('embed') }}"}},{"type":"setKeyValue","properties":{"name":"={{ $responseItem.id }}","value":"={{ $responseItem.id }}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"mistral-small"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"},{"displayName":"Enable Safe Mode","name":"safeMode","default":false,"type":"boolean","description":"Whether to inject a safety prompt before all conversations"},{"displayName":"Random Seed","name":"randomSeed","type":"number","description":"The seed to use for random sampling. If set, different calls will generate deterministic results."}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatMistralCloud/mistral.svg"},
{"displayName":"Ollama Chat Model","name":"lmChatOllama","group":["transform"],"version":1,"description":"Language Model Ollama","defaults":{"name":"Ollama Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"ollamaApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.baseUrl.replace(new RegExp(\"/$\"), \"\") }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","default":"llama3.2","description":"The model which will generate the completion. To download models, visit <a href=\"https://ollama.ai/library\">Ollama Models Library</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/api/tags"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"models"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.name}}","value":"={{$responseItem.name}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"required":true},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls the randomness of the generated text. Lower values make the output more focused and deterministic, while higher values make it more diverse and random.","type":"number"},{"displayName":"Top K","name":"topK","default":-1,"typeOptions":{"maxValue":100,"minValue":-1,"numberPrecision":1},"description":"Limits the number of highest probability vocabulary tokens to consider at each step. A higher value increases diversity but may reduce coherence. Set to -1 to disable.","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Chooses from the smallest possible set of tokens whose cumulative probability exceeds the probability top_p. Helps generate more human-like text by reducing repetitions.","type":"number"},{"displayName":"Frequency Penalty","name":"frequencyPenalty","type":"number","default":0,"typeOptions":{"minValue":0},"description":"Adjusts the penalty for tokens that have already appeared in the generated text. Higher values discourage repetition."},{"displayName":"Keep Alive","name":"keepAlive","type":"string","default":"5m","description":"Specifies the duration to keep the loaded model in memory after use. Useful for frequently used models. Format: 1h30m (1 hour 30 minutes)."},{"displayName":"Low VRAM Mode","name":"lowVram","type":"boolean","default":false,"description":"Whether to Activate low VRAM mode, which reduces memory usage at the cost of slower generation speed. Useful for GPUs with limited memory."},{"displayName":"Main GPU ID","name":"mainGpu","type":"number","default":0,"description":"Specifies the ID of the GPU to use for the main computation. Only change this if you have multiple GPUs."},{"displayName":"Context Batch Size","name":"numBatch","type":"number","default":512,"description":"Sets the batch size for prompt processing. Larger batch sizes may improve generation speed but increase memory usage."},{"displayName":"Context Length","name":"numCtx","type":"number","default":2048,"description":"The maximum number of tokens to use as context for generating the next token. Smaller values reduce memory usage, while larger values provide more context to the model."},{"displayName":"Number of GPUs","name":"numGpu","type":"number","default":-1,"description":"Specifies the number of GPUs to use for parallel processing. Set to -1 for auto-detection."},{"displayName":"Max Tokens to Generate","name":"numPredict","type":"number","default":-1,"description":"The maximum number of tokens to generate. Set to -1 for no limit. Be cautious when setting this to a large value, as it can lead to very long outputs."},{"displayName":"Number of CPU Threads","name":"numThread","type":"number","default":0,"description":"Specifies the number of CPU threads to use for processing. Set to 0 for auto-detection."},{"displayName":"Penalize Newlines","name":"penalizeNewline","type":"boolean","default":true,"description":"Whether the model will be less likely to generate newline characters, encouraging longer continuous sequences of text"},{"displayName":"Presence Penalty","name":"presencePenalty","type":"number","default":0,"description":"Adjusts the penalty for tokens based on their presence in the generated text so far. Positive values penalize tokens that have already appeared, encouraging diversity."},{"displayName":"Repetition Penalty","name":"repeatPenalty","type":"number","default":1,"description":"Adjusts the penalty factor for repeated tokens. Higher values more strongly discourage repetition. Set to 1.0 to disable repetition penalty."},{"displayName":"Use Memory Locking","name":"useMLock","type":"boolean","default":false,"description":"Whether to lock the model in memory to prevent swapping. This can improve performance but requires sufficient available memory."},{"displayName":"Use Memory Mapping","name":"useMMap","type":"boolean","default":true,"description":"Whether to use memory mapping for loading the model. This can reduce memory usage but may impact performance. Recommended to keep enabled."},{"displayName":"Load Vocabulary Only","name":"vocabOnly","type":"boolean","default":false,"description":"Whether to only load the model vocabulary without the weights. Useful for quickly testing tokenization."},{"displayName":"Output Format","name":"format","type":"options","options":[{"name":"Default","value":"default"},{"name":"JSON","value":"json"}],"default":"default","description":"Specifies the format of the API response"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMChatOllama/ollama.svg"},
{"displayName":"OpenRouter Chat Model","name":"lmChatOpenRouter","group":["transform"],"version":[1],"description":"For advanced usage with an AI chain","defaults":{"name":"OpenRouter Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenrouter/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"openRouterApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials?.url }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"If using JSON response format, you must include word \"json\" in the prompt in your chain or agent. Also, make sure to select latest models released post November 2023.","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.responseFormat":["json_object"]}}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion. <a href=\"https://openrouter.ai/docs/models\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"openai/gpt-4.1-mini"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Response Format","name":"responseFormat","default":"text","type":"options","options":[{"name":"Text","value":"text","description":"Regular text response"},{"name":"JSON","value":"json_object","description":"Enables JSON mode, which should guarantee the message the model generates is valid JSON"}]},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":2,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Timeout","name":"timeout","default":360000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatOpenRouter/openrouter.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatOpenRouter/openrouter.dark.svg"}},
{"displayName":"Vercel AI Gateway Chat Model","name":"lmChatVercelAiGateway","group":["transform"],"version":[1],"description":"For advanced usage with an AI chain via Vercel AI Gateway","defaults":{"name":"Vercel AI Gateway Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatvercel/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"vercelAiGatewayApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials?.url }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"If using JSON response format, you must include word \"json\" in the prompt in your chain or agent. Also, make sure to select latest models released post November 2023.","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.responseFormat":["json_object"]}}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"openai/gpt-4o"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Response Format","name":"responseFormat","default":"text","type":"options","options":[{"name":"Text","value":"text","description":"Regular text response"},{"name":"JSON","value":"json_object","description":"Enables JSON mode, which should guarantee the message the model generates is valid JSON"}]},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":2,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Timeout","name":"timeout","default":360000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatVercelAiGateway/vercel.dark.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatVercelAiGateway/vercel.svg"}},
{"displayName":"xAI Grok Chat Model","name":"lmChatXAiGrok","group":["transform"],"version":[1],"description":"For advanced usage with an AI chain","defaults":{"name":"xAI Grok Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatxaigrok/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"xAiApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials?.url }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"If using JSON response format, you must include word \"json\" in the prompt in your chain or agent. Also, make sure to select latest models released post November 2023.","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.responseFormat":["json_object"]}}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion. <a href=\"https://docs.x.ai/docs/models\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"grok-2-vision-1212"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Response Format","name":"responseFormat","default":"text","type":"options","options":[{"name":"Text","value":"text","description":"Regular text response"},{"name":"JSON","value":"json_object","description":"Enables JSON mode, which should guarantee the message the model generates is valid JSON"}]},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":2,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Timeout","name":"timeout","default":360000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatXAiGrok/logo.dark.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LmChatXAiGrok/logo.svg"}},
{"displayName":"OpenAI Chat Model","name":"lmChatOpenAi","group":["transform"],"version":[1,1.1,1.2],"description":"For advanced usage with an AI chain","defaults":{"name":"OpenAI Chat Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Chat Models (Recommended)"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"openAiApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $parameter.options?.baseURL?.split(\"/\").slice(0,-1).join(\"/\") || $credentials?.url?.split(\"/\").slice(0,-1).join(\"/\") || \"https://api.openai.com\" }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"If using JSON response format, you must include word \"json\" in the prompt in your chain or agent. Also, make sure to select latest models released post November 2023.","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.responseFormat":["json_object"]}}},{"displayName":"Model","name":"model","type":"options","description":"The model which will generate the completion. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"={{ $parameter.options?.baseURL?.split(\"/\").slice(-1).pop() || $credentials?.url?.split(\"/\").slice(-1).pop() || \"v1\" }}/models"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"data"}},{"type":"filter","properties":{"pass":"={{\n\t\t\t\t\t\t\t\t\t\t\t\t($parameter.options?.baseURL && !$parameter.options?.baseURL?.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t\t\t\t($credentials?.url && !$credentials.url.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t\t\t\t$responseItem.id.startsWith('ft:') ||\n\t\t\t\t\t\t\t\t\t\t\t\t$responseItem.id.startsWith('o1') ||\n\t\t\t\t\t\t\t\t\t\t\t\t$responseItem.id.startsWith('o3') ||\n\t\t\t\t\t\t\t\t\t\t\t\t($responseItem.id.startsWith('gpt-') && !$responseItem.id.includes('instruct'))\n\t\t\t\t\t\t\t\t\t\t\t}}"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.id}}","value":"={{$responseItem.id}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"default":"gpt-4o-mini","displayOptions":{"hide":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Model","name":"model","type":"resourceLocator","default":{"mode":"list","value":"gpt-4.1-mini"},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","placeholder":"Select a model...","typeOptions":{"searchListMethod":"searchModels","searchable":true}},{"displayName":"ID","name":"id","type":"string","placeholder":"gpt-4.1-mini"}],"description":"The model. Choose from the list, or specify an ID.","displayOptions":{"hide":{"@version":[{"_cnd":{"lte":1.1}}]}}},{"displayName":"When using non-OpenAI models via \"Base URL\" override, not all models might be chat-compatible or support other features, like tools calling or JSON response format","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.baseURL":[{"_cnd":{"exists":true}}]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Base URL","name":"baseURL","default":"https://api.openai.com/v1","description":"Override the default base URL for the API","type":"string","displayOptions":{"hide":{"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Response Format","name":"responseFormat","default":"text","type":"options","options":[{"name":"Text","value":"text","description":"Regular text response"},{"name":"JSON","value":"json_object","description":"Enables JSON mode, which should guarantee the message the model generates is valid JSON"}]},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":2,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Reasoning Effort","name":"reasoningEffort","default":"medium","description":"Controls the amount of reasoning tokens to use. A value of \"low\" will favor speed and economical token usage, \"high\" will favor more complete reasoning at the cost of more tokens generated and slower responses.","type":"options","options":[{"name":"Low","value":"low","description":"Favors speed and economical token usage"},{"name":"Medium","value":"medium","description":"Balance between speed and reasoning accuracy"},{"name":"High","value":"high","description":"Favors more complete reasoning at the cost of more tokens generated and slower responses"}],"displayOptions":{"show":{"/model":[{"_cnd":{"regex":"(^o1([-\\d]+)?$)|(^o[3-9].*)|(^gpt-5.*)"}}]}}},{"displayName":"Timeout","name":"timeout","default":60000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMChatOpenAi/openAiLight.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMChatOpenAi/openAiLight.dark.svg"}},
{"displayName":"OpenAI Model","name":"lmOpenAi","hidden":true,"group":["transform"],"version":1,"description":"For advanced usage with an AI chain","defaults":{"name":"OpenAI Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Text Completion Models"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmopenai/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"openAiApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $parameter.options?.baseURL?.split(\"/\").slice(0,-1).join(\"/\") || \"https://api.openai.com\" }}"},"properties":[{"displayName":"This node is using OpenAI completions which are now deprecated. Please use the OpenAI Chat Model node instead.","name":"deprecated","type":"notice","default":""},{"displayName":"Model","name":"model","type":"resourceLocator","default":{"mode":"list","value":"gpt-3.5-turbo-instruct"},"required":true,"description":"The model which will generate the completion. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.","modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"openAiModelSearch"}},{"displayName":"ID","name":"id","type":"string"}],"routing":{"send":{"type":"body","property":"model","value":"={{$parameter.model.value}}"}}},{"displayName":"When using non OpenAI models via Base URL override, not all models might be chat-compatible or support other features, like tools calling or JSON response format.","name":"notice","type":"notice","default":"","displayOptions":{"show":{"/options.baseURL":[{"_cnd":{"exists":true}}]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Base URL","name":"baseURL","default":"https://api.openai.com/v1","description":"Override the default base URL for the API","type":"string"},{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":-1,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Timeout","name":"timeout","default":60000,"description":"Maximum amount of time a request is allowed to take in milliseconds","type":"number"},{"displayName":"Max Retries","name":"maxRetries","default":2,"description":"Maximum number of retries to attempt","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMOpenAi/openAiLight.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMOpenAi/openAiLight.dark.svg"}},
{"displayName":"Cohere Model","name":"lmCohere","group":["transform"],"version":1,"description":"Language Model Cohere","defaults":{"name":"Cohere Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Text Completion Models"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmcohere/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"cohereApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":250,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Model","name":"model","type":"string","description":"The name of the model to use","default":""},{"displayName":"Sampling Temperature","name":"temperature","default":0,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMCohere/cohere.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMCohere/cohere.dark.svg"}},
{"displayName":"Ollama Model","name":"lmOllama","group":["transform"],"version":1,"description":"Language Model Ollama","defaults":{"name":"Ollama Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Text Completion Models"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmollama/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"ollamaApi","required":true}],"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.baseUrl.replace(new RegExp(\"/$\"), \"\") }}"},"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"options","default":"llama3.2","description":"The model which will generate the completion. To download models, visit <a href=\"https://ollama.ai/library\">Ollama Models Library</a>.","typeOptions":{"loadOptions":{"routing":{"request":{"method":"GET","url":"/api/tags"},"output":{"postReceive":[{"type":"rootProperty","properties":{"property":"models"}},{"type":"setKeyValue","properties":{"name":"={{$responseItem.name}}","value":"={{$responseItem.name}}"}},{"type":"sort","properties":{"key":"name"}}]}}}},"routing":{"send":{"type":"body","property":"model"}},"required":true},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Sampling Temperature","name":"temperature","default":0.7,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls the randomness of the generated text. Lower values make the output more focused and deterministic, while higher values make it more diverse and random.","type":"number"},{"displayName":"Top K","name":"topK","default":-1,"typeOptions":{"maxValue":100,"minValue":-1,"numberPrecision":1},"description":"Limits the number of highest probability vocabulary tokens to consider at each step. A higher value increases diversity but may reduce coherence. Set to -1 to disable.","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Chooses from the smallest possible set of tokens whose cumulative probability exceeds the probability top_p. Helps generate more human-like text by reducing repetitions.","type":"number"},{"displayName":"Frequency Penalty","name":"frequencyPenalty","type":"number","default":0,"typeOptions":{"minValue":0},"description":"Adjusts the penalty for tokens that have already appeared in the generated text. Higher values discourage repetition."},{"displayName":"Keep Alive","name":"keepAlive","type":"string","default":"5m","description":"Specifies the duration to keep the loaded model in memory after use. Useful for frequently used models. Format: 1h30m (1 hour 30 minutes)."},{"displayName":"Low VRAM Mode","name":"lowVram","type":"boolean","default":false,"description":"Whether to Activate low VRAM mode, which reduces memory usage at the cost of slower generation speed. Useful for GPUs with limited memory."},{"displayName":"Main GPU ID","name":"mainGpu","type":"number","default":0,"description":"Specifies the ID of the GPU to use for the main computation. Only change this if you have multiple GPUs."},{"displayName":"Context Batch Size","name":"numBatch","type":"number","default":512,"description":"Sets the batch size for prompt processing. Larger batch sizes may improve generation speed but increase memory usage."},{"displayName":"Context Length","name":"numCtx","type":"number","default":2048,"description":"The maximum number of tokens to use as context for generating the next token. Smaller values reduce memory usage, while larger values provide more context to the model."},{"displayName":"Number of GPUs","name":"numGpu","type":"number","default":-1,"description":"Specifies the number of GPUs to use for parallel processing. Set to -1 for auto-detection."},{"displayName":"Max Tokens to Generate","name":"numPredict","type":"number","default":-1,"description":"The maximum number of tokens to generate. Set to -1 for no limit. Be cautious when setting this to a large value, as it can lead to very long outputs."},{"displayName":"Number of CPU Threads","name":"numThread","type":"number","default":0,"description":"Specifies the number of CPU threads to use for processing. Set to 0 for auto-detection."},{"displayName":"Penalize Newlines","name":"penalizeNewline","type":"boolean","default":true,"description":"Whether the model will be less likely to generate newline characters, encouraging longer continuous sequences of text"},{"displayName":"Presence Penalty","name":"presencePenalty","type":"number","default":0,"description":"Adjusts the penalty for tokens based on their presence in the generated text so far. Positive values penalize tokens that have already appeared, encouraging diversity."},{"displayName":"Repetition Penalty","name":"repeatPenalty","type":"number","default":1,"description":"Adjusts the penalty factor for repeated tokens. Higher values more strongly discourage repetition. Set to 1.0 to disable repetition penalty."},{"displayName":"Use Memory Locking","name":"useMLock","type":"boolean","default":false,"description":"Whether to lock the model in memory to prevent swapping. This can improve performance but requires sufficient available memory."},{"displayName":"Use Memory Mapping","name":"useMMap","type":"boolean","default":true,"description":"Whether to use memory mapping for loading the model. This can reduce memory usage but may impact performance. Recommended to keep enabled."},{"displayName":"Load Vocabulary Only","name":"vocabOnly","type":"boolean","default":false,"description":"Whether to only load the model vocabulary without the weights. Useful for quickly testing tokenization."},{"displayName":"Output Format","name":"format","type":"options","options":[{"name":"Default","value":"default"},{"name":"JSON","value":"json"}],"default":"default","description":"Specifies the format of the API response"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMOllama/ollama.svg"},
{"displayName":"Hugging Face Inference Model","name":"lmOpenHuggingFaceInference","group":["transform"],"version":1,"description":"Language Model HuggingFaceInference","defaults":{"name":"Hugging Face Inference Model"},"codex":{"categories":["AI"],"subcategories":{"AI":["Language Models","Root Nodes"],"Language Models":["Text Completion Models"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmopenhuggingfaceinference/"}]}},"inputs":[],"outputs":["ai_languageModel"],"outputNames":["Model"],"credentials":[{"name":"huggingFaceApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Model","name":"model","type":"string","default":"mistralai/Mistral-Nemo-Base-2407"},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Custom Inference Endpoint","name":"endpointUrl","default":"","description":"Custom endpoint URL","type":"string"},{"displayName":"Frequency Penalty","name":"frequencyPenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim","type":"number"},{"displayName":"Maximum Number of Tokens","name":"maxTokens","default":128,"description":"The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).","type":"number","typeOptions":{"maxValue":32768}},{"displayName":"Presence Penalty","name":"presencePenalty","default":0,"typeOptions":{"maxValue":2,"minValue":-2,"numberPrecision":1},"description":"Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics","type":"number"},{"displayName":"Sampling Temperature","name":"temperature","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.","type":"number"},{"displayName":"Top K","name":"topK","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls the top tokens to consider within the sample operation to create new text","type":"number"},{"displayName":"Top P","name":"topP","default":1,"typeOptions":{"maxValue":1,"minValue":0,"numberPrecision":1},"description":"Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.","type":"number"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/llms/LMOpenHuggingFaceInference/huggingface.svg"},
{"displayName":"MCP Client Tool","name":"mcpClientTool","group":["output"],"version":[1,1.1,1.2],"description":"Connect tools from an MCP Server","defaults":{"name":"MCP Client"},"codex":{"categories":["AI"],"subcategories":{"AI":["Model Context Protocol","Tools"]},"alias":["Model Context Protocol","MCP Client"],"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolmcp/"}]}},"inputs":[],"outputs":[{"type":"ai_tool","displayName":"Tools"}],"credentials":[{"name":"httpBearerAuth","required":true,"displayOptions":{"show":{"authentication":["bearerAuth"]}}},{"name":"httpHeaderAuth","required":true,"displayOptions":{"show":{"authentication":["headerAuth"]}}}],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"SSE Endpoint","name":"sseEndpoint","type":"string","description":"SSE Endpoint of your MCP server","placeholder":"e.g. https://my-mcp-server.ai/sse","default":"","required":true,"displayOptions":{"show":{"@version":[1]}}},{"displayName":"Endpoint","name":"endpointUrl","type":"string","description":"Endpoint of your MCP server","placeholder":"e.g. https://my-mcp-server.ai/mcp","default":"","required":true,"displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Server Transport","name":"serverTransport","type":"options","options":[{"name":"HTTP Streamable","value":"httpStreamable"},{"name":"Server Sent Events (Deprecated)","value":"sse"}],"default":"sse","description":"The transport used by your endpoint","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Server Transport","name":"serverTransport","type":"options","options":[{"name":"HTTP Streamable","value":"httpStreamable"},{"name":"Server Sent Events (Deprecated)","value":"sse"}],"default":"httpStreamable","description":"The transport used by your endpoint","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Authentication","name":"authentication","type":"options","options":[{"name":"Bearer Auth","value":"bearerAuth"},{"name":"Header Auth","value":"headerAuth"},{"name":"None","value":"none"}],"default":"none","description":"The way to authenticate with your endpoint"},{"displayName":"Credentials","name":"credentials","type":"credentials","default":"","displayOptions":{"show":{"authentication":["headerAuth","bearerAuth"]}}},{"displayName":"Tools to Include","name":"include","type":"options","description":"How to select the tools you want to be exposed to the AI Agent","default":"all","options":[{"name":"All","value":"all","description":"Also include all unchanged fields from the input"},{"name":"Selected","value":"selected","description":"Also include the tools listed in the parameter \"Tools to Include\""},{"name":"All Except","value":"except","description":"Exclude the tools listed in the parameter \"Tools to Exclude\""}]},{"displayName":"Tools to Include","name":"includeTools","type":"multiOptions","default":[],"description":"Choose from the list, or specify IDs using an <a href=\"https://docs.n8n.io/code/expressions/\">expression</a>","typeOptions":{"loadOptionsMethod":"getTools","loadOptionsDependsOn":["sseEndpoint"]},"displayOptions":{"show":{"include":["selected"]}}},{"displayName":"Tools to Exclude","name":"excludeTools","type":"multiOptions","default":[],"description":"Choose from the list, or specify IDs using an <a href=\"https://docs.n8n.io/code/expressions/\">expression</a>","typeOptions":{"loadOptionsMethod":"getTools"},"displayOptions":{"show":{"include":["except"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Timeout","name":"timeout","type":"number","typeOptions":{"minValue":1},"default":60000,"description":"Time in ms to wait for tool calls to finish"}]}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/mcp/mcp.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/mcp/mcp.dark.svg"}},
{"displayName":"MCP Server Trigger","name":"mcpTrigger","group":["trigger"],"version":[1,1.1,2],"description":"Expose n8n tools as an MCP Server endpoint","activationMessage":"You can now connect your MCP Clients to the URL, using SSE or Streamable HTTP transports.","defaults":{"name":"MCP Server Trigger"},"codex":{"categories":["AI","Core Nodes"],"subcategories":{"AI":["Root Nodes","Model Context Protocol"],"Core Nodes":["Other Trigger Nodes"]},"alias":["Model Context Protocol","MCP Server"],"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.mcptrigger/"}]}},"triggerPanel":{"header":"Listen for MCP events","executionsHelp":{"inactive":"This trigger has two modes: test and production.<br /><br /><b>Use test mode while you build your workflow</b>. Click the 'execute step' button, then make an MCP request to the test URL. The executions will show up in the editor.<br /><br /><b>Use production mode to run your workflow automatically</b>. <a data-key='activate'>Activate</a> the workflow, then make requests to the production URL. These executions will show up in the <a data-key='executions'>executions list</a>, but not the editor.","active":"This trigger has two modes: test and production.<br /><br /><b>Use test mode while you build your workflow</b>. Click the 'execute step' button, then make an MCP request to the test URL. The executions will show up in the editor.<br /><br /><b>Use production mode to run your workflow automatically</b>. Since your workflow is activated, you can make requests to the production URL. These executions will show up in the <a data-key='executions'>executions list</a>, but not the editor."},"activationHint":"Once youve finished building your workflow, run it without having to click this button by using the production URL."},"inputs":[{"type":"ai_tool","displayName":"Tools"}],"outputs":[],"credentials":[{"name":"httpBearerAuth","required":true,"displayOptions":{"show":{"authentication":["bearerAuth"]}}},{"name":"httpHeaderAuth","required":true,"displayOptions":{"show":{"authentication":["headerAuth"]}}}],"properties":[{"displayName":"Authentication","name":"authentication","type":"options","options":[{"name":"None","value":"none"},{"name":"Bearer Auth","value":"bearerAuth"},{"name":"Header Auth","value":"headerAuth"}],"default":"none","description":"The way to authenticate"},{"displayName":"Path","name":"path","type":"string","default":"","placeholder":"webhook","required":true,"description":"The base path for this MCP server"}],"webhooks":[{"name":"setup","httpMethod":"GET","responseMode":"onReceived","isFullPath":true,"path":"={{$parameter[\"path\"]}}{{parseFloat($nodeVersion)<2 ? '/sse' : ''}}","nodeType":"mcp","ndvHideMethod":true,"ndvHideUrl":false},{"name":"default","httpMethod":"POST","responseMode":"onReceived","isFullPath":true,"path":"={{$parameter[\"path\"]}}{{parseFloat($nodeVersion)<2 ? '/messages' : ''}}","nodeType":"mcp","ndvHideMethod":true,"ndvHideUrl":true},{"name":"default","httpMethod":"DELETE","responseMode":"onReceived","isFullPath":true,"path":"={{$parameter[\"path\"]}}","nodeType":"mcp","ndvHideMethod":true,"ndvHideUrl":true}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/mcp/mcp.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/mcp/mcp.dark.svg"}},
{"displayName":"Simple Memory","name":"memoryBufferWindow","icon":"fa:database","iconColor":"black","group":["transform"],"version":[1,1.1,1.2,1.3],"description":"Stores in n8n memory, so no credentials required","defaults":{"name":"Simple Memory"},"codex":{"categories":["AI"],"subcategories":{"AI":["Memory"],"Memory":["For beginners"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"}]}},"inputs":[],"outputs":["ai_memory"],"outputNames":["Memory"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Session Key","name":"sessionKey","type":"string","default":"chat_history","description":"The key to use to store the memory in the workflow data","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Session ID","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","description":"The key to use to store the memory","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Session ID","name":"sessionIdType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"fromInput","description":"Looks for an input field called 'sessionId' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"customKey","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"fromInput","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Session Key From Previous Node","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","disabledOptions":{"show":{"sessionIdType":["fromInput"]}},"displayOptions":{"show":{"sessionIdType":["fromInput"],"@version":[{"_cnd":{"gte":1.3}}]}}},{"displayName":"Key","name":"sessionKey","type":"string","default":"","description":"The key to use to store session ID in the memory","displayOptions":{"show":{"sessionIdType":["customKey"]}}},{"displayName":"Context Window Length","name":"contextWindowLength","type":"number","default":5,"hint":"How many past interactions the model receives as context"}]},
{"displayName":"Motorhead","name":"memoryMotorhead","icon":"fa:file-export","iconColor":"black","group":["transform"],"version":[1,1.1,1.2,1.3],"description":"Use Motorhead Memory","defaults":{"name":"Motorhead"},"codex":{"categories":["AI"],"subcategories":{"AI":["Memory"],"Memory":["Other memories"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorymotorhead/"}]}},"inputs":[],"outputs":["ai_memory"],"outputNames":["Memory"],"credentials":[{"name":"motorheadApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Session ID","name":"sessionId","type":"string","required":true,"default":"","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Session ID","name":"sessionId","type":"string","default":"={{ $json.sessionId }}","description":"The key to use to store the memory","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Session ID","name":"sessionIdType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"fromInput","description":"Looks for an input field called 'sessionId' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"customKey","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"fromInput","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Session Key From Previous Node","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","disabledOptions":{"show":{"sessionIdType":["fromInput"]}},"displayOptions":{"show":{"sessionIdType":["fromInput"],"@version":[{"_cnd":{"gte":1.3}}]}}},{"displayName":"Key","name":"sessionKey","type":"string","default":"","description":"The key to use to store session ID in the memory","displayOptions":{"show":{"sessionIdType":["customKey"]}}}]},
{"displayName":"Postgres Chat Memory","name":"memoryPostgresChat","group":["transform"],"version":[1,1.1,1.2,1.3],"description":"Stores the chat history in Postgres table.","defaults":{"name":"Postgres Chat Memory"},"credentials":[{"name":"postgres","required":true,"testedBy":"postgresConnectionTest"}],"codex":{"categories":["AI"],"subcategories":{"AI":["Memory"],"Memory":["Other memories"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat/"}]}},"inputs":[],"outputs":["ai_memory"],"outputNames":["Memory"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Session ID","name":"sessionIdType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"fromInput","description":"Looks for an input field called 'sessionId' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"customKey","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"fromInput"},{"displayName":"Session Key From Previous Node","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","disabledOptions":{"show":{"sessionIdType":["fromInput"]}},"displayOptions":{"show":{"sessionIdType":["fromInput"],"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Key","name":"sessionKey","type":"string","default":"","description":"The key to use to store session ID in the memory","displayOptions":{"show":{"sessionIdType":["customKey"]}}},{"displayName":"Table Name","name":"tableName","type":"string","default":"n8n_chat_histories","description":"The table name to store the chat history in. If table does not exist, it will be created."},{"displayName":"Context Window Length","name":"contextWindowLength","type":"number","default":5,"hint":"How many past interactions the model receives as context","displayOptions":{"hide":{"@version":[{"_cnd":{"lt":1.1}}]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/memory/MemoryPostgresChat/postgres.svg"},
{"displayName":"MongoDB Chat Memory","name":"memoryMongoDbChat","group":["transform"],"version":[1],"description":"Stores the chat history in MongoDB collection.","defaults":{"name":"MongoDB Chat Memory"},"credentials":[{"name":"mongoDb","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Memory"],"Memory":["Other memories"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorymongochat/"}]}},"inputs":[],"outputs":["ai_memory"],"outputNames":["Memory"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Session ID","name":"sessionIdType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"fromInput","description":"Looks for an input field called 'sessionId' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"customKey","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"fromInput"},{"displayName":"Session Key From Previous Node","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","disabledOptions":{"show":{"sessionIdType":["fromInput"]}},"displayOptions":{"show":{"sessionIdType":["fromInput"],"@version":[{"_cnd":{"gte":1}}]}}},{"displayName":"Key","name":"sessionKey","type":"string","default":"","description":"The key to use to store session ID in the memory","displayOptions":{"show":{"sessionIdType":["customKey"]}}},{"displayName":"Collection Name","name":"collectionName","type":"string","default":"n8n_chat_histories","description":"The collection name to store the chat history in. If collection does not exist, it will be created."},{"displayName":"Database Name","name":"databaseName","type":"string","default":"","description":"The database name to store the chat history in. If not provided, the database from credentials will be used."},{"displayName":"Context Window Length","name":"contextWindowLength","type":"number","default":5,"hint":"How many past interactions the model receives as context"}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/memory/MemoryMongoDbChat/mongodb.svg"},
{"displayName":"Redis Chat Memory","name":"memoryRedisChat","group":["transform"],"version":[1,1.1,1.2,1.3,1.4,1.5],"description":"Stores the chat history in Redis.","defaults":{"name":"Redis Chat Memory"},"credentials":[{"name":"redis","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Memory"],"Memory":["Other memories"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryredischat/"}]}},"inputs":[],"outputs":["ai_memory"],"outputNames":["Memory"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Session Key","name":"sessionKey","type":"string","default":"chat_history","description":"The key to use to store the memory in the workflow data","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Session ID","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","description":"The key to use to store the memory","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Session ID","name":"sessionIdType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"fromInput","description":"Looks for an input field called 'sessionId' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"customKey","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"fromInput","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Session Key From Previous Node","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","disabledOptions":{"show":{"sessionIdType":["fromInput"]}},"displayOptions":{"show":{"sessionIdType":["fromInput"],"@version":[{"_cnd":{"gte":1.4}}]}}},{"displayName":"Key","name":"sessionKey","type":"string","default":"","description":"The key to use to store session ID in the memory","displayOptions":{"show":{"sessionIdType":["customKey"]}}},{"displayName":"Session Time To Live","name":"sessionTTL","type":"number","default":0,"description":"For how long the session should be stored in seconds. If set to 0 it will not expire."},{"displayName":"Context Window Length","name":"contextWindowLength","type":"number","default":5,"hint":"How many past interactions the model receives as context","displayOptions":{"hide":{"@version":[{"_cnd":{"lt":1.3}}]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/memory/MemoryRedisChat/redis.svg"},
{"displayName":"Chat Memory Manager","name":"memoryManager","icon":"fa:database","iconColor":"black","group":["transform"],"version":[1,1.1],"description":"Manage chat messages memory and use it in the workflow","defaults":{"name":"Chat Memory Manager"},"codex":{"categories":["AI"],"subcategories":{"AI":["Miscellaneous","Root Nodes"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorymanager/"}]}},"inputs":[{"displayName":"","type":"main"},{"displayName":"Memory","type":"ai_memory","required":true,"maxConnections":1}],"outputs":[{"displayName":"","type":"main"}],"properties":[{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"load","options":[{"name":"Get Many Messages","description":"Retrieve chat messages from connected memory","value":"load"},{"name":"Insert Messages","description":"Insert chat messages into connected memory","value":"insert"},{"name":"Delete Messages","description":"Delete chat messages from connected memory","value":"delete"}]},{"displayName":"Insert Mode","name":"insertMode","type":"options","description":"Choose how new messages are inserted into the memory","noDataExpression":true,"default":"insert","options":[{"name":"Insert Messages","value":"insert","description":"Add messages alongside existing ones"},{"name":"Override All Messages","value":"override","description":"Replace the current memory with new messages"}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Delete Mode","name":"deleteMode","type":"options","description":"How messages are deleted from memory","noDataExpression":true,"default":"lastN","options":[{"name":"Last N","value":"lastN","description":"Delete the last N messages"},{"name":"All Messages","value":"all","description":"Clear all messages from memory"}],"displayOptions":{"show":{"mode":["delete"]}}},{"displayName":"Chat Messages","name":"messages","description":"Chat messages to insert into memory","type":"fixedCollection","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add message","options":[{"name":"messageValues","displayName":"Message","values":[{"displayName":"Type Name or ID","name":"type","type":"options","options":[{"name":"AI","value":"ai"},{"name":"System","value":"system"},{"name":"User","value":"user"}],"default":"system"},{"displayName":"Message","name":"message","type":"string","required":true,"default":""},{"displayName":"Hide Message in Chat","name":"hideFromUI","type":"boolean","required":true,"default":false,"description":"Whether to hide the message from the chat UI"}]}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Messages Count","name":"lastMessagesCount","type":"number","description":"The amount of last messages to delete","default":2,"displayOptions":{"show":{"mode":["delete"],"deleteMode":["lastN"]}}},{"displayName":"Simplify Output","name":"simplifyOutput","type":"boolean","description":"Whether to simplify the output to only include the sender and the text","default":true,"displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Options","name":"options","placeholder":"Add Option","type":"collection","default":{},"options":[{"displayName":"Group Messages","name":"groupMessages","type":"boolean","default":true,"description":"Whether to group messages into a single item or return each message as a separate item"}],"displayOptions":{"show":{"mode":["load"]}}}]},
{"displayName":"Chat Messages Retriever","name":"memoryChatRetriever","icon":"fa:database","iconColor":"black","group":["transform"],"hidden":true,"version":1,"description":"Retrieve chat messages from memory and use them in the workflow","defaults":{"name":"Chat Messages Retriever"},"codex":{"categories":["AI"],"subcategories":{"AI":["Miscellaneous"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorymanager/"}]}},"inputs":["main",{"displayName":"Memory","maxConnections":1,"type":"ai_memory","required":true}],"outputs":["main"],"properties":[{"displayName":"This node is deprecated. Use 'Chat Memory Manager' node instead.","type":"notice","default":"","name":"deprecatedNotice"},{"displayName":"Simplify Output","name":"simplifyOutput","type":"boolean","description":"Whether to simplify the output to only include the sender and the text","default":true}]},
{"displayName":"Xata","name":"memoryXata","group":["transform"],"version":[1,1.1,1.2,1.3,1.4],"description":"Use Xata Memory","defaults":{"name":"Xata","color":"#1321A7"},"codex":{"categories":["AI"],"subcategories":{"AI":["Memory"],"Memory":["Other memories"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryxata/"}]}},"inputs":[],"outputs":["ai_memory"],"outputNames":["Memory"],"credentials":[{"name":"xataApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Session ID","name":"sessionId","type":"string","required":true,"default":"","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Session ID","name":"sessionId","type":"string","default":"={{ $json.sessionId }}","description":"The key to use to store the memory","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Session ID","name":"sessionIdType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"fromInput","description":"Looks for an input field called 'sessionId' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"customKey","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"fromInput","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Key","name":"sessionKey","type":"string","default":"","description":"The key to use to store session ID in the memory","displayOptions":{"show":{"sessionIdType":["customKey"]}}},{"displayName":"Session Key From Previous Node","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","disabledOptions":{"show":{"sessionIdType":["fromInput"]}},"displayOptions":{"show":{"sessionIdType":["fromInput"],"@version":[{"_cnd":{"gte":1.4}}]}}},{"displayName":"Context Window Length","name":"contextWindowLength","type":"number","default":5,"hint":"How many past interactions the model receives as context","displayOptions":{"hide":{"@version":[{"_cnd":{"lt":1.3}}]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/memory/MemoryXata/xata.svg"},
{"displayName":"Zep","name":"memoryZep","hidden":true,"group":["transform"],"version":[1,1.1,1.2,1.3],"description":"Use Zep Memory","defaults":{"name":"Zep"},"codex":{"categories":["AI"],"subcategories":{"AI":["Memory"],"Memory":["Other memories"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryzep/"}]}},"inputs":[],"outputs":["ai_memory"],"outputNames":["Memory"],"credentials":[{"name":"zepApi","required":true}],"properties":[{"displayName":"This Zep integration is deprecated and will be removed in a future version.","name":"deprecationNotice","type":"notice","default":""},{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Only works with Zep Cloud and Community edition <= v0.27.2","name":"supportedVersions","type":"notice","default":""},{"displayName":"Session ID","name":"sessionId","type":"string","required":true,"default":"","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Session ID","name":"sessionId","type":"string","default":"={{ $json.sessionId }}","description":"The key to use to store the memory","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Session ID","name":"sessionIdType","type":"options","options":[{"name":"Connected Chat Trigger Node","value":"fromInput","description":"Looks for an input field called 'sessionId' that is coming from a directly connected Chat Trigger"},{"name":"Define below","value":"customKey","description":"Use an expression to reference data in previous nodes or enter static text"}],"default":"fromInput","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"Session Key From Previous Node","name":"sessionKey","type":"string","default":"={{ $json.sessionId }}","disabledOptions":{"show":{"sessionIdType":["fromInput"]}},"displayOptions":{"show":{"sessionIdType":["fromInput"],"@version":[{"_cnd":{"gte":1.3}}]}}},{"displayName":"Key","name":"sessionKey","type":"string","default":"","description":"The key to use to store session ID in the memory","displayOptions":{"show":{"sessionIdType":["customKey"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/memory/MemoryZep/zep.png"},
{"displayName":"Auto-fixing Output Parser","name":"outputParserAutofixing","icon":"fa:tools","iconColor":"black","group":["transform"],"version":1,"description":"Deprecated, use structured output parser","defaults":{"name":"Auto-fixing Output Parser"},"codex":{"categories":["AI"],"subcategories":{"AI":["Output Parsers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/"}]}},"inputs":[{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true},{"displayName":"Output Parser","maxConnections":1,"required":true,"type":"ai_outputParser"}],"outputs":["ai_outputParser"],"outputNames":["Output Parser"],"properties":[{"displayName":"This node wraps another output parser. If the first one fails it calls an LLM to fix the format","name":"info","type":"notice","default":""},{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Retry Prompt","name":"prompt","type":"string","default":"Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:","typeOptions":{"rows":10},"hint":"Should include \"{error}\", \"{instructions}\", and \"{completion}\" placeholders","description":"Prompt template used for fixing the output. Uses placeholders: \"{instructions}\" for parsing rules, \"{completion}\" for the failed attempt, and \"{error}\" for the validation error message."}]}]},
{"displayName":"Item List Output Parser","name":"outputParserItemList","icon":"fa:bars","iconColor":"black","group":["transform"],"version":1,"description":"Return the results as separate items","defaults":{"name":"Item List Output Parser"},"codex":{"categories":["AI"],"subcategories":{"AI":["Output Parsers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparseritemlist/"}]}},"inputs":[],"outputs":["ai_outputParser"],"outputNames":["Output Parser"],"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Number Of Items","name":"numberOfItems","type":"number","default":-1,"description":"Defines how many items should be returned maximally. If set to -1, there is no limit."},{"displayName":"Separator","name":"separator","type":"string","default":"\\n","description":"Defines the separator that should be used to split the results into separate items. Defaults to a new line but can be changed depending on the data that should be returned."}]}]},
{"displayName":"Structured Output Parser","name":"outputParserStructured","icon":"fa:code","iconColor":"black","group":["transform"],"version":[1,1.1,1.2,1.3],"defaultVersion":1.3,"description":"Return data in a defined JSON format","defaults":{"name":"Structured Output Parser"},"codex":{"alias":["json","zod"],"categories":["AI"],"subcategories":{"AI":["Output Parsers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"}]}},"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tif (parameters?.autoFix) {\n\t\t\t\t\treturn [\n\t\t\t\t\t\t{ displayName: 'Model', maxConnections: 1, type: \"ai_languageModel\", required: true }\n\t\t\t\t\t];\n\t\t\t\t}\n\n\t\t\t\treturn [];\n\t\t\t})($parameter)\n\t\t}}","outputs":["ai_outputParser"],"outputNames":["Output Parser"],"properties":[{"displayName":"This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Schema Type","name":"schemaType","type":"options","noDataExpression":true,"options":[{"name":"Generate From JSON Example","value":"fromJson","description":"Generate a schema from an example JSON object"},{"name":"Define using JSON Schema","value":"manual","description":"Define the JSON schema manually"}],"default":"fromJson","description":"How to specify the schema for the function","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}}},{"displayName":"JSON Example","name":"jsonSchemaExample","type":"json","default":"{\n\t\"state\": \"California\",\n\t\"cities\": [\"Los Angeles\", \"San Francisco\", \"San Diego\"]\n}","noDataExpression":true,"typeOptions":{"rows":10},"displayOptions":{"show":{"schemaType":["fromJson"]}},"description":"Example JSON object to use to generate the schema"},{"displayName":"All properties will be required. To make them optional, use the 'JSON Schema' schema type instead","name":"notice","type":"notice","default":"","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.3}}],"schemaType":["fromJson"]}}},{"displayName":"Input Schema","name":"inputSchema","type":"json","default":"{\n\t\"type\": \"object\",\n\t\"properties\": {\n\t\t\"state\": {\n\t\t\t\"type\": \"string\"\n\t\t},\n\t\t\"cities\": {\n\t\t\t\"type\": \"array\",\n\t\t\t\"items\": {\n\t\t\t\t\"type\": \"string\"\n\t\t\t}\n\t\t}\n\t}\n}","noDataExpression":false,"typeOptions":{"rows":10},"displayOptions":{"show":{"schemaType":["manual"]}},"description":"Schema to use for the function","hint":"Use <a target=\"_blank\" href=\"https://json-schema.org/\">JSON Schema</a> format (<a target=\"_blank\" href=\"https://json-schema.org/learn/miscellaneous-examples.html\">examples</a>). $refs syntax is currently not supported."},{"displayName":"JSON Schema","name":"jsonSchema","type":"json","description":"JSON Schema to structure and validate the output against","default":"{\n  \"type\": \"object\",\n  \"properties\": {\n    \"state\": {\n      \"type\": \"string\"\n    },\n    \"cities\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      }\n    }\n  }\n}","typeOptions":{"rows":10},"required":true,"displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.1}}]}}},{"displayName":"Auto-Fix Format","description":"Whether to automatically fix the output when it is not in the correct format. Will cause another LLM call.","name":"autoFix","type":"boolean","default":false},{"displayName":"Customize Retry Prompt","name":"customizeRetryPrompt","type":"boolean","displayOptions":{"show":{"autoFix":[true]}},"default":false,"description":"Whether to customize the prompt used for retrying the output parsing. If disabled, a default prompt will be used."},{"displayName":"Custom Prompt","name":"prompt","type":"string","displayOptions":{"show":{"autoFix":[true],"customizeRetryPrompt":[true]}},"default":"Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:","typeOptions":{"rows":10},"hint":"Should include \"{error}\", \"{instructions}\", and \"{completion}\" placeholders","description":"Prompt template used for fixing the output. Uses placeholders: \"{instructions}\" for parsing rules, \"{completion}\" for the failed attempt, and \"{error}\" for the validation error message."}],"hints":[{"message":"Fields that use $refs might have the wrong type, since this syntax is not currently supported","type":"warning","location":"outputPane","whenToDisplay":"afterExecution","displayCondition":"={{ $parameter[\"schemaType\"] === \"manual\" && $parameter[\"inputSchema\"]?.includes(\"$ref\") }}"}]},
{"displayName":"Reranker Cohere","name":"rerankerCohere","group":["transform"],"version":1,"description":"Use Cohere Reranker to reorder documents after retrieval from a vector store by relevance to the given query.","defaults":{"name":"Reranker Cohere"},"requestDefaults":{"ignoreHttpStatusErrors":true,"baseURL":"={{ $credentials.host }}"},"credentials":[{"name":"cohereApi","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Rerankers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.rerankercohere/"}]}},"inputs":[],"outputs":["ai_reranker"],"outputNames":["Reranker"],"properties":[{"displayName":"Model","name":"modelName","type":"options","description":"The model that should be used to rerank the documents. <a href=\"https://docs.cohere.com/docs/models\">Learn more</a>.","default":"rerank-v3.5","options":[{"name":"rerank-v3.5","value":"rerank-v3.5"},{"name":"rerank-english-v3.0","value":"rerank-english-v3.0"},{"name":"rerank-multilingual-v3.0","value":"rerank-multilingual-v3.0"}]},{"displayName":"Top N","name":"topN","type":"number","description":"The maximum number of documents to return after reranking","default":3}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/rerankers/RerankerCohere/cohere.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/rerankers/RerankerCohere/cohere.dark.svg"}},
{"displayName":"Contextual Compression Retriever","name":"retrieverContextualCompression","icon":"fa:box-open","iconColor":"black","group":["transform"],"version":1,"description":"Enhances document similarity search by contextual compression.","defaults":{"name":"Contextual Compression Retriever"},"codex":{"categories":["AI"],"subcategories":{"AI":["Retrievers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.retrievercontextualcompression/"}]}},"inputs":[{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true},{"displayName":"Retriever","maxConnections":1,"type":"ai_retriever","required":true}],"outputs":[{"displayName":"Retriever","maxConnections":1,"type":"ai_retriever"}],"properties":[]},
{"displayName":"Vector Store Retriever","name":"retrieverVectorStore","icon":"fa:box-open","iconColor":"black","group":["transform"],"version":1,"description":"Use a Vector Store as Retriever","defaults":{"name":"Vector Store Retriever"},"codex":{"categories":["AI"],"subcategories":{"AI":["Retrievers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.retrievervectorstore/"}]}},"inputs":[{"displayName":"Vector Store","maxConnections":1,"type":"ai_vectorStore","required":true}],"outputs":["ai_retriever"],"outputNames":["Retriever"],"properties":[{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"The maximum number of results to return"}]},
{"displayName":"MultiQuery Retriever","name":"retrieverMultiQuery","icon":"fa:box-open","iconColor":"black","group":["transform"],"version":1,"description":"Automates prompt tuning, generates diverse queries and expands document pool for enhanced retrieval.","defaults":{"name":"MultiQuery Retriever"},"codex":{"categories":["AI"],"subcategories":{"AI":["Retrievers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.retrievermultiquery/"}]}},"inputs":[{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true},{"displayName":"Retriever","maxConnections":1,"type":"ai_retriever","required":true}],"outputs":[{"displayName":"Retriever","maxConnections":1,"type":"ai_retriever"}],"properties":[{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Query Count","name":"queryCount","default":3,"typeOptions":{"minValue":1},"description":"Number of different versions of the given question to generate","type":"number"}]}]},
{"displayName":"Workflow Retriever","name":"retrieverWorkflow","icon":"fa:box-open","iconColor":"black","group":["transform"],"version":[1,1.1],"description":"Use an n8n Workflow as Retriever","defaults":{"name":"Workflow Retriever"},"codex":{"categories":["AI"],"subcategories":{"AI":["Retrievers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.retrieverworkflow/"}]}},"inputs":[],"outputs":[{"displayName":"Retriever","maxConnections":1,"type":"ai_retriever"}],"properties":[{"displayName":"The workflow will receive \"query\" as input and the output of the last node will be returned and converted to Documents","name":"executeNotice","type":"notice","default":""},{"displayName":"Source","name":"source","type":"options","options":[{"name":"Database","value":"database","description":"Load the workflow from the database by ID"},{"name":"Parameter","value":"parameter","description":"Load the workflow from a parameter"}],"default":"database","description":"Where to get the workflow to execute from"},{"displayName":"Workflow ID","name":"workflowId","type":"string","displayOptions":{"show":{"source":["database"],"@version":[{"_cnd":{"eq":1}}]}},"default":"","required":true,"description":"The workflow to execute"},{"displayName":"Workflow","name":"workflowId","type":"workflowSelector","displayOptions":{"show":{"source":["database"],"@version":[{"_cnd":{"gte":1.1}}]}},"default":"","required":true},{"displayName":"Workflow JSON","name":"workflowJson","type":"json","typeOptions":{"rows":10},"displayOptions":{"show":{"source":["parameter"]}},"default":"\n\n\n","required":true,"description":"The workflow JSON code to execute"},{"displayName":"Workflow Values","name":"fields","placeholder":"Add Value","type":"fixedCollection","description":"Set the values which should be made available in the workflow","typeOptions":{"multipleValues":true,"sortable":true},"default":{},"options":[{"name":"values","displayName":"Values","values":[{"displayName":"Name","name":"name","type":"string","default":"","placeholder":"e.g. fieldName","description":"Name of the field to set the value of. Supports dot-notation. Example: data.person[0].name.","requiresDataPath":"single"},{"displayName":"Type","name":"type","type":"options","description":"The field value type","options":[{"name":"String","value":"stringValue"},{"name":"Number","value":"numberValue"},{"name":"Boolean","value":"booleanValue"},{"name":"Array","value":"arrayValue"},{"name":"Object","value":"objectValue"}],"default":"stringValue"},{"displayName":"Value","name":"stringValue","type":"string","default":"","displayOptions":{"show":{"type":["stringValue"]}},"validateType":"string","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"numberValue","type":"string","default":"","displayOptions":{"show":{"type":["numberValue"]}},"validateType":"number","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"booleanValue","type":"options","default":"true","options":[{"name":"True","value":"true"},{"name":"False","value":"false"}],"displayOptions":{"show":{"type":["booleanValue"]}},"validateType":"boolean","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"arrayValue","type":"string","default":"","placeholder":"e.g. [ arrayItem1, arrayItem2, arrayItem3 ]","displayOptions":{"show":{"type":["arrayValue"]}},"validateType":"array","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"objectValue","type":"json","default":"={}","typeOptions":{"rows":2},"displayOptions":{"show":{"type":["objectValue"]}},"validateType":"object","ignoreValidationDuringExecution":true}]}]}]},
{"displayName":"Character Text Splitter","name":"textSplitterCharacterTextSplitter","icon":"fa:grip-lines-vertical","iconColor":"black","group":["transform"],"version":1,"description":"Split text into chunks by characters","defaults":{"name":"Character Text Splitter"},"codex":{"categories":["AI"],"subcategories":{"AI":["Text Splitters"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.textsplittercharactertextsplitter/"}]}},"inputs":[],"outputs":["ai_textSplitter"],"outputNames":["Text Splitter"],"properties":[{"displayName":"This node must be connected to a document loader. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_document'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Separator","name":"separator","type":"string","default":""},{"displayName":"Chunk Size","name":"chunkSize","type":"number","default":1000,"description":"Maximum number of characters per chunk"},{"displayName":"Chunk Overlap","name":"chunkOverlap","type":"number","default":0,"description":"Number of characters shared between consecutive chunks to preserve context"}]},
{"displayName":"Recursive Character Text Splitter","name":"textSplitterRecursiveCharacterTextSplitter","icon":"fa:grip-lines-vertical","iconColor":"black","group":["transform"],"version":1,"description":"Split text into chunks by characters recursively, recommended for most use cases","defaults":{"name":"Recursive Character Text Splitter"},"codex":{"categories":["AI"],"subcategories":{"AI":["Text Splitters"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.textsplitterrecursivecharactertextsplitter/"}]}},"inputs":[],"outputs":["ai_textSplitter"],"outputNames":["Text Splitter"],"properties":[{"displayName":"This node must be connected to a document loader. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_document'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Chunk Size","name":"chunkSize","type":"number","default":1000},{"displayName":"Chunk Overlap","name":"chunkOverlap","type":"number","default":0},{"displayName":"Options","name":"options","placeholder":"Add Option","description":"Additional options to add","type":"collection","default":{},"options":[{"displayName":"Split Code","name":"splitCode","default":"markdown","type":"options","options":[{"name":"cpp","value":"cpp"},{"name":"go","value":"go"},{"name":"java","value":"java"},{"name":"js","value":"js"},{"name":"php","value":"php"},{"name":"proto","value":"proto"},{"name":"python","value":"python"},{"name":"rst","value":"rst"},{"name":"ruby","value":"ruby"},{"name":"rust","value":"rust"},{"name":"scala","value":"scala"},{"name":"swift","value":"swift"},{"name":"markdown","value":"markdown"},{"name":"latex","value":"latex"},{"name":"html","value":"html"}]}]}]},
{"displayName":"Token Splitter","name":"textSplitterTokenSplitter","icon":"fa:grip-lines-vertical","iconColor":"black","group":["transform"],"version":1,"description":"Split text into chunks by tokens","defaults":{"name":"Token Splitter"},"codex":{"categories":["AI"],"subcategories":{"AI":["Text Splitters"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.textsplittertokensplitter/"}]}},"inputs":[],"outputs":["ai_textSplitter"],"outputNames":["Text Splitter"],"properties":[{"displayName":"This node must be connected to a document loader. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_document'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Chunk Size","name":"chunkSize","type":"number","default":1000,"description":"Maximum number of tokens per chunk"},{"displayName":"Chunk Overlap","name":"chunkOverlap","type":"number","default":0,"description":"Number of tokens shared between consecutive chunks to preserve context"}]},
{"displayName":"Calculator","name":"toolCalculator","icon":"fa:calculator","iconColor":"black","group":["transform"],"version":1,"description":"Make it easier for AI agents to perform arithmetic","defaults":{"name":"Calculator"},"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolcalculator/"}]}},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}}]},
{"displayName":"Code Tool","name":"toolCode","icon":"fa:code","iconColor":"black","group":["transform"],"version":[1,1.1,1.2,1.3],"description":"Write a tool in JS or Python","defaults":{"name":"Code Tool"},"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Recommended Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolcode/"}]}},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"See an example of a conversational agent with custom tool written in JavaScript <a href=\"/templates/1963\" target=\"_blank\">here</a>.","name":"noticeTemplateExample","type":"notice","default":""},{"displayName":"Name","name":"name","type":"string","default":"","placeholder":"My_Tool","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Name","name":"name","type":"string","default":"","placeholder":"e.g. My_Tool","validateType":"string-alphanumeric","description":"The name of the function to be called, could contain letters, numbers, and underscores only","displayOptions":{"show":{"@version":[1.1]}}},{"displayName":"Description","name":"description","type":"string","default":"","placeholder":"Call this tool to get a random color. The input should be a string with comma separted names of colors to exclude.","typeOptions":{"rows":3}},{"displayName":"Language","name":"language","type":"options","noDataExpression":true,"options":[{"name":"JavaScript","value":"javaScript"},{"name":"Python (Beta)","value":"python"}],"default":"javaScript"},{"displayName":"JavaScript","name":"jsCode","type":"string","displayOptions":{"show":{"language":["javaScript"]}},"typeOptions":{"editor":"jsEditor"},"default":"// Example: convert the incoming query to uppercase and return it\nreturn query.toUpperCase()","hint":"You can access the input the tool receives via the input property \"query\". The returned value should be a single string.","description":"E.g. Converts any text to uppercase","noDataExpression":true},{"displayName":"Python","name":"pythonCode","type":"string","displayOptions":{"show":{"language":["python"]}},"typeOptions":{"editor":"codeNodeEditor","editorLanguage":"python"},"default":"# Example: convert the incoming query to uppercase and return it\nreturn query.upper()","hint":"You can access the input the tool receives via the input property \"query\". The returned value should be a single string.","description":"E.g. Converts any text to uppercase","noDataExpression":true},{"displayName":"Specify Input Schema","name":"specifyInputSchema","type":"boolean","description":"Whether to specify the schema for the function. This would require the LLM to provide the input in the correct format and would validate it against the schema.","noDataExpression":true,"default":false},{"displayName":"Schema Type","name":"schemaType","type":"options","noDataExpression":true,"options":[{"name":"Generate From JSON Example","value":"fromJson","description":"Generate a schema from an example JSON object"},{"name":"Define using JSON Schema","value":"manual","description":"Define the JSON schema manually"}],"default":"fromJson","description":"How to specify the schema for the function","displayOptions":{"show":{"specifyInputSchema":[true]}}},{"displayName":"JSON Example","name":"jsonSchemaExample","type":"json","default":"{\n\t\"some_input\": \"some_value\"\n}","noDataExpression":true,"typeOptions":{"rows":10},"displayOptions":{"show":{"specifyInputSchema":[true],"schemaType":["fromJson"]}},"description":"Example JSON object to use to generate the schema"},{"displayName":"All properties will be required. To make them optional, use the 'JSON Schema' schema type instead","name":"notice","type":"notice","default":"","displayOptions":{"show":{"specifyInputSchema":[true],"@version":[{"_cnd":{"gte":1.3}}],"schemaType":["fromJson"]}}},{"displayName":"Input Schema","name":"inputSchema","type":"json","default":"{\n\"type\": \"object\",\n\"properties\": {\n\t\"some_input\": {\n\t\t\"type\": \"string\",\n\t\t\"description\": \"Some input to the function\"\n\t\t}\n\t}\n}","noDataExpression":false,"typeOptions":{"rows":10},"displayOptions":{"show":{"specifyInputSchema":[true],"schemaType":["manual"]}},"description":"Schema to use for the function","hint":"Use <a target=\"_blank\" href=\"https://json-schema.org/\">JSON Schema</a> format (<a target=\"_blank\" href=\"https://json-schema.org/learn/miscellaneous-examples.html\">examples</a>). $refs syntax is currently not supported."}]},
{"displayName":"HTTP Request Tool","name":"toolHttpRequest","group":["output"],"version":[1,1.1],"description":"Makes an HTTP request and returns the response data","subtitle":"={{ $parameter.toolDescription }}","defaults":{"name":"HTTP Request"},"credentials":[],"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Recommended Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolhttprequest/"}]}},"hidden":true,"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Description","name":"toolDescription","type":"string","description":"Explain to LLM what this tool does, better description would allow LLM to produce expected result","placeholder":"e.g. Get the current weather in the requested city","default":"","typeOptions":{"rows":3}},{"displayName":"Method","name":"method","type":"options","options":[{"name":"DELETE","value":"DELETE"},{"name":"GET","value":"GET"},{"name":"PATCH","value":"PATCH"},{"name":"POST","value":"POST"},{"name":"PUT","value":"PUT"}],"default":"GET"},{"displayName":"Tip: You can use a {placeholder} for any part of the request to be filled by the model. Provide more context about them in the placeholders section","name":"placeholderNotice","type":"notice","default":""},{"displayName":"URL","name":"url","type":"string","default":"","required":true,"placeholder":"e.g. http://www.example.com/{path}"},{"displayName":"Authentication","name":"authentication","description":"Select the type of authentication to use if needed, authentication would be done by n8n and your credentials will not be shared with the LLM","noDataExpression":true,"type":"options","options":[{"name":"None","value":"none"},{"name":"Predefined Credential Type","value":"predefinedCredentialType","description":"We've already implemented auth for many services so that you don't have to set it up manually"},{"name":"Generic Credential Type","value":"genericCredentialType","description":"Fully customizable. Choose between basic, header, OAuth2, etc."}],"default":"none"},{"displayName":"Credential Type","name":"nodeCredentialType","type":"credentialsSelect","noDataExpression":true,"required":true,"default":"","credentialTypes":["extends:oAuth2Api","extends:oAuth1Api","has:authenticate"],"displayOptions":{"show":{"authentication":["predefinedCredentialType"]}}},{"displayName":"Make sure you have specified the scope(s) for the Service Account in the credential","name":"googleApiWarning","type":"notice","default":"","displayOptions":{"show":{"nodeCredentialType":["googleApi"]}}},{"displayName":"Generic Auth Type","name":"genericAuthType","type":"credentialsSelect","required":true,"default":"","credentialTypes":["has:genericAuth"],"displayOptions":{"show":{"authentication":["genericCredentialType"]}}},{"displayName":"Send Query Parameters","name":"sendQuery","type":"boolean","default":false,"noDataExpression":true,"description":"Whether the request has query params or not"},{"displayName":"Specify Query Parameters","name":"specifyQuery","type":"options","options":[{"name":"Using Fields Below","value":"keypair"},{"name":"Using JSON Below","value":"json"},{"name":"Let Model Specify Entire Body","value":"model"}],"default":"keypair","displayOptions":{"show":{"sendQuery":[true]}}},{"displayName":"Query Parameters","name":"parametersQuery","type":"fixedCollection","typeOptions":{"multipleValues":true},"placeholder":"Add Parameter","default":{"values":[{"name":""}]},"options":[{"name":"values","displayName":"Values","values":[{"displayName":"Name","name":"name","type":"string","default":""},{"displayName":"Value Provided","name":"valueProvider","type":"options","options":[{"name":"By Model (and is required)","value":"modelRequired"},{"name":"By Model (but is optional)","value":"modelOptional"},{"name":"Using Field Below","value":"fieldValue"}],"default":"modelRequired"},{"displayName":"Value","name":"value","type":"string","default":"","hint":"Use a {placeholder} for any data to be filled in by the model","displayOptions":{"show":{"valueProvider":["fieldValue"]}}}]}],"displayOptions":{"show":{"sendQuery":[true],"specifyQuery":["keypair"]}}},{"displayName":"JSON","name":"jsonQuery","type":"string","typeOptions":{"rows":5},"hint":"Use a {placeholder} for any data to be filled in by the model","default":"","displayOptions":{"show":{"sendQuery":[true],"specifyQuery":["json"]}}},{"displayName":"Send Headers","name":"sendHeaders","type":"boolean","default":false,"noDataExpression":true,"description":"Whether the request has headers or not"},{"displayName":"Specify Headers","name":"specifyHeaders","type":"options","options":[{"name":"Using Fields Below","value":"keypair"},{"name":"Using JSON Below","value":"json"},{"name":"Let Model Specify Entire Body","value":"model"}],"default":"keypair","displayOptions":{"show":{"sendHeaders":[true]}}},{"displayName":"Header Parameters","name":"parametersHeaders","type":"fixedCollection","typeOptions":{"multipleValues":true},"placeholder":"Add Parameter","default":{"values":[{"name":""}]},"options":[{"name":"values","displayName":"Values","values":[{"displayName":"Name","name":"name","type":"string","default":""},{"displayName":"Value Provided","name":"valueProvider","type":"options","options":[{"name":"By Model (and is required)","value":"modelRequired"},{"name":"By Model (but is optional)","value":"modelOptional"},{"name":"Using Field Below","value":"fieldValue"}],"default":"modelRequired"},{"displayName":"Value","name":"value","type":"string","default":"","hint":"Use a {placeholder} for any data to be filled in by the model","displayOptions":{"show":{"valueProvider":["fieldValue"]}}}]}],"displayOptions":{"show":{"sendHeaders":[true],"specifyHeaders":["keypair"]}}},{"displayName":"JSON","name":"jsonHeaders","type":"string","typeOptions":{"rows":5},"hint":"Use a {placeholder} for any data to be filled in by the model","default":"","displayOptions":{"show":{"sendHeaders":[true],"specifyHeaders":["json"]}}},{"displayName":"Send Body","name":"sendBody","type":"boolean","default":false,"noDataExpression":true,"description":"Whether the request has body or not"},{"displayName":"Specify Body","name":"specifyBody","type":"options","options":[{"name":"Using Fields Below","value":"keypair"},{"name":"Using JSON Below","value":"json"},{"name":"Let Model Specify Entire Body","value":"model"}],"default":"keypair","displayOptions":{"show":{"sendBody":[true]}}},{"displayName":"Body Parameters","name":"parametersBody","type":"fixedCollection","typeOptions":{"multipleValues":true},"placeholder":"Add Parameter","default":{"values":[{"name":""}]},"options":[{"name":"values","displayName":"Values","values":[{"displayName":"Name","name":"name","type":"string","default":""},{"displayName":"Value Provided","name":"valueProvider","type":"options","options":[{"name":"By Model (and is required)","value":"modelRequired"},{"name":"By Model (but is optional)","value":"modelOptional"},{"name":"Using Field Below","value":"fieldValue"}],"default":"modelRequired"},{"displayName":"Value","name":"value","type":"string","default":"","hint":"Use a {placeholder} for any data to be filled in by the model","displayOptions":{"show":{"valueProvider":["fieldValue"]}}}]}],"displayOptions":{"show":{"sendBody":[true],"specifyBody":["keypair"]}}},{"displayName":"JSON","name":"jsonBody","type":"string","typeOptions":{"rows":5},"hint":"Use a {placeholder} for any data to be filled in by the model","default":"","displayOptions":{"show":{"sendBody":[true],"specifyBody":["json"]}}},{"displayName":"Placeholder Definitions","name":"placeholderDefinitions","type":"fixedCollection","typeOptions":{"multipleValues":true},"placeholder":"Add Definition","default":[],"options":[{"name":"values","displayName":"Values","values":[{"displayName":"Placeholder Name","name":"name","type":"string","default":""},{"displayName":"Description","name":"description","type":"string","default":""},{"displayName":"Type","name":"type","type":"options","options":[{"name":"Not Specified (Default)","value":"not specified"},{"name":"String","value":"string"},{"name":"Number","value":"number"},{"name":"Boolean","value":"boolean"},{"name":"JSON","value":"json"}],"default":"not specified"}]}]},{"displayName":"Optimize Response","name":"optimizeResponse","type":"boolean","default":false,"noDataExpression":true,"description":"Whether the optimize the tool response to reduce amount of data passed to the LLM that could lead to better result and reduce cost"},{"displayName":"Expected Response Type","name":"responseType","type":"options","displayOptions":{"show":{"optimizeResponse":[true]}},"options":[{"name":"JSON","value":"json"},{"name":"HTML","value":"html"},{"name":"Text","value":"text"}],"default":"json"},{"displayName":"Field Containing Data","name":"dataField","type":"string","default":"","placeholder":"e.g. records","description":"Specify the name of the field in the response containing the data","hint":"leave blank to use whole response","requiresDataPath":"single","displayOptions":{"show":{"optimizeResponse":[true],"responseType":["json"]}}},{"displayName":"Include Fields","name":"fieldsToInclude","type":"options","description":"What fields response object should include","default":"all","displayOptions":{"show":{"optimizeResponse":[true],"responseType":["json"]}},"options":[{"name":"All","value":"all","description":"Include all fields"},{"name":"Selected","value":"selected","description":"Include only fields specified below"},{"name":"Except","value":"except","description":"Exclude fields specified below"}]},{"displayName":"Fields","name":"fields","type":"string","default":"","placeholder":"e.g. field1,field2","description":"Comma-separated list of the field names. Supports dot notation. You can drag the selected fields from the input panel.","requiresDataPath":"multiple","displayOptions":{"show":{"optimizeResponse":[true],"responseType":["json"]},"hide":{"fieldsToInclude":["all"]}}},{"displayName":"Selector (CSS)","name":"cssSelector","type":"string","description":"Select specific element(e.g. body) or multiple elements(e.g. div) of chosen type in the response HTML.","placeholder":"e.g. body","default":"body","displayOptions":{"show":{"optimizeResponse":[true],"responseType":["html"]}}},{"displayName":"Return Only Content","name":"onlyContent","type":"boolean","default":false,"description":"Whether to return only content of html elements, stripping html tags and attributes","hint":"Uses less tokens and may be easier for model to understand","displayOptions":{"show":{"optimizeResponse":[true],"responseType":["html"]}}},{"displayName":"Elements To Omit","name":"elementsToOmit","type":"string","displayOptions":{"show":{"optimizeResponse":[true],"responseType":["html"],"onlyContent":[true]}},"default":"","placeholder":"e.g. img, .className, #ItemId","description":"Comma-separated list of selectors that would be excluded when extracting content"},{"displayName":"Truncate Response","name":"truncateResponse","type":"boolean","default":false,"hint":"Helps save tokens","displayOptions":{"show":{"optimizeResponse":[true],"responseType":["text","html"]}}},{"displayName":"Max Response Characters","name":"maxLength","type":"number","default":1000,"typeOptions":{"minValue":1},"displayOptions":{"show":{"optimizeResponse":[true],"responseType":["text","html"],"truncateResponse":[true]}}}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/tools/ToolHttpRequest/httprequest.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/tools/ToolHttpRequest/httprequest.dark.svg"}},
{"displayName":"SearXNG","name":"toolSearXng","group":["transform"],"version":1,"description":"Search in SearXNG","defaults":{"name":"SearXNG"},"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolsearxng"}]}},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"credentials":[{"name":"searXngApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Number of Results","name":"numResults","type":"number","default":10},{"displayName":"Search Page Number","name":"pageNumber","type":"number","default":1},{"displayName":"Language","name":"language","type":"string","default":"en","description":"Defines the language to use. It's a two-letter language code. (e.g., `en` for English, `es` for Spanish, or `fr` for French). Head to <a href=\"https://docs.searxng.org/user/search-syntax.html#select-language\">SearXNG search syntax page</a> for more info."},{"displayName":"Safe Search","name":"safesearch","type":"options","options":[{"name":"None","value":0},{"name":"Moderate","value":1},{"name":"Strict","value":2}],"default":0,"description":"Filter search results of engines which support safe search"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/tools/ToolSearXng/searXng.svg"},
{"displayName":"SerpApi (Google Search)","name":"toolSerpApi","group":["transform"],"version":1,"description":"Search in Google using SerpAPI","defaults":{"name":"SerpAPI"},"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolserpapi/"}]}},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"credentials":[{"name":"serpApi","required":true}],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Country","name":"gl","type":"string","default":"us","description":"Defines the country to use for search. Head to <a href=\"https://serpapi.com/google-countries\">Google countries page</a> for a full list of supported countries."},{"displayName":"Device","name":"device","type":"options","options":[{"name":"Desktop","value":"desktop"},{"name":"Mobile","value":"mobile"},{"name":"Tablet","value":"tablet"}],"default":"desktop","description":"Device to use to get the results"},{"displayName":"Explicit Array","name":"no_cache","type":"boolean","default":false,"description":"Whether to force SerpApi to fetch the Google results even if a cached version is already present. Cache expires after 1h. Cached searches are free, and are not counted towards your searches per month."},{"displayName":"Google Domain","name":"google_domain","type":"string","default":"google.com","description":"Defines the domain to use for search. Head to <a href=\"https://serpapi.com/google-domains\">Google domains page</a> for a full list of supported domains."},{"displayName":"Language","name":"hl","type":"string","default":"en","description":"Defines the language to use. It's a two-letter language code. (e.g., `en` for English, `es` for Spanish, or `fr` for French). Head to <a href=\"https://serpapi.com/google-languages\">Google languages page</a> for a full list of supported languages."}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/tools/ToolSerpApi/serpApi.svg"},
{"displayName":"Think Tool","name":"toolThink","icon":"fa:brain","iconColor":"black","group":["transform"],"version":[1,1.1],"description":"Invite the AI agent to do some thinking","defaults":{"name":"Think"},"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolthink/"}]}},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Think Tool Description","name":"description","type":"string","default":"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.","placeholder":"[Describe your thinking tool here, explaining how it will help the AI think]","description":"The thinking tool's description","typeOptions":{"rows":3},"required":true}]},
{"displayName":"Vector Store Question Answer Tool","name":"toolVectorStore","icon":"fa:database","iconColor":"black","group":["transform"],"version":[1,1.1],"description":"Answer questions with a vector store","defaults":{"name":"Answer questions with a vector store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolvectorstore/"}]}},"inputs":[{"displayName":"Vector Store","maxConnections":1,"type":"ai_vectorStore","required":true},{"displayName":"Model","maxConnections":1,"type":"ai_languageModel","required":true}],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"Data Name","name":"name","type":"string","default":"","placeholder":"e.g. users_info","validateType":"string-alphanumeric","description":"Name of the data in vector store. This will be used to fill this tool description: Useful for when you need to answer questions about [name]. Whenever you need information about [data description], you should ALWAYS use this. Input should be a fully formed question.","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Description of Data","name":"description","type":"string","default":"","placeholder":"[Describe your data here, e.g. a user's name, email, etc.]","description":"Describe the data in vector store. This will be used to fill this tool description: Useful for when you need to answer questions about [name]. Whenever you need information about [data description], you should ALWAYS use this. Input should be a fully formed question.","typeOptions":{"rows":3}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"The maximum number of results to return"}]},
{"displayName":"Wikipedia","name":"toolWikipedia","group":["transform"],"version":1,"description":"Search in Wikipedia","defaults":{"name":"Wikipedia"},"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolwikipedia/"}]}},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/tools/ToolWikipedia/wikipedia.svg"},
{"displayName":"Wolfram|Alpha","name":"toolWolframAlpha","group":["transform"],"version":1,"description":"Connects to WolframAlpha's computational intelligence engine.","defaults":{"name":"Wolfram Alpha"},"credentials":[{"name":"wolframAlphaApi","required":true}],"codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolwolframalpha/"}]}},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/tools/ToolWolframAlpha/wolfram-alpha.svg"},
{"displayName":"Call n8n Workflow Tool","name":"toolWorkflow","icon":"fa:network-wired","iconColor":"black","group":["transform"],"description":"Uses another n8n workflow as a tool. Allows packaging any n8n node(s) as a tool.","codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Recommended Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolworkflow/"}]}},"defaultVersion":2.2,"defaults":{"name":"Call n8n Workflow Tool"},"version":[2,2.1,2.2],"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"See an example of a workflow to suggest meeting slots using AI <a href=\"/templates/1953\" target=\"_blank\">here</a>.","name":"noticeTemplateExample","type":"notice","default":""},{"displayName":"Name","name":"name","type":"string","default":"","placeholder":"e.g. My_Color_Tool","validateType":"string-alphanumeric","description":"The name of the function to be called, could contain letters, numbers, and underscores only","displayOptions":{"show":{"@version":[{"_cnd":{"lte":2.1}}]}}},{"displayName":"Description","name":"description","type":"string","default":"","placeholder":"Call this tool to get a random color. The input should be a string with comma separated names of colors to exclude.","typeOptions":{"rows":3}},{"displayName":"This tool will call the workflow you define below, and look in the last node for the response. The workflow needs to start with an Execute Workflow trigger","name":"executeNotice","type":"notice","default":""},{"displayName":"Source","name":"source","type":"options","options":[{"name":"Database","value":"database","description":"Load the workflow from the database by ID"},{"name":"Define Below","value":"parameter","description":"Pass the JSON code of a workflow"}],"default":"database","description":"Where to get the workflow to execute from"},{"displayName":"Workflow","name":"workflowId","type":"workflowSelector","displayOptions":{"show":{"source":["database"]}},"default":"","required":true},{"displayName":"Workflow Inputs","name":"workflowInputs","type":"resourceMapper","noDataExpression":true,"default":{"mappingMode":"defineBelow","value":null},"required":true,"typeOptions":{"loadOptionsDependsOn":["workflowId.value"],"resourceMapper":{"localResourceMapperMethod":"loadSubWorkflowInputs","valuesLabel":"Workflow Inputs","mode":"map","fieldWords":{"singular":"workflow input","plural":"workflow inputs"},"addAllFields":true,"multiKeyMatch":false,"supportAutoMap":false}},"displayOptions":{"show":{"source":["database"]},"hide":{"workflowId":[""]}}},{"displayName":"Workflow JSON","name":"workflowJson","type":"json","typeOptions":{"rows":10},"displayOptions":{"show":{"source":["parameter"]}},"default":"\n\n\n\n\n\n\n\n\n","required":true,"description":"The workflow JSON code to execute"}]},
{"displayName":"Call n8n Workflow Tool","name":"toolWorkflow","icon":"fa:network-wired","iconColor":"black","group":["transform"],"description":"Uses another n8n workflow as a tool. Allows packaging any n8n node(s) as a tool.","codex":{"categories":["AI"],"subcategories":{"AI":["Tools"],"Tools":["Recommended Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolworkflow/"}]}},"defaultVersion":2.2,"version":[1,1.1,1.2,1.3],"defaults":{"name":"Call n8n Workflow Tool"},"inputs":[],"outputs":["ai_tool"],"outputNames":["Tool"],"properties":[{"displayName":"This node must be connected to an AI agent. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"}},{"displayName":"See an example of a workflow to suggest meeting slots using AI <a href=\"/templates/1953\" target=\"_blank\">here</a>.","name":"noticeTemplateExample","type":"notice","default":""},{"displayName":"Name","name":"name","type":"string","default":"","placeholder":"My_Color_Tool","displayOptions":{"show":{"@version":[1]}}},{"displayName":"Name","name":"name","type":"string","default":"","placeholder":"e.g. My_Color_Tool","validateType":"string-alphanumeric","description":"The name of the function to be called, could contain letters, numbers, and underscores only","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Description","name":"description","type":"string","default":"","placeholder":"Call this tool to get a random color. The input should be a string with comma separted names of colors to exclude.","typeOptions":{"rows":3}},{"displayName":"This tool will call the workflow you define below, and look in the last node for the response. The workflow needs to start with an Execute Workflow trigger","name":"executeNotice","type":"notice","default":""},{"displayName":"Source","name":"source","type":"options","options":[{"name":"Database","value":"database","description":"Load the workflow from the database by ID"},{"name":"Define Below","value":"parameter","description":"Pass the JSON code of a workflow"}],"default":"database","description":"Where to get the workflow to execute from"},{"displayName":"Workflow ID","name":"workflowId","type":"string","displayOptions":{"show":{"source":["database"],"@version":[{"_cnd":{"lte":1.1}}]}},"default":"","required":true,"description":"The workflow to execute","hint":"Can be found in the URL of the workflow"},{"displayName":"Workflow","name":"workflowId","type":"workflowSelector","displayOptions":{"show":{"source":["database"],"@version":[{"_cnd":{"gte":1.2}}]}},"default":"","required":true},{"displayName":"Workflow JSON","name":"workflowJson","type":"json","typeOptions":{"rows":10},"displayOptions":{"show":{"source":["parameter"]}},"default":"\n\n\n\n\n\n\n\n\n","required":true,"description":"The workflow JSON code to execute"},{"displayName":"Field to Return","name":"responsePropertyName","type":"string","default":"response","required":true,"hint":"The field in the last-executed node of the workflow that contains the response","description":"Where to find the data that this tool should return. n8n will look in the output of the last-executed node of the workflow for a field with this name, and return its value.","displayOptions":{"show":{"@version":[{"_cnd":{"lt":1.3}}]}}},{"displayName":"Extra Workflow Inputs","name":"fields","placeholder":"Add Value","type":"fixedCollection","description":"These will be output by the 'execute workflow' trigger of the workflow being called","typeOptions":{"multipleValues":true,"sortable":true},"default":{},"options":[{"name":"values","displayName":"Values","values":[{"displayName":"Name","name":"name","type":"string","default":"","placeholder":"e.g. fieldName","description":"Name of the field to set the value of. Supports dot-notation. Example: data.person[0].name.","requiresDataPath":"single"},{"displayName":"Type","name":"type","type":"options","description":"The field value type","options":[{"name":"String","value":"stringValue"},{"name":"Number","value":"numberValue"},{"name":"Boolean","value":"booleanValue"},{"name":"Array","value":"arrayValue"},{"name":"Object","value":"objectValue"}],"default":"stringValue"},{"displayName":"Value","name":"stringValue","type":"string","default":"","displayOptions":{"show":{"type":["stringValue"]}},"validateType":"string","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"numberValue","type":"string","default":"","displayOptions":{"show":{"type":["numberValue"]}},"validateType":"number","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"booleanValue","type":"options","default":"true","options":[{"name":"True","value":"true"},{"name":"False","value":"false"}],"displayOptions":{"show":{"type":["booleanValue"]}},"validateType":"boolean","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"arrayValue","type":"string","default":"","placeholder":"e.g. [ arrayItem1, arrayItem2, arrayItem3 ]","displayOptions":{"show":{"type":["arrayValue"]}},"validateType":"array","ignoreValidationDuringExecution":true},{"displayName":"Value","name":"objectValue","type":"json","default":"={}","typeOptions":{"rows":2},"displayOptions":{"show":{"type":["objectValue"]}},"validateType":"object","ignoreValidationDuringExecution":true}]}]},{"displayName":"Specify Input Schema","name":"specifyInputSchema","type":"boolean","description":"Whether to specify the schema for the function. This would require the LLM to provide the input in the correct format and would validate it against the schema.","noDataExpression":true,"default":false},{"displayName":"Schema Type","name":"schemaType","type":"options","noDataExpression":true,"options":[{"name":"Generate From JSON Example","value":"fromJson","description":"Generate a schema from an example JSON object"},{"name":"Define using JSON Schema","value":"manual","description":"Define the JSON schema manually"}],"default":"fromJson","description":"How to specify the schema for the function","displayOptions":{"show":{"specifyInputSchema":[true]}}},{"displayName":"JSON Example","name":"jsonSchemaExample","type":"json","default":"{\n\t\"some_input\": \"some_value\"\n}","noDataExpression":true,"typeOptions":{"rows":10},"displayOptions":{"show":{"schemaType":["fromJson"]}},"description":"Example JSON object to use to generate the schema"},{"displayName":"Input Schema","name":"inputSchema","type":"json","default":"{\n\"type\": \"object\",\n\"properties\": {\n\t\"some_input\": {\n\t\t\"type\": \"string\",\n\t\t\"description\": \"Some input to the function\"\n\t\t}\n\t}\n}","noDataExpression":false,"typeOptions":{"rows":10},"displayOptions":{"show":{"schemaType":["manual"]}},"description":"Schema to use for the function","hint":"Use <a target=\"_blank\" href=\"https://json-schema.org/\">JSON Schema</a> format (<a target=\"_blank\" href=\"https://json-schema.org/learn/miscellaneous-examples.html\">examples</a>). $refs syntax is currently not supported."}]},
{"displayName":"Manual Chat Trigger","name":"manualChatTrigger","icon":"fa:comments","group":["trigger"],"version":[1,1.1],"description":"Runs the flow on new manual chat message","eventTriggerDescription":"","maxNodes":1,"hidden":true,"defaults":{"name":"When chat message received","color":"#909298"},"codex":{"categories":["Core Nodes"],"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"}]},"subcategories":{"Core Nodes":["Other Trigger Nodes"]}},"inputs":[],"outputs":["main"],"properties":[{"displayName":"This node is where a manual chat workflow execution starts. To make one, go back to the canvas and click Chat","name":"notice","type":"notice","default":""},{"displayName":"Chat and execute workflow","name":"openChat","type":"button","typeOptions":{"buttonConfig":{"action":"openChat"}},"default":""}]},
{"displayName":"Chat Trigger","name":"chatTrigger","icon":"fa:comments","iconColor":"black","group":["trigger"],"version":[1,1.1,1.2,1.3],"defaultVersion":1.3,"description":"Runs the workflow when an n8n generated webchat is submitted","defaults":{"name":"When chat message received"},"codex":{"categories":["Core Nodes"],"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"}]}},"maxNodes":1,"inputs":"={{ (() => {\n\t\t\tif (!['hostedChat', 'webhook'].includes($parameter.mode)) {\n\t\t\t\treturn [];\n\t\t\t}\n\t\t\tif ($parameter.options?.loadPreviousSession !== 'memory') {\n\t\t\t\treturn [];\n\t\t\t}\n\n\t\t\treturn [\n\t\t\t\t{\n\t\t\t\t\tdisplayName: 'Memory',\n\t\t\t\t\tmaxConnections: 1,\n\t\t\t\t\ttype: 'ai_memory',\n\t\t\t\t\trequired: true,\n\t\t\t\t}\n\t\t\t];\n\t\t })() }}","outputs":["main"],"credentials":[{"name":"httpBasicAuth","required":true,"displayOptions":{"show":{"authentication":["basicAuth"]}}}],"webhooks":[{"name":"setup","httpMethod":"GET","responseMode":"onReceived","path":"chat","ndvHideUrl":true},{"name":"default","httpMethod":"POST","responseMode":"={{$parameter.options?.[\"responseMode\"] || \"lastNode\" }}","path":"chat","ndvHideMethod":true,"ndvHideUrl":"={{ !$parameter.public }}"}],"eventTriggerDescription":"Waiting for you to submit the chat","activationMessage":"You can now make calls to your production chat URL.","triggerPanel":false,"properties":[{"displayName":"Make Chat Publicly Available","name":"public","type":"boolean","default":false,"description":"Whether the chat should be publicly available or only accessible through the manual chat interface"},{"displayName":"Mode","name":"mode","type":"options","options":[{"name":"Hosted Chat","value":"hostedChat","description":"Chat on a page served by n8n"},{"name":"Embedded Chat","value":"webhook","description":"Chat through a widget embedded in another page, or by calling a webhook"}],"default":"hostedChat","displayOptions":{"show":{"public":[true]}}},{"displayName":"Chat will be live at the URL above once you activate this workflow. Live executions will show up in the executions tab","name":"hostedChatNotice","type":"notice","displayOptions":{"show":{"mode":["hostedChat"],"public":[true]}},"default":""},{"displayName":"Follow the instructions <a href=\"https://www.npmjs.com/package/@n8n/chat\" target=\"_blank\">here</a> to embed chat in a webpage (or just call the webhook URL at the top of this section). Chat will be live once you activate this workflow","name":"embeddedChatNotice","type":"notice","displayOptions":{"show":{"mode":["webhook"],"public":[true]}},"default":""},{"displayName":"Authentication","name":"authentication","type":"options","displayOptions":{"show":{"public":[true]}},"options":[{"name":"Basic Auth","value":"basicAuth","description":"Simple username and password (the same one for all users)"},{"name":"n8n User Auth","value":"n8nUserAuth","description":"Require user to be logged in with their n8n account"},{"name":"None","value":"none"}],"default":"none","description":"The way to authenticate"},{"displayName":"Initial Message(s)","name":"initialMessages","type":"string","displayOptions":{"show":{"mode":["hostedChat"],"public":[true]}},"typeOptions":{"rows":3},"default":"Hi there! \nMy name is Nathan. How can I assist you today?","description":"Default messages shown at the start of the chat, one per line"},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"public":[false],"@version":[1,1.1]}},"placeholder":"Add Field","default":{},"options":[{"displayName":"Allow File Uploads","name":"allowFileUploads","type":"boolean","default":false,"description":"Whether to allow file uploads in the chat"},{"displayName":"Allowed File Mime Types","name":"allowedFilesMimeTypes","type":"string","default":"*","placeholder":"e.g. image/*, text/*, application/pdf","description":"Allowed file types for upload. Comma-separated list of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types\" target=\"_blank\">MIME types</a>."}]},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"mode":["hostedChat","webhook"],"public":[true],"@version":[1,1.1]}},"placeholder":"Add Field","default":{},"options":[{"displayName":"Allowed Origins (CORS)","name":"allowedOrigins","type":"string","default":"*","description":"Comma-separated list of URLs allowed for cross-origin non-preflight requests. Use * (default) to allow all origins.","displayOptions":{"show":{"/mode":["hostedChat","webhook"]}}},{"displayName":"Allow File Uploads","name":"allowFileUploads","type":"boolean","default":false,"description":"Whether to allow file uploads in the chat","displayOptions":{"show":{"/mode":["hostedChat"]}}},{"displayName":"Allowed File Mime Types","name":"allowedFilesMimeTypes","type":"string","default":"*","placeholder":"e.g. image/*, text/*, application/pdf","description":"Allowed file types for upload. Comma-separated list of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types\" target=\"_blank\">MIME types</a>.","displayOptions":{"show":{"/mode":["hostedChat"]}}},{"displayName":"Input Placeholder","name":"inputPlaceholder","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Type your question..","placeholder":"e.g. Type your message here","description":"Shown as placeholder text in the chat input field"},{"displayName":"Load Previous Session","name":"loadPreviousSession","type":"options","options":[{"name":"Off","value":"notSupported","description":"Loading messages of previous session is turned off"},{"name":"From Memory","value":"memory","description":"Load session messages from memory"},{"name":"Manually","value":"manually","description":"Manually return messages of session"}],"default":"notSupported","description":"If loading messages of a previous session should be enabled"},{"displayName":"Require Button Click to Start Chat","name":"showWelcomeScreen","type":"boolean","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":false,"description":"Whether to show the welcome screen at the start of the chat"},{"displayName":"Start Conversation Button Text","name":"getStarted","type":"string","displayOptions":{"show":{"showWelcomeScreen":[true],"/mode":["hostedChat"]}},"default":"New Conversation","placeholder":"e.g. New Conversation","description":"Shown as part of the welcome screen, in the middle of the chat window"},{"displayName":"Subtitle","name":"subtitle","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Start a chat. We're here to help you 24/7.","placeholder":"e.g. We're here for you","description":"Shown at the top of the chat, under the title"},{"displayName":"Title","name":"title","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Hi there! ","placeholder":"e.g. Welcome","description":"Shown at the top of the chat"},{"displayName":"Custom Chat Styling","name":"customCss","type":"string","typeOptions":{"rows":10,"editor":"cssEditor"},"displayOptions":{"show":{"/mode":["hostedChat"]}},"default":":root {\n  /* Colors */\n  --chat--color-primary: #e74266;\n  --chat--color-primary-shade-50: #db4061;\n  --chat--color-primary-shade-100: #cf3c5c;\n  --chat--color-secondary: #20b69e;\n  --chat--color-secondary-shade-50: #1ca08a;\n  --chat--color-white: #ffffff;\n  --chat--color-light: #f2f4f8;\n  --chat--color-light-shade-50: #e6e9f1;\n  --chat--color-light-shade-100: #c2c5cc;\n  --chat--color-medium: #d2d4d9;\n  --chat--color-dark: #101330;\n  --chat--color-disabled: #d2d4d9;\n  --chat--color-typing: #404040;\n\n  /* Base Layout */\n  --chat--spacing: 1rem;\n  --chat--border-radius: 0.25rem;\n  --chat--transition-duration: 0.15s;\n  --chat--font-family: (\n    -apple-system,\n    BlinkMacSystemFont,\n    'Segoe UI',\n    Roboto,\n    Oxygen-Sans,\n    Ubuntu,\n    Cantarell,\n    'Helvetica Neue',\n    sans-serif\n  );\n\n  /* Window Dimensions */\n  --chat--window--width: 400px;\n  --chat--window--height: 600px;\n  --chat--window--bottom: var(--chat--spacing);\n  --chat--window--right: var(--chat--spacing);\n  --chat--window--z-index: 9999;\n  --chat--window--border: 1px solid var(--chat--color-light-shade-50);\n  --chat--window--border-radius: var(--chat--border-radius);\n  --chat--window--margin-bottom: var(--chat--spacing);\n\n  /* Header Styles */\n  --chat--header-height: auto;\n  --chat--header--padding: var(--chat--spacing);\n  --chat--header--background: var(--chat--color-dark);\n  --chat--header--color: var(--chat--color-light);\n  --chat--header--border-top: none;\n  --chat--header--border-bottom: none;\n  --chat--header--border-left: none;\n  --chat--header--border-right: none;\n  --chat--heading--font-size: 2em;\n  --chat--subtitle--font-size: inherit;\n  --chat--subtitle--line-height: 1.8;\n\n  /* Message Styles */\n  --chat--message--font-size: 1rem;\n  --chat--message--padding: var(--chat--spacing);\n  --chat--message--border-radius: var(--chat--border-radius);\n  --chat--message-line-height: 1.5;\n  --chat--message--margin-bottom: calc(var(--chat--spacing) * 1);\n  --chat--message--bot--background: var(--chat--color-white);\n  --chat--message--bot--color: var(--chat--color-dark);\n  --chat--message--bot--border: none;\n  --chat--message--user--background: var(--chat--color-secondary);\n  --chat--message--user--color: var(--chat--color-white);\n  --chat--message--user--border: none;\n  --chat--message--pre--background: rgba(0, 0, 0, 0.05);\n  --chat--messages-list--padding: var(--chat--spacing);\n\n  /* Toggle Button */\n  --chat--toggle--size: 64px;\n  --chat--toggle--width: var(--chat--toggle--size);\n  --chat--toggle--height: var(--chat--toggle--size);\n  --chat--toggle--border-radius: 50%;\n  --chat--toggle--background: var(--chat--color-primary);\n  --chat--toggle--hover--background: var(--chat--color-primary-shade-50);\n  --chat--toggle--active--background: var(--chat--color-primary-shade-100);\n  --chat--toggle--color: var(--chat--color-white);\n\n  /* Input Area */\n  --chat--textarea--height: 50px;\n  --chat--textarea--max-height: 30rem;\n  --chat--input--font-size: inherit;\n  --chat--input--border: 0;\n  --chat--input--border-radius: 0;\n  --chat--input--padding: 0.8rem;\n  --chat--input--background: var(--chat--color-white);\n  --chat--input--text-color: initial;\n  --chat--input--line-height: 1.5;\n  --chat--input--placeholder--font-size: var(--chat--input--font-size);\n  --chat--input--border-active: 0;\n  --chat--input--left--panel--width: 2rem;\n\n  /* Button Styles */\n  --chat--button--color: var(--chat--color-light);\n  --chat--button--background: var(--chat--color-primary);\n  --chat--button--padding: calc(var(--chat--spacing) * 1 / 2) var(--chat--spacing);\n  --chat--button--border-radius: var(--chat--border-radius);\n  --chat--button--hover--color: var(--chat--color-light);\n  --chat--button--hover--background: var(--chat--color-primary-shade-50);\n  --chat--close--button--color-hover: var(--chat--color-primary);\n\n  /* Send and File Buttons */\n  --chat--input--send--button--background: var(--chat--color-white);\n  --chat--input--send--button--color: var(--chat--color-secondary);\n  --chat--input--send--button--background-hover: var(--chat--color-primary-shade-50);\n  --chat--input--send--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--input--file--button--background: var(--chat--color-white);\n  --chat--input--file--button--color: var(--chat--color-secondary);\n  --chat--input--file--button--background-hover: var(--chat--input--file--button--background);\n  --chat--input--file--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--files-spacing: 0.25rem;\n\n  /* Body and Footer */\n  --chat--body--background: var(--chat--color-light);\n  --chat--footer--background: var(--chat--color-light);\n  --chat--footer--color: var(--chat--color-dark);\n}\n\n\n/* You can override any class styles, too. Right-click inspect in Chat UI to find class to override. */\n.chat-message {\n\tmax-width: 50%;\n}","description":"Override default styling of the public chat interface with CSS"},{"displayName":"Response Mode","name":"responseMode","type":"options","options":[{"name":"When Last Node Finishes","value":"lastNode","description":"Returns data of the last-executed node"},{"name":"Using 'Respond to Webhook' Node","value":"responseNode","description":"Response defined in that node"}],"default":"lastNode","description":"When and how to respond to the webhook"}]},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"mode":["hostedChat","webhook"],"public":[true],"@version":[1.2]}},"placeholder":"Add Field","default":{},"options":[{"displayName":"Allowed Origins (CORS)","name":"allowedOrigins","type":"string","default":"*","description":"Comma-separated list of URLs allowed for cross-origin non-preflight requests. Use * (default) to allow all origins.","displayOptions":{"show":{"/mode":["hostedChat","webhook"]}}},{"displayName":"Allow File Uploads","name":"allowFileUploads","type":"boolean","default":false,"description":"Whether to allow file uploads in the chat","displayOptions":{"show":{"/mode":["hostedChat"]}}},{"displayName":"Allowed File Mime Types","name":"allowedFilesMimeTypes","type":"string","default":"*","placeholder":"e.g. image/*, text/*, application/pdf","description":"Allowed file types for upload. Comma-separated list of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types\" target=\"_blank\">MIME types</a>.","displayOptions":{"show":{"/mode":["hostedChat"]}}},{"displayName":"Input Placeholder","name":"inputPlaceholder","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Type your question..","placeholder":"e.g. Type your message here","description":"Shown as placeholder text in the chat input field"},{"displayName":"Load Previous Session","name":"loadPreviousSession","type":"options","options":[{"name":"Off","value":"notSupported","description":"Loading messages of previous session is turned off"},{"name":"From Memory","value":"memory","description":"Load session messages from memory"},{"name":"Manually","value":"manually","description":"Manually return messages of session"}],"default":"notSupported","description":"If loading messages of a previous session should be enabled"},{"displayName":"Require Button Click to Start Chat","name":"showWelcomeScreen","type":"boolean","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":false,"description":"Whether to show the welcome screen at the start of the chat"},{"displayName":"Start Conversation Button Text","name":"getStarted","type":"string","displayOptions":{"show":{"showWelcomeScreen":[true],"/mode":["hostedChat"]}},"default":"New Conversation","placeholder":"e.g. New Conversation","description":"Shown as part of the welcome screen, in the middle of the chat window"},{"displayName":"Subtitle","name":"subtitle","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Start a chat. We're here to help you 24/7.","placeholder":"e.g. We're here for you","description":"Shown at the top of the chat, under the title"},{"displayName":"Title","name":"title","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Hi there! ","placeholder":"e.g. Welcome","description":"Shown at the top of the chat"},{"displayName":"Custom Chat Styling","name":"customCss","type":"string","typeOptions":{"rows":10,"editor":"cssEditor"},"displayOptions":{"show":{"/mode":["hostedChat"]}},"default":":root {\n  /* Colors */\n  --chat--color-primary: #e74266;\n  --chat--color-primary-shade-50: #db4061;\n  --chat--color-primary-shade-100: #cf3c5c;\n  --chat--color-secondary: #20b69e;\n  --chat--color-secondary-shade-50: #1ca08a;\n  --chat--color-white: #ffffff;\n  --chat--color-light: #f2f4f8;\n  --chat--color-light-shade-50: #e6e9f1;\n  --chat--color-light-shade-100: #c2c5cc;\n  --chat--color-medium: #d2d4d9;\n  --chat--color-dark: #101330;\n  --chat--color-disabled: #d2d4d9;\n  --chat--color-typing: #404040;\n\n  /* Base Layout */\n  --chat--spacing: 1rem;\n  --chat--border-radius: 0.25rem;\n  --chat--transition-duration: 0.15s;\n  --chat--font-family: (\n    -apple-system,\n    BlinkMacSystemFont,\n    'Segoe UI',\n    Roboto,\n    Oxygen-Sans,\n    Ubuntu,\n    Cantarell,\n    'Helvetica Neue',\n    sans-serif\n  );\n\n  /* Window Dimensions */\n  --chat--window--width: 400px;\n  --chat--window--height: 600px;\n  --chat--window--bottom: var(--chat--spacing);\n  --chat--window--right: var(--chat--spacing);\n  --chat--window--z-index: 9999;\n  --chat--window--border: 1px solid var(--chat--color-light-shade-50);\n  --chat--window--border-radius: var(--chat--border-radius);\n  --chat--window--margin-bottom: var(--chat--spacing);\n\n  /* Header Styles */\n  --chat--header-height: auto;\n  --chat--header--padding: var(--chat--spacing);\n  --chat--header--background: var(--chat--color-dark);\n  --chat--header--color: var(--chat--color-light);\n  --chat--header--border-top: none;\n  --chat--header--border-bottom: none;\n  --chat--header--border-left: none;\n  --chat--header--border-right: none;\n  --chat--heading--font-size: 2em;\n  --chat--subtitle--font-size: inherit;\n  --chat--subtitle--line-height: 1.8;\n\n  /* Message Styles */\n  --chat--message--font-size: 1rem;\n  --chat--message--padding: var(--chat--spacing);\n  --chat--message--border-radius: var(--chat--border-radius);\n  --chat--message-line-height: 1.5;\n  --chat--message--margin-bottom: calc(var(--chat--spacing) * 1);\n  --chat--message--bot--background: var(--chat--color-white);\n  --chat--message--bot--color: var(--chat--color-dark);\n  --chat--message--bot--border: none;\n  --chat--message--user--background: var(--chat--color-secondary);\n  --chat--message--user--color: var(--chat--color-white);\n  --chat--message--user--border: none;\n  --chat--message--pre--background: rgba(0, 0, 0, 0.05);\n  --chat--messages-list--padding: var(--chat--spacing);\n\n  /* Toggle Button */\n  --chat--toggle--size: 64px;\n  --chat--toggle--width: var(--chat--toggle--size);\n  --chat--toggle--height: var(--chat--toggle--size);\n  --chat--toggle--border-radius: 50%;\n  --chat--toggle--background: var(--chat--color-primary);\n  --chat--toggle--hover--background: var(--chat--color-primary-shade-50);\n  --chat--toggle--active--background: var(--chat--color-primary-shade-100);\n  --chat--toggle--color: var(--chat--color-white);\n\n  /* Input Area */\n  --chat--textarea--height: 50px;\n  --chat--textarea--max-height: 30rem;\n  --chat--input--font-size: inherit;\n  --chat--input--border: 0;\n  --chat--input--border-radius: 0;\n  --chat--input--padding: 0.8rem;\n  --chat--input--background: var(--chat--color-white);\n  --chat--input--text-color: initial;\n  --chat--input--line-height: 1.5;\n  --chat--input--placeholder--font-size: var(--chat--input--font-size);\n  --chat--input--border-active: 0;\n  --chat--input--left--panel--width: 2rem;\n\n  /* Button Styles */\n  --chat--button--color: var(--chat--color-light);\n  --chat--button--background: var(--chat--color-primary);\n  --chat--button--padding: calc(var(--chat--spacing) * 1 / 2) var(--chat--spacing);\n  --chat--button--border-radius: var(--chat--border-radius);\n  --chat--button--hover--color: var(--chat--color-light);\n  --chat--button--hover--background: var(--chat--color-primary-shade-50);\n  --chat--close--button--color-hover: var(--chat--color-primary);\n\n  /* Send and File Buttons */\n  --chat--input--send--button--background: var(--chat--color-white);\n  --chat--input--send--button--color: var(--chat--color-secondary);\n  --chat--input--send--button--background-hover: var(--chat--color-primary-shade-50);\n  --chat--input--send--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--input--file--button--background: var(--chat--color-white);\n  --chat--input--file--button--color: var(--chat--color-secondary);\n  --chat--input--file--button--background-hover: var(--chat--input--file--button--background);\n  --chat--input--file--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--files-spacing: 0.25rem;\n\n  /* Body and Footer */\n  --chat--body--background: var(--chat--color-light);\n  --chat--footer--background: var(--chat--color-light);\n  --chat--footer--color: var(--chat--color-dark);\n}\n\n\n/* You can override any class styles, too. Right-click inspect in Chat UI to find class to override. */\n.chat-message {\n\tmax-width: 50%;\n}","description":"Override default styling of the public chat interface with CSS"},{"displayName":"Response Mode","name":"responseMode","type":"options","options":[{"name":"When Last Node Finishes","value":"lastNode","description":"Returns data of the last-executed node"},{"name":"Using 'Respond to Webhook' Node","value":"responseNode","description":"Response defined in that node"},{"name":"Streaming","value":"streaming","description":"Streaming response from specified nodes (e.g. Agents)"}],"default":"lastNode","description":"When and how to respond to the webhook"}]},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"public":[false],"@version":[{"_cnd":{"gte":1.3}}]}},"placeholder":"Add Field","default":{},"options":[{"displayName":"Allow File Uploads","name":"allowFileUploads","type":"boolean","default":false,"description":"Whether to allow file uploads in the chat"},{"displayName":"Allowed File Mime Types","name":"allowedFilesMimeTypes","type":"string","default":"*","placeholder":"e.g. image/*, text/*, application/pdf","description":"Allowed file types for upload. Comma-separated list of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types\" target=\"_blank\">MIME types</a>."},{"displayName":"Response Mode","name":"responseMode","type":"options","options":[{"name":"When Last Node Finishes","value":"lastNode","description":"Returns data of the last-executed node"},{"name":"Using Response Nodes","value":"responseNodes","description":"Send responses to the chat by using 'Respond to Chat' or 'Respond to Webhook' nodes"}],"default":"lastNode","description":"When and how to respond to the chat"}]},{"displayName":"Options","name":"options","type":"collection","displayOptions":{"show":{"mode":["hostedChat","webhook"],"public":[true],"@version":[{"_cnd":{"gte":1.3}}]}},"placeholder":"Add Field","default":{},"options":[{"displayName":"Allowed Origins (CORS)","name":"allowedOrigins","type":"string","default":"*","description":"Comma-separated list of URLs allowed for cross-origin non-preflight requests. Use * (default) to allow all origins.","displayOptions":{"show":{"/mode":["hostedChat","webhook"]}}},{"displayName":"Allow File Uploads","name":"allowFileUploads","type":"boolean","default":false,"description":"Whether to allow file uploads in the chat","displayOptions":{"show":{"/mode":["hostedChat"]}}},{"displayName":"Allowed File Mime Types","name":"allowedFilesMimeTypes","type":"string","default":"*","placeholder":"e.g. image/*, text/*, application/pdf","description":"Allowed file types for upload. Comma-separated list of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types\" target=\"_blank\">MIME types</a>.","displayOptions":{"show":{"/mode":["hostedChat"]}}},{"displayName":"Input Placeholder","name":"inputPlaceholder","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Type your question..","placeholder":"e.g. Type your message here","description":"Shown as placeholder text in the chat input field"},{"displayName":"Load Previous Session","name":"loadPreviousSession","type":"options","options":[{"name":"Off","value":"notSupported","description":"Loading messages of previous session is turned off"},{"name":"From Memory","value":"memory","description":"Load session messages from memory"},{"name":"Manually","value":"manually","description":"Manually return messages of session"}],"default":"notSupported","description":"If loading messages of a previous session should be enabled"},{"displayName":"Require Button Click to Start Chat","name":"showWelcomeScreen","type":"boolean","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":false,"description":"Whether to show the welcome screen at the start of the chat"},{"displayName":"Start Conversation Button Text","name":"getStarted","type":"string","displayOptions":{"show":{"showWelcomeScreen":[true],"/mode":["hostedChat"]}},"default":"New Conversation","placeholder":"e.g. New Conversation","description":"Shown as part of the welcome screen, in the middle of the chat window"},{"displayName":"Subtitle","name":"subtitle","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Start a chat. We're here to help you 24/7.","placeholder":"e.g. We're here for you","description":"Shown at the top of the chat, under the title"},{"displayName":"Title","name":"title","type":"string","displayOptions":{"show":{"/mode":["hostedChat"]}},"default":"Hi there! ","placeholder":"e.g. Welcome","description":"Shown at the top of the chat"},{"displayName":"Custom Chat Styling","name":"customCss","type":"string","typeOptions":{"rows":10,"editor":"cssEditor"},"displayOptions":{"show":{"/mode":["hostedChat"]}},"default":":root {\n  /* Colors */\n  --chat--color-primary: #e74266;\n  --chat--color-primary-shade-50: #db4061;\n  --chat--color-primary-shade-100: #cf3c5c;\n  --chat--color-secondary: #20b69e;\n  --chat--color-secondary-shade-50: #1ca08a;\n  --chat--color-white: #ffffff;\n  --chat--color-light: #f2f4f8;\n  --chat--color-light-shade-50: #e6e9f1;\n  --chat--color-light-shade-100: #c2c5cc;\n  --chat--color-medium: #d2d4d9;\n  --chat--color-dark: #101330;\n  --chat--color-disabled: #d2d4d9;\n  --chat--color-typing: #404040;\n\n  /* Base Layout */\n  --chat--spacing: 1rem;\n  --chat--border-radius: 0.25rem;\n  --chat--transition-duration: 0.15s;\n  --chat--font-family: (\n    -apple-system,\n    BlinkMacSystemFont,\n    'Segoe UI',\n    Roboto,\n    Oxygen-Sans,\n    Ubuntu,\n    Cantarell,\n    'Helvetica Neue',\n    sans-serif\n  );\n\n  /* Window Dimensions */\n  --chat--window--width: 400px;\n  --chat--window--height: 600px;\n  --chat--window--bottom: var(--chat--spacing);\n  --chat--window--right: var(--chat--spacing);\n  --chat--window--z-index: 9999;\n  --chat--window--border: 1px solid var(--chat--color-light-shade-50);\n  --chat--window--border-radius: var(--chat--border-radius);\n  --chat--window--margin-bottom: var(--chat--spacing);\n\n  /* Header Styles */\n  --chat--header-height: auto;\n  --chat--header--padding: var(--chat--spacing);\n  --chat--header--background: var(--chat--color-dark);\n  --chat--header--color: var(--chat--color-light);\n  --chat--header--border-top: none;\n  --chat--header--border-bottom: none;\n  --chat--header--border-left: none;\n  --chat--header--border-right: none;\n  --chat--heading--font-size: 2em;\n  --chat--subtitle--font-size: inherit;\n  --chat--subtitle--line-height: 1.8;\n\n  /* Message Styles */\n  --chat--message--font-size: 1rem;\n  --chat--message--padding: var(--chat--spacing);\n  --chat--message--border-radius: var(--chat--border-radius);\n  --chat--message-line-height: 1.5;\n  --chat--message--margin-bottom: calc(var(--chat--spacing) * 1);\n  --chat--message--bot--background: var(--chat--color-white);\n  --chat--message--bot--color: var(--chat--color-dark);\n  --chat--message--bot--border: none;\n  --chat--message--user--background: var(--chat--color-secondary);\n  --chat--message--user--color: var(--chat--color-white);\n  --chat--message--user--border: none;\n  --chat--message--pre--background: rgba(0, 0, 0, 0.05);\n  --chat--messages-list--padding: var(--chat--spacing);\n\n  /* Toggle Button */\n  --chat--toggle--size: 64px;\n  --chat--toggle--width: var(--chat--toggle--size);\n  --chat--toggle--height: var(--chat--toggle--size);\n  --chat--toggle--border-radius: 50%;\n  --chat--toggle--background: var(--chat--color-primary);\n  --chat--toggle--hover--background: var(--chat--color-primary-shade-50);\n  --chat--toggle--active--background: var(--chat--color-primary-shade-100);\n  --chat--toggle--color: var(--chat--color-white);\n\n  /* Input Area */\n  --chat--textarea--height: 50px;\n  --chat--textarea--max-height: 30rem;\n  --chat--input--font-size: inherit;\n  --chat--input--border: 0;\n  --chat--input--border-radius: 0;\n  --chat--input--padding: 0.8rem;\n  --chat--input--background: var(--chat--color-white);\n  --chat--input--text-color: initial;\n  --chat--input--line-height: 1.5;\n  --chat--input--placeholder--font-size: var(--chat--input--font-size);\n  --chat--input--border-active: 0;\n  --chat--input--left--panel--width: 2rem;\n\n  /* Button Styles */\n  --chat--button--color: var(--chat--color-light);\n  --chat--button--background: var(--chat--color-primary);\n  --chat--button--padding: calc(var(--chat--spacing) * 1 / 2) var(--chat--spacing);\n  --chat--button--border-radius: var(--chat--border-radius);\n  --chat--button--hover--color: var(--chat--color-light);\n  --chat--button--hover--background: var(--chat--color-primary-shade-50);\n  --chat--close--button--color-hover: var(--chat--color-primary);\n\n  /* Send and File Buttons */\n  --chat--input--send--button--background: var(--chat--color-white);\n  --chat--input--send--button--color: var(--chat--color-secondary);\n  --chat--input--send--button--background-hover: var(--chat--color-primary-shade-50);\n  --chat--input--send--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--input--file--button--background: var(--chat--color-white);\n  --chat--input--file--button--color: var(--chat--color-secondary);\n  --chat--input--file--button--background-hover: var(--chat--input--file--button--background);\n  --chat--input--file--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--files-spacing: 0.25rem;\n\n  /* Body and Footer */\n  --chat--body--background: var(--chat--color-light);\n  --chat--footer--background: var(--chat--color-light);\n  --chat--footer--color: var(--chat--color-dark);\n}\n\n\n/* You can override any class styles, too. Right-click inspect in Chat UI to find class to override. */\n.chat-message {\n\tmax-width: 50%;\n}","description":"Override default styling of the public chat interface with CSS"},{"displayName":"Response Mode","name":"responseMode","type":"options","options":[{"name":"When Last Node Finishes","value":"lastNode","description":"Returns data of the last-executed node"},{"name":"Streaming","value":"streaming","description":"Streaming response from specified nodes (e.g. Agents)"},{"name":"Using 'Respond to Webhook' Node","value":"responseNode","description":"Response defined in that node"}],"default":"lastNode","description":"When and how to respond to the chat","displayOptions":{"show":{"/mode":["webhook"]}}},{"displayName":"Response Mode","name":"responseMode","type":"options","options":[{"name":"When Last Node Finishes","value":"lastNode","description":"Returns data of the last-executed node"},{"name":"Streaming","value":"streaming","description":"Streaming response from specified nodes (e.g. Agents)"},{"name":"Using Response Nodes","value":"responseNodes","description":"Send responses to the chat by using 'Respond to Chat' or 'Respond to Webhook' nodes"}],"default":"lastNode","description":"When and how to respond to the webhook","displayOptions":{"show":{"/mode":["hostedChat"]}}}]}]},
{"displayName":"Respond to Chat","name":"chat","icon":"fa:comments","iconColor":"black","group":["input"],"version":1,"description":"Send a message to a chat","defaults":{"name":"Respond to Chat"},"codex":{"categories":["Core Nodes","HITL"],"subcategories":{"HITL":["Human in the Loop"]},"alias":["human","wait","hitl"],"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chat/"}]}},"inputs":"={{ ((parameters) => {\n  const inputs = [\n    {\n      type: \"main\",\n      displayName: \"User Response\"\n    }\n  ];\n  if (parameters.options?.memoryConnection) {\n    return [\n      ...inputs,\n      {\n        type: \"ai_memory\",\n        displayName: \"Memory\",\n        maxConnections: 1\n      }\n    ];\n  }\n  return inputs;\n})($parameter) }}","outputs":["main"],"properties":[{"displayName":"Verify you're using a chat trigger with the 'Response Mode' option set to 'Using Response Nodes'","name":"generalNotice","type":"notice","default":""},{"displayName":"Message","name":"message","type":"string","default":"","required":true,"typeOptions":{"rows":6}},{"displayName":"Wait for User Reply","name":"waitUserReply","type":"boolean","default":true},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Add Memory Input Connection","name":"memoryConnection","type":"boolean","default":false},{"displayName":"Limit Wait Time","name":"limitWaitTime","type":"fixedCollection","description":"Whether to limit the time this node should wait for a user response before execution resumes","default":{"values":{"limitType":"afterTimeInterval","resumeAmount":45,"resumeUnit":"minutes"}},"options":[{"displayName":"Values","name":"values","values":[{"displayName":"Limit Type","name":"limitType","type":"options","default":"afterTimeInterval","description":"Sets the condition for the execution to resume. Can be a specified date or after some time.","options":[{"name":"After Time Interval","description":"Waits for a certain amount of time","value":"afterTimeInterval"},{"name":"At Specified Time","description":"Waits until the set date and time to continue","value":"atSpecifiedTime"}]},{"displayName":"Amount","name":"resumeAmount","type":"number","displayOptions":{"show":{"limitType":["afterTimeInterval"]}},"typeOptions":{"minValue":0,"numberPrecision":2},"default":1,"description":"The time to wait"},{"displayName":"Unit","name":"resumeUnit","type":"options","displayOptions":{"show":{"limitType":["afterTimeInterval"]}},"options":[{"name":"Minutes","value":"minutes"},{"name":"Hours","value":"hours"},{"name":"Days","value":"days"}],"default":"hours","description":"Unit of the interval value"},{"displayName":"Max Date and Time","name":"maxDateAndTime","type":"dateTime","displayOptions":{"show":{"limitType":["atSpecifiedTime"]}},"default":"","description":"Continue execution after the specified date and time"}]}],"displayOptions":{"show":{"/waitUserReply":[true]}}}]}]},
{"displayName":"Simple Vector Store","name":"vectorStoreInMemory","description":"The easiest way to experiment with vector stores, without external setup.","icon":"fa:database","iconColor":"black","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Simple Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["For Beginners"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/"}]}},"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. The easiest way to experiment with vector stores, without external setup.","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"Memory Key","name":"memoryKey","type":"string","default":"vector_store_key","description":"The key to use to store the vector memory in the workflow data. The key will be prefixed with the workflow ID to avoid collisions.","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.1}}]}}},{"displayName":"Memory Key","name":"memoryKey","type":"resourceLocator","required":true,"default":{"mode":"list","value":"vector_store_key"},"description":"The key to use to store the vector memory in the workflow data. These keys are shared between workflows.","displayOptions":{"show":{"@version":[{"_cnd":{"gte":1.2}}]}},"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"vectorStoresSearch","searchable":true,"allowNewResource":{"label":"resourceLocator.mode.list.addNewResource.vectorStoreInMemory","defaultName":"vector_store_key","method":"createVectorStore"}}},{"displayName":"Manual","name":"id","type":"string","placeholder":"vector_store_key"}]},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Clear Store","name":"clearStore","type":"boolean","default":false,"description":"Whether to clear the store before inserting new data","displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"<strong>For experimental use only</strong>: Data is stored in memory and will be lost if n8n restarts. Data may also be cleared if available memory gets low, and is accessible to all users of this instance. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/\">More info</a>","name":"notice","type":"notice","default":"","displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"<strong>For experimental use only</strong>: Data is stored in memory and will be lost if n8n restarts. Data may also be cleared if available memory gets low, and is accessible to all users of this instance. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/\">More info</a>","name":"notice","type":"notice","default":"","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"<strong>For experimental use only</strong>: Data is stored in memory and will be lost if n8n restarts. Data may also be cleared if available memory gets low, and is accessible to all users of this instance. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/\">More info</a>","name":"notice","type":"notice","default":"","displayOptions":{"show":{"mode":["retrieve"]}}}]},
{"displayName":"In Memory Vector Store Insert","name":"vectorStoreInMemoryInsert","icon":"fa:database","group":["transform"],"version":1,"hidden":true,"description":"Insert data into an in-memory vector store","defaults":{"name":"In Memory Vector Store Insert"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/"}]}},"inputs":["main",{"displayName":"Document","maxConnections":1,"type":"ai_document","required":true},{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["main"],"properties":[{"displayName":"The embbded data are stored in the server memory, so they will be lost when the server is restarted. Additionally, if the amount of data is too large, it may cause the server to crash due to insufficient memory.","name":"notice","type":"notice","default":""},{"displayName":"Clear Store","name":"clearStore","type":"boolean","default":false,"description":"Whether to clear the store before inserting new data"},{"displayName":"Memory Key","name":"memoryKey","type":"string","default":"vector_store_key","description":"The key to use to store the vector memory in the workflow data. The key will be prefixed with the workflow ID to avoid collisions."}]},
{"displayName":"In Memory Vector Store Load","name":"vectorStoreInMemoryLoad","icon":"fa:database","group":["transform"],"version":1,"hidden":true,"description":"Load embedded data from an in-memory vector store","defaults":{"name":"In Memory Vector Store Load"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/"}]}},"inputs":[{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["ai_vectorStore"],"outputNames":["Vector Store"],"properties":[{"displayName":"Memory Key","name":"memoryKey","type":"string","default":"vector_store_key","description":"The key to use to store the vector memory in the workflow data. The key will be prefixed with the workflow ID to avoid collisions."}]},
{"displayName":"Milvus Vector Store","name":"vectorStoreMilvus","description":"Work with your data in Milvus Vector Store","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Milvus Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoremilvus/"}]}},"credentials":[{"name":"milvusApi","required":true}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in Milvus Vector Store","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"Milvus Collection","name":"milvusCollection","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"milvusCollectionsSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Clear Collection","name":"clearCollection","type":"boolean","default":false,"description":"Whether to clear the collection before inserting new data"}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreMilvus/milvus-icon-black.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreMilvus/milvus-icon-white.svg"}},
{"displayName":"MongoDB Atlas Vector Store","name":"vectorStoreMongoDBAtlas","description":"Work with your data in MongoDB Atlas Vector Store","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"MongoDB Atlas Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoremongodbatlas/"}]}},"credentials":[{"name":"mongoDb","required":true}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"},{"name":"Update Documents","value":"update","description":"Update documents in vector store by ID","action":"Update vector store documents"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in MongoDB Atlas Vector Store","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"MongoDB Collection","name":"mongoCollection","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"mongoCollectionSearch"}},{"displayName":"Name","name":"name","type":"string","placeholder":"e.g. my_collection"}]},{"displayName":"Embedding","name":"embedding","type":"string","default":"embedding","description":"The field with the embedding array","required":true},{"displayName":"Metadata Field","name":"metadata_field","type":"string","default":"text","description":"The text field of the raw data","required":true},{"displayName":"Vector Index Name","name":"vectorIndexName","type":"string","default":"","description":"The name of the vector index","required":true},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Clear Namespace","name":"clearNamespace","type":"boolean","default":false,"description":"Whether to clear documents in the namespace before inserting new data"},{"displayName":"Namespace","name":"namespace","type":"string","description":"Logical partition for documents. Uses metadata.namespace field for filtering.","default":""}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Namespace","name":"namespace","type":"string","description":"Logical partition for documents. Uses metadata.namespace field for filtering.","default":""},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]},{"displayName":"Pre Filter","name":"preFilter","type":"json","typeOptions":{"alwaysOpenEditWindow":true},"default":"","placeholder":"{ \"key\": \"value\" }","hint":"This is a filter applied in the $vectorSearch stage <a href=\"https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter\">here</a>","required":true,"description":"MongoDB Atlas Vector Search pre-filter"},{"displayName":"Post Filter Pipeline","name":"postFilterPipeline","type":"json","typeOptions":{"alwaysOpenEditWindow":true},"default":"","placeholder":"[{ \"$match\": { \"$gt\": \"1950-01-01\" }, ... }]","hint":"Learn more about aggregation pipeline <a href=\"https://docs.mongodb.com/manual/core/aggregation-pipeline/\">here</a>","required":true,"description":"MongoDB aggregation pipeline in JSON format"}],"displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Namespace","name":"namespace","type":"string","description":"Logical partition for documents. Uses metadata.namespace field for filtering.","default":""},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]},{"displayName":"Pre Filter","name":"preFilter","type":"json","typeOptions":{"alwaysOpenEditWindow":true},"default":"","placeholder":"{ \"key\": \"value\" }","hint":"This is a filter applied in the $vectorSearch stage <a href=\"https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter\">here</a>","required":true,"description":"MongoDB Atlas Vector Search pre-filter"},{"displayName":"Post Filter Pipeline","name":"postFilterPipeline","type":"json","typeOptions":{"alwaysOpenEditWindow":true},"default":"","placeholder":"[{ \"$match\": { \"$gt\": \"1950-01-01\" }, ... }]","hint":"Learn more about aggregation pipeline <a href=\"https://docs.mongodb.com/manual/core/aggregation-pipeline/\">here</a>","required":true,"description":"MongoDB aggregation pipeline in JSON format"}],"displayOptions":{"show":{"mode":["retrieve"]}}}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreMongoDBAtlas/mongodb.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreMongoDBAtlas/mongodb.dark.svg"}},
{"displayName":"Postgres PGVector Store","name":"vectorStorePGVector","description":"Work with your data in Postgresql with the PGVector extension","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Postgres PGVector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepgvector/"}]}},"credentials":[{"name":"postgres","required":true,"testedBy":"postgresConnectionTest"}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in Postgresql with the PGVector extension","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"Table Name","name":"tableName","type":"string","default":"n8n_vectors","description":"The table name to store the vectors in. If table does not exist, it will be created."},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Collection","name":"collection","type":"fixedCollection","description":"Collection of vectors","default":{"values":{"useCollection":false,"collectionName":"n8n","collectionTable":"n8n_vector_collections"}},"typeOptions":{},"placeholder":"Add Collection Settings","options":[{"name":"values","displayName":"Collection Settings","values":[{"displayName":"Use Collection","name":"useCollection","type":"boolean","default":false},{"displayName":"Collection Name","name":"collectionName","type":"string","default":"n8n","required":true,"displayOptions":{"show":{"useCollection":[true]}}},{"displayName":"Collection Table Name","name":"collectionTableName","type":"string","default":"n8n_vector_collections","required":true,"displayOptions":{"show":{"useCollection":[true]}}}]}]},{"displayName":"Column Names","name":"columnNames","type":"fixedCollection","description":"The names of the columns in the PGVector table","default":{"values":{"idColumnName":"id","vectorColumnName":"embedding","contentColumnName":"text","metadataColumnName":"metadata"}},"typeOptions":{},"placeholder":"Set Column Names","options":[{"name":"values","displayName":"Column Name Settings","values":[{"displayName":"ID Column Name","name":"idColumnName","type":"string","default":"id","required":true},{"displayName":"Vector Column Name","name":"vectorColumnName","type":"string","default":"embedding","required":true},{"displayName":"Content Column Name","name":"contentColumnName","type":"string","default":"text","required":true},{"displayName":"Metadata Column Name","name":"metadataColumnName","type":"string","default":"metadata","required":true}]}]}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Distance Strategy","name":"distanceStrategy","type":"options","default":"cosine","description":"The method to calculate the distance between two vectors","options":[{"name":"Cosine","value":"cosine"},{"name":"Inner Product","value":"innerProduct"},{"name":"Euclidean","value":"euclidean"}]},{"displayName":"Collection","name":"collection","type":"fixedCollection","description":"Collection of vectors","default":{"values":{"useCollection":false,"collectionName":"n8n","collectionTable":"n8n_vector_collections"}},"typeOptions":{},"placeholder":"Add Collection Settings","options":[{"name":"values","displayName":"Collection Settings","values":[{"displayName":"Use Collection","name":"useCollection","type":"boolean","default":false},{"displayName":"Collection Name","name":"collectionName","type":"string","default":"n8n","required":true,"displayOptions":{"show":{"useCollection":[true]}}},{"displayName":"Collection Table Name","name":"collectionTableName","type":"string","default":"n8n_vector_collections","required":true,"displayOptions":{"show":{"useCollection":[true]}}}]}]},{"displayName":"Column Names","name":"columnNames","type":"fixedCollection","description":"The names of the columns in the PGVector table","default":{"values":{"idColumnName":"id","vectorColumnName":"embedding","contentColumnName":"text","metadataColumnName":"metadata"}},"typeOptions":{},"placeholder":"Set Column Names","options":[{"name":"values","displayName":"Column Name Settings","values":[{"displayName":"ID Column Name","name":"idColumnName","type":"string","default":"id","required":true},{"displayName":"Vector Column Name","name":"vectorColumnName","type":"string","default":"embedding","required":true},{"displayName":"Content Column Name","name":"contentColumnName","type":"string","default":"text","required":true},{"displayName":"Metadata Column Name","name":"metadataColumnName","type":"string","default":"metadata","required":true}]}]},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Distance Strategy","name":"distanceStrategy","type":"options","default":"cosine","description":"The method to calculate the distance between two vectors","options":[{"name":"Cosine","value":"cosine"},{"name":"Inner Product","value":"innerProduct"},{"name":"Euclidean","value":"euclidean"}]},{"displayName":"Collection","name":"collection","type":"fixedCollection","description":"Collection of vectors","default":{"values":{"useCollection":false,"collectionName":"n8n","collectionTable":"n8n_vector_collections"}},"typeOptions":{},"placeholder":"Add Collection Settings","options":[{"name":"values","displayName":"Collection Settings","values":[{"displayName":"Use Collection","name":"useCollection","type":"boolean","default":false},{"displayName":"Collection Name","name":"collectionName","type":"string","default":"n8n","required":true,"displayOptions":{"show":{"useCollection":[true]}}},{"displayName":"Collection Table Name","name":"collectionTableName","type":"string","default":"n8n_vector_collections","required":true,"displayOptions":{"show":{"useCollection":[true]}}}]}]},{"displayName":"Column Names","name":"columnNames","type":"fixedCollection","description":"The names of the columns in the PGVector table","default":{"values":{"idColumnName":"id","vectorColumnName":"embedding","contentColumnName":"text","metadataColumnName":"metadata"}},"typeOptions":{},"placeholder":"Set Column Names","options":[{"name":"values","displayName":"Column Name Settings","values":[{"displayName":"ID Column Name","name":"idColumnName","type":"string","default":"id","required":true},{"displayName":"Vector Column Name","name":"vectorColumnName","type":"string","default":"embedding","required":true},{"displayName":"Content Column Name","name":"contentColumnName","type":"string","default":"text","required":true},{"displayName":"Metadata Column Name","name":"metadataColumnName","type":"string","default":"metadata","required":true}]}]},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["retrieve"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStorePGVector/postgres.svg"},
{"displayName":"Pinecone Vector Store","name":"vectorStorePinecone","description":"Work with your data in Pinecone Vector Store","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Pinecone Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/"}]}},"credentials":[{"name":"pineconeApi","required":true}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"},{"name":"Update Documents","value":"update","description":"Update documents in vector store by ID","action":"Update vector store documents"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in Pinecone Vector Store","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"Pinecone Index","name":"pineconeIndex","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"pineconeIndexSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Clear Namespace","name":"clearNamespace","type":"boolean","default":false,"description":"Whether to clear the namespace before inserting new data"},{"displayName":"Pinecone Namespace","name":"pineconeNamespace","type":"string","description":"Partition the records in an index into namespaces. Queries and other operations are then limited to one namespace, so different requests can search different subsets of your index.","default":""}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Pinecone Namespace","name":"pineconeNamespace","type":"string","description":"Partition the records in an index into namespaces. Queries and other operations are then limited to one namespace, so different requests can search different subsets of your index.","default":""},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Pinecone Namespace","name":"pineconeNamespace","type":"string","description":"Partition the records in an index into namespaces. Queries and other operations are then limited to one namespace, so different requests can search different subsets of your index.","default":""},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["retrieve"]}}}],"iconUrl":{"light":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStorePinecone/pinecone.svg","dark":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStorePinecone/pinecone.dark.svg"}},
{"displayName":"Pinecone: Insert","hidden":true,"name":"vectorStorePineconeInsert","group":["transform"],"version":1,"description":"Insert data into Pinecone Vector Store index","defaults":{"name":"Pinecone: Insert","color":"#1321A7"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/"}]}},"credentials":[{"name":"pineconeApi","required":true}],"inputs":["main",{"displayName":"Document","maxConnections":1,"type":"ai_document","required":true},{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["main"],"properties":[{"displayName":"Pinecone Index","name":"pineconeIndex","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"pineconeIndexSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Pinecone Namespace","name":"pineconeNamespace","type":"string","default":""},{"displayName":"Specify the document to load in the document loader sub-node","name":"notice","type":"notice","default":""},{"displayName":"Clear Namespace","name":"clearNamespace","type":"boolean","default":false,"description":"Whether to clear the namespace before inserting new data"}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStorePineconeInsert/pinecone.svg"},
{"displayName":"Pinecone: Load","hidden":true,"name":"vectorStorePineconeLoad","group":["transform"],"version":1,"description":"Load data from Pinecone Vector Store index","defaults":{"name":"Pinecone: Load"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/"}]}},"credentials":[{"name":"pineconeApi","required":true}],"inputs":[{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["ai_vectorStore"],"outputNames":["Vector Store"],"properties":[{"displayName":"Pinecone Index","name":"pineconeIndex","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"pineconeIndexSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Pinecone Namespace","name":"pineconeNamespace","type":"string","default":""},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStorePineconeLoad/pinecone.svg"},
{"displayName":"Qdrant Vector Store","name":"vectorStoreQdrant","description":"Work with your data in a Qdrant collection","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Qdrant Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant/"}]}},"credentials":[{"name":"qdrantApi","required":true}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in a Qdrant collection","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"Qdrant Collection","name":"qdrantCollection","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"qdrantCollectionsSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Collection Config","name":"collectionConfig","type":"json","default":"","description":"JSON options for creating a collection. <a href=\"https://qdrant.tech/documentation/concepts/collections\">Learn more</a>."}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Search Filter","name":"searchFilterJson","type":"json","typeOptions":{"rows":5},"default":"{\n  \"should\": [\n    {\n      \"key\": \"metadata.batch\",\n      \"match\": {\n        \"value\": 12345\n      }\n    }\n  ]\n}","validateType":"object","description":"Filter pageContent or metadata using this <a href=\"https://qdrant.tech/documentation/concepts/filtering/\" target=\"_blank\">filtering syntax</a>"}],"displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Search Filter","name":"searchFilterJson","type":"json","typeOptions":{"rows":5},"default":"{\n  \"should\": [\n    {\n      \"key\": \"metadata.batch\",\n      \"match\": {\n        \"value\": 12345\n      }\n    }\n  ]\n}","validateType":"object","description":"Filter pageContent or metadata using this <a href=\"https://qdrant.tech/documentation/concepts/filtering/\" target=\"_blank\">filtering syntax</a>"}],"displayOptions":{"show":{"mode":["retrieve"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreQdrant/qdrant.svg"},
{"displayName":"Supabase Vector Store","name":"vectorStoreSupabase","description":"Work with your data in Supabase Vector Store","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Supabase Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoresupabase/"}]}},"credentials":[{"name":"supabaseApi","required":true}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"},{"name":"Update Documents","value":"update","description":"Update documents in vector store by ID","action":"Update vector store documents"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in Supabase Vector Store","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"Table Name","name":"tableName","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"supabaseTableNameSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Query Name","name":"queryName","type":"string","default":"match_documents","description":"Name of the query to use for matching documents"}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Query Name","name":"queryName","type":"string","default":"match_documents","description":"Name of the query to use for matching documents"},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Query Name","name":"queryName","type":"string","default":"match_documents","description":"Name of the query to use for matching documents"},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Query Name","name":"queryName","type":"string","default":"match_documents","description":"Name of the query to use for matching documents"}],"displayOptions":{"show":{"mode":["update"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreSupabase/supabase.svg"},
{"displayName":"Supabase: Insert","hidden":true,"name":"vectorStoreSupabaseInsert","group":["transform"],"version":1,"description":"Insert data into Supabase Vector Store index [https://supabase.com/docs/guides/ai/langchain]","defaults":{"name":"Supabase: Insert"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoresupabase/"}]}},"credentials":[{"name":"supabaseApi","required":true}],"inputs":["main",{"displayName":"Document","maxConnections":1,"type":"ai_document","required":true},{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["main"],"properties":[{"displayName":"Please refer to the <a href=\"https://supabase.com/docs/guides/ai/langchain\" target=\"_blank\">Supabase documentation</a> for more information on how to setup your database as a Vector Store.","name":"setupNotice","type":"notice","default":""},{"displayName":"Table Name","name":"tableName","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"supabaseTableNameSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Query Name","name":"queryName","type":"string","default":"match_documents","required":true,"description":"Name of the query to use for matching documents"},{"displayName":"Specify the document to load in the document loader sub-node","name":"notice","type":"notice","default":""}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreSupabaseInsert/supabase.svg"},
{"displayName":"Supabase: Load","name":"vectorStoreSupabaseLoad","hidden":true,"group":["transform"],"version":1,"description":"Load data from Supabase Vector Store index","defaults":{"name":"Supabase: Load"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoresupabase/"}]}},"credentials":[{"name":"supabaseApi","required":true}],"inputs":[{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["ai_vectorStore"],"outputNames":["Vector Store"],"properties":[{"displayName":"Table Name","name":"tableName","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"supabaseTableNameSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Query Name","name":"queryName","type":"string","default":"match_documents","required":true,"description":"Name of the query to use for matching documents"},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreSupabaseLoad/supabase.svg"},
{"displayName":"Weaviate Vector Store","name":"vectorStoreWeaviate","description":"Work with your data in a Weaviate Cluster","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Weaviate Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreweaviate/"}]}},"credentials":[{"name":"weaviateApi","required":true}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in a Weaviate Cluster","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"Weaviate Collection","name":"weaviateCollection","type":"resourceLocator","default":{"mode":"list","value":""},"required":true,"modes":[{"displayName":"From List","name":"list","type":"list","typeOptions":{"searchListMethod":"weaviateCollectionsSearch"}},{"displayName":"ID","name":"id","type":"string"}]},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Tenant Name","name":"tenant","type":"string","validateType":"string","description":"Tenant Name. Collection must have been created with tenant support enabled."},{"displayName":"Text Key","name":"textKey","type":"string","default":"text","validateType":"string","description":"The key in the document that contains the embedded text"},{"displayName":"Skip Init Checks","name":"skip_init_checks","type":"boolean","default":false,"validateType":"boolean","description":"Whether to skip init checks while instantiating the client"},{"displayName":"Init Timeout","name":"timeout_init","type":"number","default":2,"validateType":"number","description":"Number of timeout seconds for initial checks"},{"displayName":"Insert Timeout","name":"timeout_insert","type":"number","default":90,"validateType":"number","description":"Number of timeout seconds for inserts"},{"displayName":"Query Timeout","name":"timeout_query","type":"number","default":30,"validateType":"number","description":"Number of timeout seconds for queries"},{"displayName":"GRPC Proxy","name":"proxy_grpc","type":"string","validateType":"string","description":"Proxy to use for GRPC"},{"displayName":"Clear Data","name":"clearStore","type":"boolean","default":false,"description":"Whether to clear the Collection/Tenant before inserting new data"}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Search Filters","name":"searchFilterJson","type":"json","typeOptions":{"rows":5},"default":"{\n  \"OR\": [\n    {\n        \"path\": [\"pdf_info_Author\"],\n        \"operator\": \"Equal\",\n        \"valueString\": \"Elis\"\n    },\n    {\n        \"path\": [\"pdf_info_Author\"],\n        \"operator\": \"Equal\",\n        \"valueString\": \"Pinnacle\"\n    }    \n  ]\n}","validateType":"object","description":"Filter pageContent or metadata using this <a href=\"https://weaviate.io/\" target=\"_blank\">filtering syntax</a>"},{"displayName":"Metadata Keys","name":"metadataKeys","type":"string","default":"source,page","validateType":"string","description":"Select the metadata to retrieve along the content"},{"displayName":"Tenant Name","name":"tenant","type":"string","validateType":"string","description":"Tenant Name. Collection must have been created with tenant support enabled."},{"displayName":"Text Key","name":"textKey","type":"string","default":"text","validateType":"string","description":"The key in the document that contains the embedded text"},{"displayName":"Skip Init Checks","name":"skip_init_checks","type":"boolean","default":false,"validateType":"boolean","description":"Whether to skip init checks while instantiating the client"},{"displayName":"Init Timeout","name":"timeout_init","type":"number","default":2,"validateType":"number","description":"Number of timeout seconds for initial checks"},{"displayName":"Insert Timeout","name":"timeout_insert","type":"number","default":90,"validateType":"number","description":"Number of timeout seconds for inserts"},{"displayName":"Query Timeout","name":"timeout_query","type":"number","default":30,"validateType":"number","description":"Number of timeout seconds for queries"},{"displayName":"GRPC Proxy","name":"proxy_grpc","type":"string","validateType":"string","description":"Proxy to use for GRPC"}],"displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Search Filters","name":"searchFilterJson","type":"json","typeOptions":{"rows":5},"default":"{\n  \"OR\": [\n    {\n        \"path\": [\"pdf_info_Author\"],\n        \"operator\": \"Equal\",\n        \"valueString\": \"Elis\"\n    },\n    {\n        \"path\": [\"pdf_info_Author\"],\n        \"operator\": \"Equal\",\n        \"valueString\": \"Pinnacle\"\n    }    \n  ]\n}","validateType":"object","description":"Filter pageContent or metadata using this <a href=\"https://weaviate.io/\" target=\"_blank\">filtering syntax</a>"},{"displayName":"Metadata Keys","name":"metadataKeys","type":"string","default":"source,page","validateType":"string","description":"Select the metadata to retrieve along the content"},{"displayName":"Tenant Name","name":"tenant","type":"string","validateType":"string","description":"Tenant Name. Collection must have been created with tenant support enabled."},{"displayName":"Text Key","name":"textKey","type":"string","default":"text","validateType":"string","description":"The key in the document that contains the embedded text"},{"displayName":"Skip Init Checks","name":"skip_init_checks","type":"boolean","default":false,"validateType":"boolean","description":"Whether to skip init checks while instantiating the client"},{"displayName":"Init Timeout","name":"timeout_init","type":"number","default":2,"validateType":"number","description":"Number of timeout seconds for initial checks"},{"displayName":"Insert Timeout","name":"timeout_insert","type":"number","default":90,"validateType":"number","description":"Number of timeout seconds for inserts"},{"displayName":"Query Timeout","name":"timeout_query","type":"number","default":30,"validateType":"number","description":"Number of timeout seconds for queries"},{"displayName":"GRPC Proxy","name":"proxy_grpc","type":"string","validateType":"string","description":"Proxy to use for GRPC"}],"displayOptions":{"show":{"mode":["retrieve"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreWeaviate/weaviate.svg"},
{"displayName":"Zep Vector Store","name":"vectorStoreZep","description":"Work with your data in Zep Vector Store","group":["transform"],"version":[1,1.1,1.2,1.3],"defaults":{"name":"Zep Vector Store"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores","Tools","Root Nodes"],"Vector Stores":["Other Vector Stores"],"Tools":["Other Tools"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorezep/"}]}},"credentials":[{"name":"zepApi","required":true}],"inputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode;\n\t\t\t\tconst useReranker = parameters?.useReranker;\n\t\t\t\tconst inputs = [{ displayName: \"Embedding\", type: \"ai_embedding\", required: true, maxConnections: 1}]\n\n\t\t\t\tif (['load', 'retrieve', 'retrieve-as-tool'].includes(mode) && useReranker) {\n\t\t\t\t\tinputs.push({ displayName: \"Reranker\", type: \"ai_reranker\", required: true, maxConnections: 1})\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn inputs;\n\t\t\t\t}\n\n\t\t\t\tif (['insert', 'load', 'update'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"\", type: \"main\"})\n\t\t\t\t}\n\n\t\t\t\tif (['insert'].includes(mode)) {\n\t\t\t\t\tinputs.push({ displayName: \"Document\", type: \"ai_document\", required: true, maxConnections: 1})\n\t\t\t\t}\n\t\t\t\treturn inputs\n\t\t\t})($parameter)\n\t\t}}","outputs":"={{\n\t\t\t((parameters) => {\n\t\t\t\tconst mode = parameters?.mode ?? 'retrieve';\n\n\t\t\t\tif (mode === 'retrieve-as-tool') {\n\t\t\t\t\treturn [{ displayName: \"Tool\", type: \"ai_tool\"}]\n\t\t\t\t}\n\n\t\t\t\tif (mode === 'retrieve') {\n\t\t\t\t\treturn [{ displayName: \"Vector Store\", type: \"ai_vectorStore\"}]\n\t\t\t\t}\n\t\t\t\treturn [{ displayName: \"\", type: \"main\"}]\n\t\t\t})($parameter)\n\t\t}}","properties":[{"displayName":"Tip: Get a feel for vector stores in n8n with our","name":"ragStarterCallout","type":"callout","typeOptions":{"calloutAction":{"label":"RAG starter template","type":"openSampleWorkflowTemplate","templateId":"rag-starter-template"}},"default":""},{"displayName":"Operation Mode","name":"mode","type":"options","noDataExpression":true,"default":"retrieve","options":[{"name":"Get Many","value":"load","description":"Get many ranked documents from vector store for query","action":"Get ranked documents from vector store"},{"name":"Insert Documents","value":"insert","description":"Insert documents into vector store","action":"Add documents to vector store"},{"name":"Retrieve Documents (As Vector Store for Chain/Tool)","value":"retrieve","description":"Retrieve documents from vector store to be used as vector store with AI nodes","action":"Retrieve documents for Chain/Tool as Vector Store","outputConnectionType":"ai_vectorStore"},{"name":"Retrieve Documents (As Tool for AI Agent)","value":"retrieve-as-tool","description":"Retrieve documents from vector store to be used as tool with AI nodes","action":"Retrieve documents for AI Agent as Tool","outputConnectionType":"ai_tool"}]},{"displayName":"This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>","name":"notice","type":"notice","default":"","typeOptions":{"containerClass":"ndv-connection-hint-notice"},"displayOptions":{"show":{"mode":["retrieve"]}}},{"displayName":"Name","name":"toolName","type":"string","default":"","required":true,"description":"Name of the vector store","placeholder":"e.g. company_knowledge_base","validateType":"string-alphanumeric","displayOptions":{"show":{"@version":[{"_cnd":{"lte":1.2}}],"mode":["retrieve-as-tool"]}}},{"displayName":"Description","name":"toolDescription","type":"string","default":"","required":true,"typeOptions":{"rows":2},"description":"Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often","placeholder":"e.g. Work with your data in Zep Vector Store","displayOptions":{"show":{"mode":["retrieve-as-tool"]}}},{"displayName":"This Zep integration is deprecated and will be removed in a future version.","name":"deprecationNotice","type":"notice","default":""},{"displayName":"Collection Name","name":"collectionName","type":"string","default":"","required":true},{"displayName":"Embedding Batch Size","name":"embeddingBatchSize","type":"number","default":200,"description":"Number of documents to embed in a single batch","displayOptions":{"show":{"mode":["insert"],"@version":[{"_cnd":{"gte":1.1}}]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Embedding Dimensions","name":"embeddingDimensions","type":"number","default":1536,"description":"Whether to allow using characters from the Unicode surrogate blocks"},{"displayName":"Is Auto Embedded","name":"isAutoEmbedded","type":"boolean","default":true,"description":"Whether to automatically embed documents when they are added"}],"displayOptions":{"show":{"mode":["insert"]}}},{"displayName":"Prompt","name":"prompt","type":"string","default":"","required":true,"description":"Search prompt to retrieve matching documents from the vector store using similarity-based ranking","displayOptions":{"show":{"mode":["load"]}}},{"displayName":"Limit","name":"topK","type":"number","default":4,"description":"Number of top results to fetch from vector store","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Include Metadata","name":"includeDocumentMetadata","type":"boolean","default":true,"description":"Whether or not to include document metadata","displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Rerank Results","name":"useReranker","type":"boolean","default":false,"description":"Whether or not to rerank results","displayOptions":{"show":{"mode":["load","retrieve","retrieve-as-tool"]}}},{"displayName":"ID","name":"id","type":"string","default":"","required":true,"description":"ID of an embedding entry","displayOptions":{"show":{"mode":["update"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Embedding Dimensions","name":"embeddingDimensions","type":"number","default":1536,"description":"Whether to allow using characters from the Unicode surrogate blocks"},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["load","retrieve-as-tool"]}}},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Embedding Dimensions","name":"embeddingDimensions","type":"number","default":1536,"description":"Whether to allow using characters from the Unicode surrogate blocks"},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}],"displayOptions":{"show":{"mode":["retrieve"]}}}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreZep/zep.png"},
{"displayName":"Zep Vector Store: Insert","name":"vectorStoreZepInsert","hidden":true,"group":["transform"],"version":1,"description":"Insert data into Zep Vector Store index","defaults":{"name":"Zep: Insert"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorezep/"}]}},"credentials":[{"name":"zepApi","required":true}],"inputs":["main",{"displayName":"Document","maxConnections":1,"type":"ai_document","required":true},{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["main"],"properties":[{"displayName":"This Zep integration is deprecated and will be removed in a future version.","name":"deprecationNotice","type":"notice","default":""},{"displayName":"Collection Name","name":"collectionName","type":"string","default":"","required":true},{"displayName":"Specify the document to load in the document loader sub-node","name":"notice","type":"notice","default":""},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Embedding Dimensions","name":"embeddingDimensions","type":"number","default":1536,"description":"Whether to allow using characters from the Unicode surrogate blocks"},{"displayName":"Is Auto Embedded","name":"isAutoEmbedded","type":"boolean","default":true,"description":"Whether to automatically embed documents when they are added"}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreZepInsert/zep.png"},
{"displayName":"Zep Vector Store: Load","name":"vectorStoreZepLoad","hidden":true,"group":["transform"],"version":1,"description":"Load data from Zep Vector Store index","defaults":{"name":"Zep: Load"},"codex":{"categories":["AI"],"subcategories":{"AI":["Vector Stores"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorezep/"}]}},"credentials":[{"name":"zepApi","required":true}],"inputs":[{"displayName":"Embedding","maxConnections":1,"type":"ai_embedding","required":true}],"outputs":["ai_vectorStore"],"outputNames":["Vector Store"],"properties":[{"displayName":"This Zep integration is deprecated and will be removed in a future version.","name":"deprecationNotice","type":"notice","default":""},{"displayName":"Collection Name","name":"collectionName","type":"string","default":"","required":true},{"displayName":"Options","name":"options","type":"collection","placeholder":"Add Option","default":{},"options":[{"displayName":"Embedding Dimensions","name":"embeddingDimensions","type":"number","default":1536,"description":"Whether to allow using characters from the Unicode surrogate blocks"},{"displayName":"Metadata Filter","name":"metadata","type":"fixedCollection","description":"Metadata to filter the document by","typeOptions":{"multipleValues":true},"default":{},"placeholder":"Add filter field","options":[{"name":"metadataValues","displayName":"Fields to Set","values":[{"displayName":"Name","name":"name","type":"string","default":"","required":true},{"displayName":"Value","name":"value","type":"string","default":""}]}]}]}],"iconUrl":"icons/@n8n/n8n-nodes-langchain/dist/nodes/vector_store/VectorStoreZepLoad/zep.png"},
{"displayName":"Tool Executor","name":"toolExecutor","version":1,"defaults":{"name":"Tool Executor"},"hidden":true,"inputs":["main","ai_tool"],"outputs":["main"],"properties":[{"displayName":"Query","name":"query","type":"json","default":"{}","description":"Parameters to pass to the tool as JSON or string"},{"displayName":"Tool Name","name":"toolName","type":"string","default":"","description":"Name of the tool to execute if the connected tool is a toolkit"}],"group":["transform"],"description":"Node to execute tools without an AI Agent","codex":{"categories":["Core Nodes"],"subcategories":{"Core Nodes":["Helpers"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.editimage/"}]}}},
{"displayName":"Model Selector","name":"modelSelector","icon":"fa:map-signs","iconColor":"green","defaults":{"name":"Model Selector"},"version":1,"group":["transform"],"description":"Use this node to select one of the connected models to this node based on workflow data","inputs":"={{\n\t\t\t\t((parameters) => {\n\t\t\t\t\tfunction configuredInputs(parameters) {\n  return Array.from({ length: parameters.numberInputs || 2 }, (_, i) => ({\n    type: \"ai_languageModel\",\n    displayName: `Model ${(i + 1).toString()}`,\n    required: true,\n    maxConnections: 1\n  }));\n};\n\t\t\t\t\treturn configuredInputs(parameters)\n\t\t\t\t})($parameter)\n\t\t\t}}","codex":{"categories":["AI"],"subcategories":{"AI":["Language Models"]},"resources":{"primaryDocumentation":[{"url":"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.modelselector/"}]}},"outputs":["ai_languageModel"],"requiredInputs":1,"properties":[{"displayName":"Number of Inputs","name":"numberInputs","type":"options","noDataExpression":true,"default":2,"options":[{"name":"2","value":2},{"name":"3","value":3},{"name":"4","value":4},{"name":"5","value":5},{"name":"6","value":6},{"name":"7","value":7},{"name":"8","value":8},{"name":"9","value":9},{"name":"10","value":10}],"validateType":"number","description":"The number of data inputs you want to merge. The node waits for all connected inputs to be executed."},{"displayName":"Rules","name":"rules","placeholder":"Add Rule","type":"fixedCollection","typeOptions":{"multipleValues":true,"sortable":true},"description":"Rules to map workflow data to specific models","default":{},"options":[{"displayName":"Rule","name":"rule","values":[{"displayName":"Model","name":"modelIndex","type":"options","description":"Choose model input from the list","default":1,"required":true,"placeholder":"Choose model input from the list","typeOptions":{"loadOptionsMethod":"getModels"}},{"displayName":"Conditions","name":"conditions","placeholder":"Add Condition","type":"filter","default":{},"typeOptions":{"filter":{"caseSensitive":true,"typeValidation":"strict","version":2}},"description":"Conditions that must be met to select this model"}]}]}]}
]